
@article{ WOS:000413387000003,
Author = {Tharwat, Alaa and Gaber, Tarek and Hassanien, Aboul Ella},
Title = {One-dimensional vs. two-dimensional based features: Plant identification
   approach},
Journal = {JOURNAL OF APPLIED LOGIC},
Year = {2017},
Volume = {24},
Number = {B, SI},
Pages = {15-31},
Month = {NOV},
Abstract = {The number of endangered species has been increased due to shifts in the
   agricultural production, climate change, and poor urban planning. This
   has led to investigating new methods to address the problem of plant
   species identification/classification. In this paper, a plant
   identification approach using 2D digital leaves images was proposed. The
   approach used two features extraction methods based on one-dimensional
   (1D) and two-dimensional (2D) and the Bagging classifier. For the
   1D-based methods, Principal Component Analysis (PCA), Direct Linear
   Discriminant Analysis (DLDA), and PCA + LDA techniques were applied,
   while 2DPCA and 2DLDA algorithms were used for the 2D-based method. To
   classify the extracted features in both methods, the Bagging classifier,
   with the decision tree as a weak learner was used. The five variants,
   i.e. PCA, PCA + LDA, DLDA, 2DPCA, and 2DLDA, of the approach were tested
   using the Flavia public dataset which consists of 1907 colored leaves
   images. The accuracy of these variants was evaluated and the results
   showed that the 2DPCA and 2DLDA methods were much better than using the
   PCA, PCA + LDA, and DLDA. Furthermore, it was found that the 2DLDA
   method was the best one and the increase of the weak learners of the
   Bagging classifier yielded a better classification accuracy. Also, a
   comparison with the most related work showed that our approach achieved
   better accuracy under the same dataset and same experimental setup. (C)
   2016 Elsevier B.V. All rights reserved.},
Publisher = {ELSEVIER},
Address = {RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Gaber, T (Corresponding Author), SRGE, Cairo, Egypt.
   Gaber, T (Corresponding Author), Suez Canal Univ, Fac Comp \& Informat, Ismailia, Egypt.
   Tharwat, Alaa, Suez Canal Univ, Fac Engn, Ismailia, Egypt.
   Tharwat, Alaa; Gaber, Tarek; Hassanien, Aboul Ella, SRGE, Cairo, Egypt.
   Gaber, Tarek, Suez Canal Univ, Fac Comp \& Informat, Ismailia, Egypt.
   Hassanien, Aboul Ella, Cairo Univ, Fac Comp \& Informat, Giza, Egypt.},
DOI = {10.1016/j.jal.2016.11.021},
ISSN = {1570-8683},
EISSN = {1570-8691},
Keywords = {Plant identification; Principal component analysis; Linear Discriminant
   Analysis (LDA); Bagging classifier; 2DLDA; 2DPCA; Direct-LDA; Leaf
   image; Small Sample Size (SSS); PCA plus LDA},
Keywords-Plus = {LINEAR DISCRIMINANT-ANALYSIS; TEXTURE},
Research-Areas = {Computer Science; Mathematics; Science \& Technology - Other Topics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science, Theory \&
   Methods; Mathematics, Applied; Logic},
Author-Email = {engalaatharwat@hotmail.com
   tmgaber@gmail.com
   aboitcairo@gmail.com},
Affiliations = {Egyptian Knowledge Bank (EKB); Suez Canal University; Egyptian Knowledge
   Bank (EKB); Suez Canal University; Egyptian Knowledge Bank (EKB); Cairo
   University},
ResearcherID-Numbers = {Hassanien, Aboul ella/O-5672-2014
   Gaber, Tarek/B-9472-2011
   Tharwat, Alaa/AAS-5682-2020
   Othman, Alaa Tharwat/O-6010-2014},
ORCID-Numbers = {Hassanien, Aboul ella/0000-0002-9989-6681
   Gaber, Tarek/0000-0003-4065-4191
   Tharwat, Alaa/0000-0003-4204-4506
   Othman, Alaa Tharwat/0000-0003-4204-4506},
Cited-References = {{[}Anonymous], 2006, INTRO LINEAR ALGEBRA.
   {[}Anonymous], 2013, INT J ENG SCI TECHNO.
   {[}Anonymous], 8 INT C INF SYST INF.
   {[}Anonymous], 2005, DEP COMPUTER SCI U T.
   {[}Anonymous], 2012, CLEF ONLINE WORKING.
   Arun Priya C., 2012, Proceedings of the 2012 International Conference on Pattern Recognition, Informatics and Medical Engineering (PRIME), P428, DOI 10.1109/ICPRIME.2012.6208384.
   Brain D., 1999, P 4 AUSTR KNOWL ACQ, P117.
   Caglayan A, 2013, LECT NOTES COMPUT SC, V8157, P161, DOI 10.1007/978-3-642-41184-7\_17.
   Chaki J., 2012, INT J COMPUT APPL, V56.
   Chaki J, 2016, SMART INNOV SYST TEC, V43, P37, DOI 10.1007/978-81-322-2538-6\_5.
   Chaki J, 2015, PATTERN RECOGN LETT, V58, P61, DOI 10.1016/j.patrec.2015.02.010.
   Feng T.-t., 2014, ARXIV14092579.
   Gaber T, 2015, ADV INTELL SYST COMP, V368, P375, DOI 10.1007/978-3-319-19719-7\_33.
   Galdamez P.L., 2015, J APPL LOG.
   Kuncheva L. I., 2004, COMBINING PATTERN CL.
   Li M, 2005, PATTERN RECOGN LETT, V26, P527, DOI 10.1016/j.patrec.2004.09.007.
   Lowe DG., 1999, P 7 IEEE INT C COMPU, V2, P1150, DOI {[}10.1109/iccv.1999.790410, DOI 10.1109/ICCV.1999.790410].
   Lu JW, 2005, PATTERN RECOGN LETT, V26, P181, DOI 10.1016/j.patrec.2004.09.014.
   Marcialis G.L., 2002, BIOMETRIC AUTHENTICA, P30.
   Mitchell JBO, 2014, WIRES COMPUT MOL SCI, V4, P468, DOI 10.1002/wcms.1183.
   MOORE BC, 1981, IEEE T AUTOMAT CONTR, V26, P17, DOI 10.1109/TAC.1981.1102568.
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623.
   Salvador E, 2004, COMPUT VIS IMAGE UND, V95, P238, DOI 10.1016/j.cviu.2004.03.008.
   Tharwat A, 2015, ADV INTELL SYST, V334, P359, DOI 10.1007/978-3-319-13572-4\_30.
   Tharwat A, 2014, COMM COM INF SC, V488, P236.
   Tharwat A, 2014, ADV INTELL SYST, V303, P217, DOI 10.1007/978-3-319-08156-4\_22.
   TURK MA, 1991, 1991 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, P586.
   Uluturk C., 2012, INT S INN INT SYST A, P1, DOI DOI 10.1109/INISTA.2012.6247030.
   Valliammal N., 2011, COMPUTER SCI ENG INT, V1, P13, DOI {[}DOI 10.5121/cseij.2011.1402, DOI 10.5121/CSEIJ.2011.1402].
   Wu MC, 2009, BIOINFORMATICS, V25, P1145, DOI 10.1093/bioinformatics/btp019.
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097.
   Ye J., 2004, ADV NEURAL INFORM PR, P1569.
   Ye JP, 2006, J MACH LEARN RES, V7, P1183.},
Number-of-Cited-References = {33},
Times-Cited = {7},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {15},
Journal-ISO = {J. Appl. Log.},
Doc-Delivery-Number = {FK3LQ},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000413387000003},
OA = {hybrid},
DA = {2023-08-12},
}

@inproceedings{ WOS:000465234300020,
Author = {Fawakherji, Mulham and Youssef, Ali and Bloisi, Domenico D. and Pretto,
   Alberto and Nardi, Daniele},
Book-Group-Author = {IEEE},
Title = {Crop and Weeds Classification for Precision Agriculture using
   Context-Independent Pixel-Wise Segmentation},
Booktitle = {2019 THIRD IEEE INTERNATIONAL CONFERENCE ON ROBOTIC COMPUTING (IRC 2019)},
Year = {2019},
Pages = {146-152},
Note = {3rd IEEE International Conference on Robotic Computing (IRC), Naples,
   ITALY, FEB 25-27, 2019},
Organization = {IEEE; IEEE Comp Soc},
Abstract = {Precision agriculture is gaining increasing attention because of the
   possible reduction of agricultural inputs (e.g., fertilizers and
   pesticides) that can be obtained by using high-tech equipment, including
   robots. In this paper, we focus on an agricultural robotics system that
   addresses the weeding problem by means of selective spraying or
   mechanical removal of the detected weeds. In particular, we describe a
   deep learning based method to allow a robot to perform an accurate
   weed/crop classification using a sequence of two Convolutional Neural
   Networks (CNNs) applied to RGB images. The first network, based on an
   encoder-decoder segmentation architecture, performs a pixel-wise,
   plant-type agnostic, segmentation between vegetation and soil that
   enables to extract a set of connected blobs representing plant
   instances. We show that such network can be trained also using external,
   ready to use pixel-wise labeled data sets coming from different
   contexts. Each plant is hence classified between crop and weeds by using
   the second network. Quantitative experimental results, obtained on real
   world data, demonstrate that the proposed approach can achieve good
   classification results also on challenging images.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Bloisi, DD (Corresponding Author), Univ Basilicata, Dept Math Comp Sci \& Econ, Potenza, Italy.
   Fawakherji, Mulham; Youssef, Ali; Pretto, Alberto; Nardi, Daniele, Sapienza Univ Rome, Dept Comp Control \& Management Engn, Rome, Italy.
   Bloisi, Domenico D., Univ Basilicata, Dept Math Comp Sci \& Econ, Potenza, Italy.},
DOI = {10.1109/IRC.2019.00029},
ISBN = {978-1-5386-9245-5},
Keywords-Plus = {CROP/WEED DISCRIMINATION; PLANT CLASSIFICATION},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Cybernetics; Robotics},
Author-Email = {domenico.bloisi@unibas.it
   nardi@diag.uniroma1.it},
Affiliations = {Sapienza University Rome; University of Basilicata},
ResearcherID-Numbers = {Pretto, Alberto/IAQ-1553-2023},
Cited-References = {{[}Anonymous], 2015, ARXIV151100561.
   {[}Anonymous], ARXIV180208960.
   {[}Anonymous], 2014, IEEE WINTER C APPL C.
   Chebrolu N., 2017, INT J ROBOTICS RES.
   De Rainville FM, 2014, PATTERN ANAL APPL, V17, P401, DOI 10.1007/s10044-012-0307-5.
   Di Cicco M, 2017, IEEE INT C INT ROBOT, P5188, DOI 10.1109/IROS.2017.8206408.
   Duckett T, 2018, UK RAS WHITE PAPERS.
   Haug S, 2015, LECT NOTES COMPUT SC, V8928, P105, DOI {[}10.1007/978-3-319-16220-1-8, 10.1007/978-3-319-16220-1\_8].
   Lee SH, 2015, IEEE IMAGE PROC, P452, DOI 10.1109/ICIP.2015.7350839.
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965.
   Lottes Philipp, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3024, DOI 10.1109/ICRA.2017.7989347.
   Lottes P, 2016, IEEE INT CONF ROBOT, P5157, DOI 10.1109/ICRA.2016.7487720.
   Lottes P., 2018, ARXIV180603413.
   Lottes P., 2018, IEEE ROBOTICS AUTOMA, V3, P3097.
   McCool C, 2017, IEEE ROBOT AUTOM LET, V2, P1344, DOI 10.1109/LRA.2017.2667039.
   Milioto A, 2018, IEEE INT CONF ROBOT, P2229.
   Potena C, 2017, ADV INTELL SYST COMP, V531, P105, DOI 10.1007/978-3-319-48036-7\_9.
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4\_28.
   Sa I, 2018, IEEE ROBOT AUTOM LET, V3, P588, DOI 10.1109/LRA.2017.2774979.
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683.
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556.
   Strothmann W, 2017, COMPUT ELECTRON AGR, V134, P79, DOI 10.1016/j.compag.2017.01.003.},
Number-of-Cited-References = {22},
Times-Cited = {47},
Usage-Count-Last-180-days = {4},
Usage-Count-Since-2013 = {18},
Doc-Delivery-Number = {BM5LZ},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000465234300020},
DA = {2023-08-12},
}

@article{ WOS:000361860900004,
Author = {Chandler, Sabrina and Van Hese, Nathalie and Coutte, Francois and
   Jacques, Philippe and Hofte, Monica and De Vleesschauwer, David},
Title = {Role of cyclic lipopeptides produced by Bacillus subtilis in mounting
   induced immunity in rice (Oryza sativa L.)},
Journal = {PHYSIOLOGICAL AND MOLECULAR PLANT PATHOLOGY},
Year = {2015},
Volume = {91},
Pages = {20-30},
Month = {JUL},
Abstract = {In this study, we demonstrate the potential of Bacillus subtilis BBG111
   to trigger ISR in rice (Oryza sativa L.) against Rhizoctonia solani,
   while there was no effect against Magnaporthe oryzae. We show that plant
   recognition of BBG111 induces jasmonic acid (JA) and ethylene (ET) as
   well as abscisic acid (ABA) and auxin signaling. In addition, B.
   subtilis supernatants also boosted immune responses triggered by chitin,
   suggesting that BBG111 triggers ISR at least in part by reinforcing
   basal plant defense responses. Finally, our results reveal an
   indispensable role of the BBG111 cyclic lipopeptides, fengycin and
   surfactin, in the induced defense state. (C) 2015 Elsevier Ltd. All
   rights reserved.},
Publisher = {ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD},
Address = {24-28 OVAL RD, LONDON NW1 7DX, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Hofte, M (Corresponding Author), Univ Ghent, Dept Crop Protect, Coupure Links 653, B-9000 Ghent, Belgium.
   Chandler, Sabrina; Van Hese, Nathalie; Hofte, Monica; De Vleesschauwer, David, Univ Ghent, Fac Biosci Engn, Lab Phytopathol, B-9000 Ghent, Belgium.
   Coutte, Francois; Jacques, Philippe, Univ Lille 1, Sci \& Technol, Charles Viollette Inst,Polytech Lille, Reg Res Lab Food \& Biotechnol ProBioGEM Team,EA10, F-59655 Villeneuve Dascq, France.},
DOI = {10.1016/j.pmpp.2015.05.010},
ISSN = {0885-5765},
Keywords = {Oryza sativa; Rhizoctonia solani; Magnaporthe oryzae; Bacillus subtilis;
   Rice; Immunity; Hormone signaling; Cyclic lipopeptides; Induced systemic
   resistance; Biocontrol; Surfactin; Fengycin},
Keywords-Plus = {SPECTRUM DISEASE RESISTANCE; INDUCED SYSTEMIC RESISTANCE;
   PATTERN-RECOGNITION RECEPTOR; ABSCISIC-ACID; SIGNALING PATHWAY;
   CONSTITUTIVE EXPRESSION; INTERFAMILY TRANSFER; RHIZOCTONIA-SOLANI;
   MAGNAPORTHE-GRISEA; FUNGAL PATHOGENS},
Research-Areas = {Plant Sciences},
Web-of-Science-Categories  = {Plant Sciences},
Author-Email = {monica.hofte@ugent.be},
Affiliations = {Ghent University; Universite de Lille - ISITE; Universite de Lille},
ResearcherID-Numbers = {Hofte, Monica MR/A-6154-2008
   COUTTE, FRANCOIS/AAF-6134-2020
   De Vleesschauwer, David/L-9126-2014
   },
ORCID-Numbers = {De Vleesschauwer, David/0000-0002-1992-0734
   COUTTE, Francois/0000-0002-5233-1181
   Hofte, Monica/0000-0002-0850-3249},
Funding-Acknowledgement = {Institute for the Promotion of Innovation through Science and technology
   in Flanders (IWT-Flanders) {[}LA-traject 110789]; Special Research Fund
   of Ghent University {[}GOA 01GB3013]; EU INTERREG IV PhytoBio Project;
   Research Foundation-Flanders (FWO-Vlaanderen)},
Funding-Text = {This work was financed by grants from the Institute for the Promotion of
   Innovation through Science and technology in Flanders (IWT-Flanders,
   LA-traject 110789), the Special Research Fund of Ghent University (GOA
   01GB3013), the EU INTERREG IV PhytoBio Project and a postdoctoral
   fellowship of the Research Foundation-Flanders (FWO-Vlaanderen) to
   D.D.V.},
Cited-References = {Afroz A, 2011, PLANT CELL TISS ORG, V104, P227, DOI 10.1007/s11240-010-9825-2.
   Asselbergh B, 2007, PLANT PHYSIOL, V144, P1863, DOI 10.1104/pp.107.099226.
   BABA A, 1986, PLANT CELL PHYSIOL, V27, P463.
   Bechet M, 2013, BIORESOURCE TECHNOL, V145, P264, DOI 10.1016/j.biortech.2013.03.123.
   Chern MS, 2001, PLANT J, V27, P101, DOI 10.1046/j.1365-313x.2001.01070.x.
   Contreras I, 2004, PLANT J, V38, P685, DOI 10.1111/j.1365-313X.2004.02075.x.
   Coutte F, 2010, J APPL MICROBIOL, V109, P480, DOI 10.1111/j.1365-2672.2010.04683.x.
   Coutte F, 2013, PROCESS BIOCHEM, V48, P25, DOI 10.1016/j.procbio.2012.10.005.
   D'aes J, 2010, ENV MICROBIOL REP, V2, P359, DOI 10.1111/j.1758-2229.2009.00104.x.
   De Vleesschauwer D, 2008, PLANT PHYSIOL, V148, P1996, DOI 10.1104/pp.108.127878.
   De Vleesschauwer D, 2006, MOL PLANT MICROBE IN, V19, P1406, DOI 10.1094/MPMI-19-1406.
   De Vleesschauwer D, 2014, FRONT PLANT SCI, V5, DOI 10.3389/fpls.2014.00611.
   De Vleesschauwer D, 2013, TRENDS PLANT SCI, V18, P555, DOI 10.1016/j.tplants.2013.07.002.
   De Vleesschauwer D, 2010, PLANT PHYSIOL, V152, P2036, DOI 10.1104/pp.109.152702.
   De Vleesschauwer D, 2009, ADV BOT RES, V51, P223, DOI 10.1016/S0065-2296(09)51006-3.
   Dean R, 2012, MOL PLANT PATHOL, V13, P414, DOI 10.1111/j.1364-3703.2011.00783.x.
   Deravel J, 2014, APPL MICROBIOL BIOT, V98, P6255, DOI 10.1007/s00253-014-5663-1.
   Desoignies N, 2013, MOL PLANT PATHOL, V14, P416, DOI 10.1111/mpp.12008.
   Ding XH, 2008, PLANT CELL, V20, P228, DOI 10.1105/tpc.107.055657.
   Domingo C, 2009, MOL PLANT MICROBE IN, V22, P201, DOI 10.1094/MPMI-22-2-0201.
   Falardeau J, 2013, J CHEM ECOL, V39, P869, DOI 10.1007/s10886-013-0319-7.
   Farace G, 2015, MOL PLANT PATHOL, V16, P177, DOI 10.1111/mpp.12170.
   Fradin EF, 2011, PLANT PHYSIOL, V156, P2255, DOI 10.1104/pp.111.180067.
   Fu J, 2011, PLANT PHYSIOL, V155, P589, DOI 10.1104/pp.110.163774.
   Garcia-Gutierrez L, 2013, MICROB BIOTECHNOL, V6, P264, DOI 10.1111/1751-7915.12028.
   Grant M, 2006, CURR OPIN PLANT BIOL, V9, P414, DOI 10.1016/j.pbi.2006.05.013.
   Han CU, 2004, MOL CELLS, V17, P462.
   Helliwell EE, 2013, PLANT BIOTECHNOL J, V11, P33, DOI 10.1111/pbi.12004.
   Henry G, 2011, CELL MICROBIOL, V13, P1824, DOI 10.1111/j.1462-5822.2011.01664.x.
   Holton N, 2015, PLOS PATHOG, V11, DOI 10.1371/journal.ppat.1004602.
   HOWARD RJ, 1991, P NATL ACAD SCI USA, V88, P11281, DOI 10.1073/pnas.88.24.11281.
   Jacques P, 2011, MICROBIOL MONOGR, V20, P57, DOI 10.1007/978-3-642-14490-5\_3.
   Jiang CJ, 2010, MOL PLANT MICROBE IN, V23, P791, DOI 10.1094/MPMI-23-6-0791.
   Jourdan E, 2009, MOL PLANT MICROBE IN, V22, P456, DOI 10.1094/MPMI-22-4-0456.
   Jwa NS, 2001, BIOCHEM BIOPH RES CO, V286, P973, DOI 10.1006/bbrc.2001.5507.
   Khush GS, 2005, PLANT MOL BIOL, V59, P1, DOI 10.1007/s11103-005-2159-5.
   Kidou S, 1998, PLANT MOL BIOL, V36, P137, DOI 10.1023/A:1005960721762.
   Kim MC, 2002, J BIOL CHEM, V277, P19304, DOI 10.1074/jbc.M108478200.
   Koga H, 2004, PHYSIOL MOL PLANT P, V65, P3, DOI 10.1016/j.pmpp.2004.11.002.
   Kumar KVK, 2012, RICE SCI, V19, P55, DOI 10.1016/S1672-6308(12)60021-3.
   Kurusu T, 2010, PLANT PHYSIOL, V153, P678, DOI 10.1104/pp.109.151852.
   Lacombe S, 2010, NAT BIOTECHNOL, V28, P365, DOI 10.1038/nbt.1613.
   LEE FN, 1983, PLANT DIS, V67, P829, DOI 10.1094/PD-67-829.
   Lee MW, 2001, MOL PLANT MICROBE IN, V14, P527, DOI 10.1094/MPMI.2001.14.4.527.
   Lugtenberg B, 2009, ANNU REV MICROBIOL, V63, P541, DOI 10.1146/annurev.micro.62.081307.162918.
   MCELROY D, 1990, PLANT MOL BIOL, V15, P257, DOI 10.1007/BF00036912.
   Mendes BMJ, 2010, PLANT PATHOL, V59, P68, DOI 10.1111/j.1365-3059.2009.02148.x.
   Mew T.W., 2004, P FIN WORKSH SEED HL.
   MUNDY J, 1988, EMBO J, V7, P2279, DOI 10.1002/j.1460-2075.1988.tb03070.x.
   Nandakumar R, 2001, SOIL BIOL BIOCHEM, V33, P603, DOI 10.1016/S0038-0717(00)00202-9.
   Ongena M, 2005, APPL MICROBIOL BIOT, V69, P29, DOI 10.1007/s00253-005-1940-3.
   Ongena M, 2008, TRENDS MICROBIOL, V16, P115, DOI 10.1016/j.tim.2007.12.009.
   Ongena M, 2007, ENVIRON MICROBIOL, V9, P1084, DOI 10.1111/j.1462-2920.2006.01202.x.
   Ortmann I, 2006, FEBS LETT, V580, P4491, DOI 10.1016/j.febslet.2006.07.025.
   OU SH, 1980, ANNU REV PHYTOPATHOL, V18, P167, DOI 10.1146/annurev.py.18.090180.001123.
   Peng XX, 2012, PLANTA, V236, P1485, DOI 10.1007/s00425-012-1698-7.
   Pieterse CMJ, 1998, PLANT CELL, V10, P1571, DOI 10.1105/tpc.10.9.1571.
   Pieterse CMJ, 2012, ANNU REV CELL DEV BI, V28, P489, DOI 10.1146/annurev-cellbio-092910-154055.
   Pieterse CMJ, 2009, NAT CHEM BIOL, V5, P308, DOI 10.1038/nchembio.164.
   Raaijmakers JM, 2006, MOL PLANT MICROBE IN, V19, P699, DOI 10.1094/MPMI-19-0699.
   Raaijmakers JM, 2010, FEMS MICROBIOL REV, V34, P1037, DOI 10.1111/j.1574-6976.2010.00221.x.
   Rabindran R, 1996, CROP PROT, V15, P715, DOI 10.1016/S0261-2194(96)00045-2.
   Shimono M, 2007, PLANT CELL, V19, P2064, DOI 10.1105/tpc.106.046250.
   Shlezinger N, 2011, PLOS PATHOG, V7, DOI 10.1371/journal.ppat.1002185.
   Song FM, 2001, PHYSIOL MOL PLANT P, V59, P1, DOI 10.1006/pmpp.2001.0353.
   Taheri P, 2007, PHYTOPATHOLOGY, V97, P373, DOI 10.1094/PHYTO-97-3-0373.
   TAKAIWA F, 1985, PLANT MOL BIOL, V4, P355, DOI 10.1007/BF02418257.
   Talbot NJ, 2003, ANNU REV MICROBIOL, V57, P177, DOI 10.1146/annurev.micro.57.030502.090957.
   Thuan NTN, 2006, EUR J PLANT PATHOL, V114, P381, DOI 10.1007/s10658-006-0002-8.
   Tran H, 2007, NEW PHYTOL, V175, P731, DOI 10.1111/j.1469-8137.2007.02138.x.
   Tripathi JN, 2014, PLANT BIOTECHNOL J, V12, P663, DOI 10.1111/pbi.12170.
   Van Bockhaven J, 2013, J EXP BOT, V64, P1281, DOI 10.1093/jxb/ers329.
   van Loon LC, 1998, ANNU REV PHYTOPATHOL, V36, P453, DOI 10.1146/annurev.phyto.36.1.453.
   Verhagen BWM, 2004, MOL PLANT MICROBE IN, V17, P895, DOI 10.1094/MPMI.2004.17.8.895.
   Yang GX, 2005, J PROTEOME RES, V4, P456, DOI 10.1021/pr049801h.
   Yazawa K, 2012, PHYSIOL MOL PLANT P, V78, P1, DOI 10.1016/j.pmpp.2011.12.003.
   Zarembinski TI, 1997, PLANT MOL BIOL, V33, P71, DOI 10.1023/B:PLAN.0000009693.26740.c3.
   Zheng AP, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms2427.
   Zhu HC, 2007, SCI CHINA SER C, V50, P31, DOI 10.1007/s11427-007-0001-9.
   Zhu Q, 1995, PLANT MOL BIOL, V29, P535, DOI 10.1007/BF00020983.},
Number-of-Cited-References = {80},
Times-Cited = {39},
Usage-Count-Last-180-days = {3},
Usage-Count-Since-2013 = {61},
Journal-ISO = {Physiol. Mol. Plant Pathol.},
Doc-Delivery-Number = {CS1WZ},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000361860900004},
DA = {2023-08-12},
}

@article{ WOS:000710080700009,
Author = {Araujo, Voncarlos M. and Britto Jr, Alceu S. and Oliveira, Luiz S. and
   Koerich, Alessandro L.},
Title = {Two-view fine-grained classification of plant species},
Journal = {NEUROCOMPUTING},
Year = {2022},
Volume = {467},
Pages = {427-441},
Month = {JAN 7},
Abstract = {Automatic plant classification is challenging due to the vast
   biodiversity of the existing plant species in a fine-grained scenario.
   Robust deep learning architectures have been used to improve the
   classification performance in such a fine-grained problem but usually
   build models that are highly dependent on a large training dataset and
   are not scalable. This paper proposes a novel method based on a two-view
   leaf image representation and a hierarchical classification strategy for
   fine-grained plant species recognition. It uses the botanical taxonomy
   as a basis for a coarse-to-fine strategy applied to identify the plant
   genus and species. The two-view representation provides complementary
   global and local features of leaf images. A deep metric based on Siamese
   Convolutional Neural Networks is used to reduce the depen-dence on many
   training samples and make the method scalable to new plant species. The
   experimental results on two challenging fine-grained datasets of leaf
   images (i.e., PlantCLEF 2015 and LeafSnap) have shown the proposed
   method's effectiveness, which achieved recognition accuracy of 0.87 and
   0.96, respectively. (c) 2021 Elsevier B.V. All rights reserved.},
Publisher = {ELSEVIER},
Address = {RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Araujo, VM (Corresponding Author), Pontifical Catholic Univ Parana PUCPR, Curitiba, Parana, Brazil.
   Araujo, Voncarlos M.; Britto Jr, Alceu S., Pontifical Catholic Univ Parana PUCPR, Curitiba, Parana, Brazil.
   Britto Jr, Alceu S., State Univ Ponta Grossa UEPG, Ponta Grossa, Parana, Brazil.
   Oliveira, Luiz S., Fed Univ Parana UFPR, Curitiba, Parana, Brazil.
   Koerich, Alessandro L., Univ Quebec, Ecole Technol Super ETS, Montreal, PQ, Canada.},
DOI = {10.1016/j.neucom.2021.10.015},
EarlyAccessDate = {OCT 2021},
ISSN = {0925-2312},
EISSN = {1872-8286},
Keywords = {Siamese neural network; Fine-grained classification; Plant species
   recognition; Deep metrics},
Keywords-Plus = {IDENTIFICATION},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence},
Author-Email = {voncarlos.araujo@gmail.com
   alceu@ppgia.pucpr.br
   luiz.oliveira@ufpr.br
   alekoe@gmail.com},
Affiliations = {Pontificia Universidade Catolica do Parana; Universidade Estadual de
   Ponta Grossa; Universidade Federal do Parana; University of Quebec;
   Ecole de Technologie Superieure - Canada; University of Quebec Montreal},
ResearcherID-Numbers = {Koerich, Alessandro Lameiras/F-7246-2012
   de Souza Britto Jr, Alceu/AAC-1155-2022
   },
ORCID-Numbers = {Koerich, Alessandro Lameiras/0000-0001-5879-7014
   de araujo, voncarlos/0000-0002-7103-6882},
Cited-References = {Aakif A, 2015, BIOSYST ENG, V139, P66, DOI 10.1016/j.biosystemseng.2015.08.003.
   Aggarwal CC, 2001, LECT NOTES COMPUT SC, V1973, P420.
   Angelova A, 2013, PROC CVPR IEEE, P811, DOI 10.1109/CVPR.2013.110.
   {[}Anonymous], 2009, BIOL SYSTEMATICS PRI.
   Araujo V, 2017, IEEE SYS MAN CYBERN, P1880, DOI 10.1109/SMC.2017.8122891.
   Araujo VM, 2018, PROC INT C TOOLS ART, P1, DOI 10.1109/ICTAI.2018.00011.
   Barbedo JGA, 2018, COMPUT ELECTRON AGR, V153, P46, DOI 10.1016/j.compag.2018.08.013.
   Arun Priya C., 2012, Proceedings of the 2012 International Conference on Pattern Recognition, Informatics and Medical Engineering (PRIME), P428, DOI 10.1109/ICPRIME.2012.6208384.
   Barre P, 2017, ECOL INFORM, V40, P50, DOI 10.1016/j.ecoinf.2017.05.005.
   Bloice M. D., 2017, J OPEN SOURCE SOFTW, DOI {[}DOI 10.21105/JOSS.00432, 10.21105/joss.00432].
   Bodhwani Vinit, 2019, Procedia Computer Science, V152, P186, DOI 10.1016/j.procs.2019.05.042.
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339.
   Chaki J, 2015, PATTERN RECOGN LETT, V58, P61, DOI 10.1016/j.patrec.2015.02.010.
   Elhariri E, 2014, 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING \& SYSTEMS (ICCES), P271, DOI 10.1109/ICCES.2014.7030971.
   Figueroa-Mata G, 2020, BIOMIMETICS-BASEL, V5, DOI 10.3390/biomimetics5010008.
   Gao ZY, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S0218001418500350.
   Ge Z., 2016, P IEEE WINT C APPL C, P1, DOI DOI 10.1109/WACV.2016.7477700.
   Ge ZY, 2015, IEEE IMAGE PROC, P561, DOI 10.1109/ICIP.2015.7350861.
   Ghazi MM, 2017, NEUROCOMPUTING, V235, P228, DOI 10.1016/j.neucom.2017.01.018.
   Grinblat GL, 2016, COMPUT ELECTRON AGR, V127, P418, DOI 10.1016/j.compag.2016.07.003.
   Han DM, 2018, EXPERT SYST APPL, V95, P43, DOI 10.1016/j.eswa.2017.11.028.
   Joly A, 2015, LECT NOTES COMPUT SC, V9283, P462, DOI 10.1007/978-3-319-24027-5\_46.
   Kadir A., 2014, INT J ADV SCI TECHNO, V44, P113.
   Khosla A, 2011, P CVPR WORKSH FIN GR, V2.
   Koch G., 2015, ICML DEEP LEARNING W, P2.
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386.
   Kumar N, 2012, LECT NOTES COMPUT SC, V7573, P502, DOI 10.1007/978-3-642-33709-3\_36.
   Lee S, 2017, 24TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2017), DOI {[}10.1016/j.patcog.2017.05.015, 10.14722/ndss.2017.23457].
   Lee SH, 2017, IEEE IMAGE PROC, P4462, DOI 10.1109/ICIP.2017.8297126.
   Lee SH, 2015, IEEE IMAGE PROC, P452, DOI 10.1109/ICIP.2015.7350839.
   Melekhov I, 2016, INT C PATT RECOG, P378, DOI 10.1109/ICPR.2016.7899663.
   Naresh YG, 2016, NEUROCOMPUTING, V173, P1789, DOI 10.1016/j.neucom.2015.08.090.
   Pawara P, 2017, LECT NOTES COMPUT SC, V10617, P615, DOI 10.1007/978-3-319-70353-4\_52.
   Sfar AR, 2015, INT J COMPUT VISION, V111, P255, DOI 10.1007/s11263-014-0743-3.
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556.
   Simpson MG, 2010, PLANT SYSTEMATICS, 2ND EDITION, P1.
   Snell J., 2017, ADV NEURAL INFORM PR, P4077.
   Soderkvist O., 2001, THESIS.
   Sulc M, 2017, PLANT METHODS, V13, DOI 10.1186/s13007-017-0265-4.
   Sungbin C., 2015, CLEF WORKING NOTES.
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594.
   Taylor L., 2017, ARXIV PREPRINT ARXIV.
   Waldchen J, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1005993.
   Wang B, 2019, IEEE ACCESS, V7, P151754, DOI 10.1109/ACCESS.2019.2947510.
   Wei XS, 2019, IEEE T IMAGE PROCESS, V28, P6116, DOI 10.1109/TIP.2019.2924811.
   Wu SG, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, VOLS 1-3, P120.
   Yanikoglu B, 2014, MACH VISION APPL, V25, P1369, DOI 10.1007/s00138-014-0612-7.
   Zhu YX, 2019, NEUROCOMPUTING, V365, P191, DOI 10.1016/j.neucom.2019.07.016.},
Number-of-Cited-References = {48},
Times-Cited = {7},
Usage-Count-Last-180-days = {11},
Usage-Count-Since-2013 = {30},
Journal-ISO = {Neurocomputing},
Doc-Delivery-Number = {WL0BA},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000710080700009},
OA = {Green Submitted},
DA = {2023-08-12},
}

@article{ WOS:000907931700001,
Author = {Batchuluun, Ganbayar and Nam, Se Hyun and Park, Kang Ryoung},
Title = {Deep learning-based plant classification and crop disease classification
   by thermal camera},
Journal = {JOURNAL OF KING SAUD UNIVERSITY-COMPUTER AND INFORMATION SCIENCES},
Year = {2022},
Volume = {34},
Number = {10, B},
Pages = {10474-10486},
Month = {NOV},
Abstract = {Studies regarding image classification based on plant and crop disease
   images that were acquired using a visible light camera have been
   conducted in the past, whereas those based on thermal images are
   limited. This is because the thermal images are blurry due to the nature
   of the thermal camera, which makes it extremely difficult to classify
   objects. Therefore, this study proposes a new plant and crop disease
   classification method based on thermal images. The proposed method used
   a convolutional neural network with explainable artificial intelligence
   (XAI) to improve plant and crop disease classification performance.
   A new thermal plant image dataset was built for conducting the
   experiments, which contained 4,720 various images of flowers and leaves.
   In addition, an open database of crop diseases was also used, such as
   the Paddy crop dataset. The proposed plant and crop disease
   classification method demonstrated a 98.55\% accuracy for the thermal
   plant image dataset and a 90.04\% accuracy for the Paddy crop dataset,
   both of which outperformed other existing methods. (c) 2022 The
   Author(s). Published by Elsevier B.V. on behalf of King Saud University.},
Publisher = {ELSEVIER},
Address = {RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Park, KR (Corresponding Author), Dongguk Univ, Div Elect \& Elect Engn, 30 Pildong Ro 1 Gil, Seoul 04620, South Korea.
   Batchuluun, Ganbayar; Nam, Se Hyun; Park, Kang Ryoung, Dongguk Univ, Div Elect \& Elect Engn, 30 Pildong Ro 1 Gil, Seoul 04620, South Korea.},
DOI = {10.1016/j.jksuci.2022.11.003},
ISSN = {1319-1578},
EISSN = {2213-1248},
Keywords = {Crop disease image; Plant image classification; Thermal image;
   Convolutional neural network; Explainable artificial intelligence},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Information Systems},
Author-Email = {parkgr@dongguk.edu},
Affiliations = {Dongguk University},
Funding-Acknowledgement = {National Research Foundation of Korea (NRF) - Ministry of Science and
   ICT (MSIT) through the Basic Science Research Program
   {[}NRF-2022R1F1A1064291]; NRF - MSIT through the Basic Science Research
   Program {[}NRF-2021R1F1A1045587]; MSIT, Korea, under the ITRC
   (Information Technology Research Center) support program
   {[}IITP-2022-2020-0-01789]},
Funding-Text = {This research was supported in part by the National Research Foundation
   of Korea (NRF) funded by the Ministry of Science and ICT (MSIT) through
   the Basic Science Research Program (NRF-2022R1F1A1064291), in part by
   the NRF funded by the MSIT through the Basic Science Research Program
   (NRF-2021R1F1A1045587), and in part by the MSIT, Korea, under the ITRC
   (Information Technology Research Center) support program
   (IITP-2022-2020-0-01789) supervised by the IITP (Institute for
   Information \& Communications Technology Planning \& Evaluation).},
Cited-References = {Abdul Hamid N.N.A., 2019, INDONES J ELECT ENG, V14, P333, DOI {[}10.11591/ijeecs.v14.i1.pp333-339, DOI 10.11591/IJEECS.V14.I1.PP333-339].
   Anasta N., 2021, IOP Conference Series: Earth and Environmental Science, V739, DOI 10.1088/1755-1315/739/1/012088.
   {[}Anonymous], MOBILE ACCESSORIES.
   {[}Anonymous], PLANTVILLAGE DATASET.
   {[}Anonymous], FIDS30 DATASET.
   {[}Anonymous], CATEGORICAL LOSS.
   {[}Anonymous], TITAN X.
   {[}Anonymous], COMPACTPROTM XR.
   {[}Anonymous], THERMAL CAMERA.
   {[}Anonymous], PADDY CROP DATASET.
   {[}Anonymous], TAU 2.
   {[}Anonymous], PLANTDXAI MODEL PLAN.
   Ashwinkumar S, 2022, MATER TODAY-PROC, V51, P480, DOI 10.1016/j.matpr.2021.05.584.
   Biswas B., 2019, COMPUTATIONAL INTELL, P105, DOI {[}10.1007/978-981-13-9042-5\_10, DOI 10.1007/978-981-13-9042-5\_10].
   Chakraborty Aditya, 2021, Proceedings of 5th International Conference on Computing Methodologies and Communication (ICCMC 2021), P1624, DOI 10.1109/ICCMC51019.2021.9418042.
   Chompookham Thipwimon, 2021, ICIC Express Letters, V15, P553, DOI 10.24507/icicel.15.06.553.
   Dandekar M., 2021, P INT JOINT C NEURAL, P1.
   Derczynski L, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P261.
   Dey S, 2022, PLANT BIOSYST, V156, P411, DOI 10.1080/11263504.2020.1866093.
   Franczyk Bogdan, 2020, Procedia Computer Science, V176, P1211, DOI 10.1016/j.procs.2020.09.117.
   Ghosh S, 2020, PROCEEDINGS OF 2020 IEEE APPLIED SIGNAL PROCESSING CONFERENCE (ASPCON 2020), P163, DOI {[}10.1109/ASPCON49795.2020.9276669, 10.1109/aspcon49795.2020.9276669].
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90.
   Hossain MS, 2019, IEEE T IND INFORM, V15, P1027, DOI 10.1109/TII.2018.2875149.
   Hussain I., 2020, INT J COMPUTER, V39, P88, DOI {[}10.1007/978-3-319-96133-0\_23, DOI 10.1007/978-3-319-96133-0\_23].
   Kader A., 2020, INT RES J ENG TECHNO, V7, P1.
   Keras, US.
   Kingma D. P., 2015, PROC INT C LEARN REP.
   Lydia M.S., 2019, J PHYS C SERIES, V1566.
   MathWorks, US.
   Muhathir M., 2020, J INFORM TELECOMMUN, V4, P1, DOI {[}10.31289/jite.v4i1.3860, DOI 10.31289/JITE.V4I1.3860].
   OpenCV, US.
   Powers D. M., 2010, J MACH LEARN TECHNOL, P37.
   Python, US.
   Raza SEA, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0123262.
   Redmon J, 2018, Arxiv, DOI arXiv:1804.02767.
   Rhamadiyanti Dzalfa Tsalsabila, 2021, 2021 International Seminar on Intelligent Technology and Its Applications (ISITIA), P226, DOI 10.1109/ISITIA52817.2021.9502258.
   Rudnik K, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9193971.
   Santos Thiago, 2019, Zenodo, DOI 10.5281/ZENODO.3361736.
   Shahi TB, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0264586.
   Siddiqi R., 2020, P 11 INT C ADV INFOR, P1, DOI {[}10.1145/3406601.3406619, DOI 10.1145/3406601.3406619].
   Siddiqi R, 2019, ICDLT 2019: 2019 3RD INTERNATIONAL CONFERENCE ON DEEP LEARNING TECHNOLOGIES, P91, DOI 10.1145/3342999.3343002.
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556.
   Singh D, 2020, ACM INT CONF PR SER, P249, DOI 10.1145/3371158.3371196.
   Singh S, 2022, CMC-COMPUT MATER CON, V71, P1849, DOI 10.32604/cmc.2022.021875.
   Srivastava S., 2020, INT J ENG RES TECHNO, V9, P896.
   Szegedy C, 2015, Arxiv, DOI {[}arXiv:1512.00567, DOI 10.48550/ARXIV.1512.00567].
   VASUMATHI MT, 2021, INDIAN J SCI TECHNOL, V14, P1310, DOI DOI 10.17485/IJST/v14i16.432.
   Wang DF, 2021, COMPUT ELECTRON AGR, V190, DOI 10.1016/j.compag.2021.106468.
   Yilma G, 2021, TURK J ELECTR ENG CO, V29, P2869, DOI 10.3906/elk-2105-115.
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319.
   Zhu WJ, 2018, IFAC PAPERSONLINE, V51, P424, DOI 10.1016/j.ifacol.2018.08.184.},
Number-of-Cited-References = {51},
Times-Cited = {2},
Usage-Count-Last-180-days = {14},
Usage-Count-Since-2013 = {14},
Journal-ISO = {J. King Saud Univ.-Comput. Inf. Sci.},
Doc-Delivery-Number = {7O3ML},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000907931700001},
OA = {gold},
DA = {2023-08-12},
}

@article{ WOS:000444516000026,
Author = {Jiang, Ji-song and Kim, Hak-Jin and Cho, Woo-Jae},
Title = {On-the-go Image Processing System for Spatial Mapping of Lettuce Fresh
   Weight in Plant Factory},
Journal = {IFAC PAPERSONLINE},
Year = {2018},
Volume = {51},
Number = {17},
Pages = {130-134},
Note = {6th International-Federation-of-Automatic-Control (IFAC) Conference on
   Bio-Robotics (BIOROBOTICS), Beijing, PEOPLES R CHINA, JUL 13-15, 2018},
Organization = {Int Federat Automat Control},
Abstract = {Real-time monitoring of crop growth parameters in plant factory can
   provide useful information about accurate assessment of their growth
   status for precision crop management. Plant weight is one of the most
   important biophysical properties used to determine the optimum time for
   harvesting. Conventional plant weight measurements are destructive and
   laborious. An on-the-go image processing system consisting of image
   acquisition and weight estimation was developed to generate a fresh
   weight map of plants grown in hydroponic solutions. Key technologies
   developed in this study are real-time image processing and spatial
   mapping methods that estimate the fresh weights of individual lettuces.
   Images were automatically captured with a low cost web camera and
   processed using a MYRIO-based embedded controller. The camera and
   embedded system moved along an XY axis frame above a plant growing bed
   (0.94 x 1.8 m) using two stepping motors and linear actuators. The image
   preprocessing algorithm consisted of two main subroutines, i.e., image
   segmentation and target plant recognition. For the image segmentation,
   the S channel of the HSV color space and Otsu's threshold were used to
   separate the plants from the background. The target plant was identified
   based on location information of the growing bed holes in captured
   images. The plant weight was estimated using calibration equations
   previously developed that relate the pixel numbers of lettuce images to
   their actual fresh weights in conjunction with the use of a two-point
   normalization method. The accuracy of the fresh weight determined by the
   developed embedded system was confirmed by a highly linear relationship
   with a slope near 1.0 and a coefficient of determination (R-2) of 0.95
   with a processing time of within 4 s. In addition, it was possible to
   generate a spatial map of the fresh weights of lettuces grown in a
   cultivation bed, which could be used to estimate their yields prior to
   harvesting. (C) 2018, IFAC (International Federation of Automatic
   Control) Hosting by Elsevier Ltd. All rights reserved.},
Publisher = {ELSEVIER},
Address = {RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Jiang, JS (Corresponding Author), Seoul Natl Univ, Dept Biosyst Engn, Seoul, South Korea.
   Jiang, Ji-song; Kim, Hak-Jin; Cho, Woo-Jae, Seoul Natl Univ, Dept Biosyst Engn, Seoul, South Korea.},
DOI = {10.1016/j.ifacol.2018.08.075},
ISSN = {2405-8963},
Keywords = {Plant factory; Image processing; Real-time sensing; Fresh weight;
   Overlapping leaf; Plant growth},
Keywords-Plus = {GROWTH MEASUREMENT},
Research-Areas = {Automation \& Control Systems},
Web-of-Science-Categories  = {Automation \& Control Systems},
Author-Email = {290575943@qq.com
   kimhj69@snu.ac.kr
   er8er@naver.com},
Affiliations = {Seoul National University (SNU)},
Funding-Acknowledgement = {Institute of Planning \& Evaluation for Technology in Food, Agriculture,
   Forestry \& Fisheries (iPET), Republic of Korea {[}315011033SB010]
   Funding Source: Korea Institute of Science \& Technology Information
   (KISTI), National Science \& Technology Information Service (NTIS)},
Cited-References = {{[}Anonymous], 1997, J GRAPH TOOLS, DOI DOI 10.1080/10867651.1997.10487480.
   Chien CF, 2005, T ASAE, V48, P1953, DOI 10.13031/2013.19987.
   Jiang J. S., 2016, SPRING C KOR SOC AGR, V21, P201.
   Jung Dae-Hyun, 2015, Journal of Biosystems Engineering, V40, P89.
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076.
   Story D, 2010, COMPUT ELECTRON AGR, V74, P238, DOI 10.1016/j.compag.2010.08.010.
   Yeh YHF, 2014, BIOSYST ENG, V117, P43, DOI 10.1016/j.biosystemseng.2013.08.011.},
Number-of-Cited-References = {7},
Times-Cited = {8},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {9},
Journal-ISO = {IFAC PAPERSONLINE},
Doc-Delivery-Number = {GT4ZQ},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000444516000026},
OA = {gold},
DA = {2023-08-12},
}

@article{ WOS:000540218000018,
Author = {Hao, Xia and Jia, Jingdun and Khattak, Abdul Mateen and Zhang, Li and
   Guo, Xuchao and Gao, Wanlin and Wang, Minjuan},
Title = {Growing period classification of Gynura bicolor DC using GL-CNN},
Journal = {COMPUTERS AND ELECTRONICS IN AGRICULTURE},
Year = {2020},
Volume = {174},
Month = {JUL},
Abstract = {Determining the optimal growth stage of leafy vegetables suitable for
   harvesting is of great importance. Despite the availability of many
   intelligent programs designed for plant classification, identifying the
   growth stage of a vegetable from its leaf features remains a major
   challenge. Gynura bicolor DC (G. bicolor) is an important vegetable, and
   its leaves are harvested for culinary use at a specific growth stage.
   The produce quality of leaves is compromised when they are harvested at
   improper stage. A classification model named GL-CNN was proposed based
   on convolutional neural networks to address this issue. The proposed
   model merges the features using a network fusion strategy to expand the
   feature representation on the basis of the intact leaf and leaf patch
   image sets. The networks were validated using a new dataset of G.
   bicolor planted and collected by ourselves. ``Early fusion{''} and
   ``late fusion{''} networks were designed and compared with GL-CNN to
   verify the rationality of network fusion location. The test accuracy of
   GL-CNN reaches 95.63\%, which is the best in the classification task.},
Publisher = {ELSEVIER SCI LTD},
Address = {THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Gao, WL; Wang, MJ (Corresponding Author), China Agr Univ, Key Lab Agr Informatizat Standardizat, Minist Agr \& Rural Affairs, Beijing 10083, Peoples R China.
   Hao, Xia; Jia, Jingdun; Zhang, Li; Gao, Wanlin; Wang, Minjuan, Minist Agr \& Rural Affairs, Key Lab Agr Informatizat Standardizat, Beijing 100083, Peoples R China.
   Hao, Xia; Khattak, Abdul Mateen; Zhang, Li; Guo, Xuchao; Gao, Wanlin; Wang, Minjuan, China Agr Univ, Coll Informat \& Elect Engn, Beijing 100083, Peoples R China.
   Khattak, Abdul Mateen, Univ Agr, Dept Hort, Peshawar 25120, Pakistan.
   Wang, Minjuan, Shandong Agr \& Engn Univ, Coll Informat Sci \& Engn, Jinan 251100, Peoples R China.},
DOI = {10.1016/j.compag.2020.105497},
Article-Number = {105497},
ISSN = {0168-1699},
EISSN = {1872-7107},
Keywords = {Classification; Deep learning; Fusion strategy; Multi-scale information},
Keywords-Plus = {IMAGE CLASSIFICATION; POROUS-TUBE; ION UPTAKE; RECOGNITION; EFFICIENCY;
   IDENTIFICATION; FEATURES; GROWTH; PLANTS},
Research-Areas = {Agriculture; Computer Science},
Web-of-Science-Categories  = {Agriculture, Multidisciplinary; Computer Science, Interdisciplinary
   Applications},
Author-Email = {wanlin\_cau@163.com
   minjuan@cau.edu.cn},
Affiliations = {Ministry of Agriculture \& Rural Affairs; China Agricultural University;
   Agricultural University Peshawar; University of Agriculture Faisalabad;
   Shandong Agriculture \& Engineering University},
ORCID-Numbers = {Hao, Xia/0000-0001-6817-1779
   Guo, Xuchao/0000-0002-6457-0534},
Funding-Acknowledgement = {Key Research and Development Project of Shandong Province
   {[}2019GNC106091]; National Key Research and Development Program
   {[}2016YFD0200600-2016YFD0200602]},
Funding-Text = {This work was supported by the Key Research and Development Project of
   Shandong Province (Grant No. 2019GNC106091) and the National Key
   Research and Development Program (Grant No.
   2016YFD0200600-2016YFD0200602). All of the mentioned support is
   gratefully acknowledged. In addition, thanks for all the help of the
   teachers and students of the related universities.},
Cited-References = {Amara J., 2017, P BTW WORKSH STUTTG, P79.
   {[}Anonymous], 2020, AGRIVITA J AGR SCI.
   {[}Anonymous], P IEEE C COMP VIS PA.
   Araujo VM, 2018, PROC INT C TOOLS ART, P1, DOI 10.1109/ICTAI.2018.00011.
   Atabay H. A, 2016, IIOAB J, V7, P226.
   Azman A.A., 2017, ELEKTR J ELECT ENG, V16, P1, DOI 10.11113/elektrika.v16n2.542017(2).
   Backes AR, 2013, INFORM SCIENCES, V219, P168, DOI 10.1016/j.ins.2012.07.003.
   Du CB, 2017, IEEE ACCESS, V5, P15750, DOI 10.1109/ACCESS.2017.2735019.
   Esgario JGM, 2020, COMPUT ELECTRON AGR, V169, DOI 10.1016/j.compag.2019.105162.
   Esmaeili H, 2018, INT JOINT CONF COMP, P191.
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213.
   Ghazi MM, 2017, NEUROCOMPUTING, V235, P228, DOI 10.1016/j.neucom.2017.01.018.
   Ghosal S, 2018, P NATL ACAD SCI USA, V115, P4613, DOI 10.1073/pnas.1716999115.
   Habibzadeh M, 2018, PROC SPIE, V10696, DOI 10.1117/12.2311282.
   Hu J, 2018, IEEE SIGNAL PROC LET, V25, P853, DOI 10.1109/LSP.2018.2809688.
   Jmour N, 2017, 2018 INTERNATIONAL CONFERENCE ON ADVANCED SYSTEMS AND ELECTRICAL TECHNOLOGIES (IC\_ASET), P397.
   Kangune K., 2019, 2019 GLOBAL C ADVANC, P1, DOI DOI 10.1109/GCAT47503.2019.8978341.
   Knoll FJ, 2018, COMPUT ELECTRON AGR, V153, P347, DOI 10.1016/j.compag.2018.08.032.
   Lai J, 2016, SENS IMAGING, V17, DOI 10.1007/s11220-016-0138-3.
   Lee SH, 2018, IEEE T IMAGE PROCESS, V27, P4287, DOI 10.1109/TIP.2018.2836321.
   Lee SH, 2015, IEEE IMAGE PROC, P452, DOI 10.1109/ICIP.2015.7350839.
   Liu B, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10010011.
   Liu J, 2019, M CONT JURISPRUD CHI, P1, DOI {[}10.1007/978-981-13-3756-7, 10.1155/2019/8156450, 10.1080/08827508.2019.1575214, 10.1007/978-981-13-3756-7\_1].
   Liu JinRong, 2018, Journal of Agricultural Science and Technology (Beijing), V20, P55.
   Lu J, 2017, COMPUT ELECTRON AGR, V142, P369, DOI 10.1016/j.compag.2017.09.012.
   Ma JC, 2018, COMPUT ELECTRON AGR, V154, P18, DOI 10.1016/j.compag.2018.08.048.
   Millard K, 2015, REMOTE SENS-BASEL, V7, P8489, DOI 10.3390/rs70708489.
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419.
   Nair V., 2010, ICML 10 PROC 27 INT.
   Naresh YG, 2016, NEUROCOMPUTING, V173, P1789, DOI 10.1016/j.neucom.2015.08.090.
   Nasiri A, 2019, POSTHARVEST BIOL TEC, V153, P133, DOI 10.1016/j.postharvbio.2019.04.003.
   Picon A, 2019, COMPUT ELECTRON AGR, V161, P280, DOI 10.1016/j.compag.2018.04.002.
   Ramcharan A, 2017, FRONT PLANT SCI, V8, DOI 10.3389/fpls.2017.01852.
   Ren XD, 2017, LECT NOTES COMPUT SC, V10431, P378, DOI 10.1007/978-3-319-64185-0\_28.
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707.
   Saleem G, 2019, COMPUT ELECTRON AGR, V157, P270, DOI 10.1016/j.compag.2018.12.038.
   Shi X., 2003, C COMP VIS PATT REC, V8, P95.
   Shimizu Y, 2010, FOOD SCI TECHNOL RES, V16, P479, DOI 10.3136/fstr.16.479.
   Taniguchi H., 2018, P 23 OPT COMM C, P1, DOI {[}10.1109/OECC.2018.8730055, DOI 10.1109/OECC.2018.8730055, DOI 10.1109/AIPR.2018.8707385].
   Tian HongKun, 2020, Information Processing in Agriculture, V7, P1, DOI 10.1016/j.inpa.2019.09.006.
   Tian Y, 2011, INTELL AUTOM SOFT CO, V17, P519, DOI 10.1080/10798587.2011.10643166.
   Wang LiJun, 2015, Journal of Beijing Forestry University, V37, P55.
   Wang M, 2016, PLANT BIOLOGY, V18, P391, DOI 10.1111/plb.12426.
   Wang MJ, 2015, ACTA ASTRONAUT, V114, P138, DOI 10.1016/j.actaastro.2015.05.010.
   Wang MJ, 2015, ACTA ASTRONAUT, V113, P13, DOI 10.1016/j.actaastro.2015.03.023.
   Wu SG, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, VOLS 1-3, P120.
   Xiao Z, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9132725.
   Yang CC, 2003, AGR SYST, V76, P1101, DOI 10.1016/S0308-521X(02)00051-3.
   Zhang L, 2018, IEEE ACCESS, V6, P67940, DOI 10.1109/ACCESS.2018.2879324.
   {[}张宁 Zhang Ning], 2013, {[}计算机应用, Journal of Computer Applications], V33, P2009.
   {[}郑一力 Zheng Yili], 2017, {[}农业机械学报, Transactions of the Chinese Society for Agricultural Machinery], V48, P30.
   Zhiyu Liu, 2015, Intelligent Computing Theories and Methodologies. 11th International Conference, ICIC 2015. Proceedings: LNCS 9226, P115, DOI 10.1007/978-3-319-22186-1\_11.
   Zhu XL, 2018, COGN SYST RES, V52, P223, DOI 10.1016/j.cogsys.2018.06.008.},
Number-of-Cited-References = {53},
Times-Cited = {15},
Usage-Count-Last-180-days = {5},
Usage-Count-Since-2013 = {30},
Journal-ISO = {Comput. Electron. Agric.},
Doc-Delivery-Number = {LY0MJ},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000540218000018},
DA = {2023-08-12},
}

@inproceedings{ WOS:000451039802200,
Author = {Ozdil, Omer and Esin, Yunus Emre and Demirel, Berkan and Ozturk, Safak},
Book-Group-Author = {IEEE},
Title = {Representative Signature Generation for Plant Detection in Hyperspectral
   Images},
Booktitle = {IGARSS 2018 - 2018 IEEE INTERNATIONAL GEOSCIENCE AND REMOTE SENSING
   SYMPOSIUM},
Series = {IEEE International Symposium on Geoscience and Remote Sensing IGARSS},
Year = {2018},
Pages = {2709-2712},
Note = {38th IEEE International Geoscience and Remote Sensing Symposium
   (IGARSS), Valencia, SPAIN, JUL 22-27, 2018},
Organization = {Inst Elect \& Elect Engineers; Inst Elect \& Elect Engineers Geoscience
   \& Remote Sensing Soc; European Space Agcy},
Abstract = {In this study, the effect of utilizing different type of signatures on
   plant detection success is evaluated on hyperspectral aerial images.
   Plant regions are tried to detect using spectral signatures of leaf,
   stem and tassel belonging to the plant separately and the plant
   representative signature (PRS) is created by averaging of signatures of
   selected region on the aerial images. The signatures used for detection
   are generated from hyperspectral images taken from 10m distance to
   target plant. The Spectral Angle Mapper(SAM) and Generalized Likelihood
   Ratio Test(GLRT) algorithms are used for target detection. Performance
   evaluation is made by Receiver Operating Characteristic (ROC) curves.
   When the results are evaluated, it is observed that the detection
   performance with the use of PRS is higher.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Ozdil, O (Corresponding Author), HAVELSAN Inc, Sensors Signal \& Image Proc Grp, Ankara, Turkey.
   Ozdil, Omer; Esin, Yunus Emre; Demirel, Berkan; Ozturk, Safak, HAVELSAN Inc, Sensors Signal \& Image Proc Grp, Ankara, Turkey.},
ISSN = {2153-6996},
ISBN = {978-1-5386-7150-4},
Keywords = {hyperspectral image processing; plant classification; corn detection;
   spectral library},
Research-Areas = {Engineering; Geology; Remote Sensing},
Web-of-Science-Categories  = {Engineering, Electrical \& Electronic; Geosciences, Multidisciplinary;
   Remote Sensing},
Author-Email = {oozdil@bgt.havelsan.com.tr
   yesin@bgt.havelsan.com.tr
   bdemirel@bgt.havelsan.com.tr
   sozturk@bgt.havelsan.com.tr},
Affiliations = {Havelsan AS},
ResearcherID-Numbers = {Esin, Yunus/ABI-3881-2020
   },
ORCID-Numbers = {Esin, Yunus/0000-0002-3719-9290
   Demirel, Berkan/0000-0002-5759-6410},
Cited-References = {Ayoub TF, 2000, IEEE T AERO ELEC SYS, V36, P810, DOI 10.1109/7.869498.
   Griffin M. K., 2003, Lincoln Laboratory Journal, V14, P29.
   Lee ZP, 1999, APPL OPTICS, V38, P3831, DOI 10.1364/AO.38.003831.
   Lu D, 2002, INT J REMOTE SENS, V23, P2651, DOI 10.1080/01431160110109642.
   Manolakis D., 2003, Lincoln Laboratory Journal, V14, P79.
   Manolakis D, 2002, IEEE SIGNAL PROC MAG, V19, P29, DOI 10.1109/79.974724.
   Ozdemir O. B., 2015, SIG BAS VEG DET HYP.
   Thenkabail PS, 2012, HYPERSPECTRAL REMOTE SENSING OF VEGETATION, P1.},
Number-of-Cited-References = {8},
Times-Cited = {6},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {2},
Doc-Delivery-Number = {BL4XL},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000451039802200},
DA = {2023-08-12},
}

@article{ WOS:000402364000003,
Author = {Lu, Hao and Cao, Zhiguo and Xiao, Yang and Fang, Zhiwen and Zhu, Yanjun},
Title = {Towards fine-grained maize tassel flowering status recognition: Dataset,
   theory and practice},
Journal = {APPLIED SOFT COMPUTING},
Year = {2017},
Volume = {56},
Pages = {34-45},
Month = {JUL},
Abstract = {Maize is one of the three main cereal crops of the world. Accurately
   knowing its tassel flowering status can help to analyze the growth
   status and adjust the farming operation accordingly. At the current
   stage, acquiring the tassel flowering status mainly depends on human
   observation. Actually, it is costly and subjective, especially for the
   large-scale quantitative analysis under the in-field environment. To
   alleviate this, we propose an automatic maize tassel flowering status
   (i.e., non-flowering, partially-flowering and fully-flowering)
   recognition method via the computer vision technology in this paper. In
   particular, this task is formulated as a fine-grained image
   categorization problem. More specifically, scale-invariant feature
   transform (SIFT) is first extracted as the low-level visual descriptor
   to characterize the maize flower. Fisher vector (FV) is then applied to
   execute feature encoding on SIFT to generate more discriminative
   flowering status representation. To further leverage the performance, a
   novel metric leaning method termed large-margin dimensionality reduction
   (LMDR) is proposed. To verify the effectiveness of the proposed method,
   a flowering status dataset that consists of 3000 images is built. The
   experimental results demonstrate that our approach goes beyond the
   state-of-the-art by large margins (at least 8.3\%). The dataset and
   source code are made available online. (C) 2017 Elsevier B.V. All rights
   reserved.},
Publisher = {ELSEVIER},
Address = {RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Xiao, Y (Corresponding Author), Huazhong Univ Sci \& Technol, Natl Key Lab Sci \& Technol Multispectral Informat, Sch Automat, Wuhan 430074, Peoples R China.
   Lu, Hao; Cao, Zhiguo; Xiao, Yang; Fang, Zhiwen; Zhu, Yanjun, Huazhong Univ Sci \& Technol, Natl Key Lab Sci \& Technol Multispectral Informat, Sch Automat, Wuhan 430074, Peoples R China.},
DOI = {10.1016/j.asoc.2017.02.026},
ISSN = {1568-4946},
EISSN = {1872-9681},
Keywords = {Maize tassel; Flowering status recognition; Fine-grained visual
   categorization; Fisher vector; Metric learning},
Keywords-Plus = {CLASSIFICATION; SYSTEM; CROP},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications},
Author-Email = {poppinace@hust.edu.cn
   zgcao@hust.edu.cn
   Yang\_Xiao@hust.edu.cn
   fzw310@hust.edu.cn
   yjzhu@hust.edu.cn},
Affiliations = {Huazhong University of Science \& Technology},
ResearcherID-Numbers = {lu, hao/HZH-4458-2023
   Cao, Zhiguo/ABA-6803-2020
   Lu, Hao/AFL-6512-2022
   },
ORCID-Numbers = {Cao, Zhiguo/0000-0002-9223-1863
   Zhu, Yanjun/0000-0002-8841-6072},
Funding-Acknowledgement = {National Natural Science Foundation of China {[}61502187]; National
   High-tech R\&D Program of China {[}2015AA015904]; Chinese Fundamental
   Research Funds for the Central Universities {[}HUST: 2015QN036]},
Funding-Text = {This work is jointly supported by the National Natural Science
   Foundation of China (Grant No. 61502187), National High-tech R\&D
   Program of China (863 Program) (Grant No. 2015AA015904) and Chinese
   Fundamental Research Funds for the Central Universities (HUST:
   2015QN036).},
Cited-References = {Acosta IF, 2009, SCIENCE, V323, P262, DOI 10.1126/science.1164645.
   {[}Anonymous], 2010, PROC ACM INT C MULTI, DOI DOI 10.1145/1873951.1874249.
   Belhumeur PN, 2008, LECT NOTES COMPUT SC, V5305, P116, DOI 10.1007/978-3-540-88693-8\_9.
   C. M. Administration, 1993, SPEC AGR OBS, V1.
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411.
   Fan RE, 2008, J MACH LEARN RES, V9, P1871.
   Gebbers R, 2010, SCIENCE, V327, P828, DOI 10.1126/science.1183899.
   GERALDI IO, 1985, MAYDICA, V30, P1.
   Guo W, 2015, PLANT METHODS, V11, DOI 10.1186/s13007-015-0047-9.
   Jaakkola TS, 1999, ADV NEUR IN, V11, P487.
   Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57.
   Kurtulmus F, 2014, EXPERT SYST APPL, V41, P7390, DOI 10.1016/j.eswa.2014.06.013.
   LAMBERT RJ, 1978, CROP SCI, V18, P499, DOI 10.2135/cropsci1978.0011183X001800030037x.
   Li LW, 2007, 2007 ASIA-PACIFIC CONFERENCE ON APPLIED ELECTROMAGNETICS, PROCEEDINGS, P1.
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679.
   Lowe DG., 1999, P 7 IEEE INT C COMPU, V2, P1150, DOI {[}10.1109/iccv.1999.790410, DOI 10.1109/ICCV.1999.790410].
   Lu H, 2016, BIOSYST ENG, V147, P139, DOI 10.1016/j.biosystemseng.2016.04.007.
   Lu H, 2015, COMPUT ELECTRON AGR, V118, P143, DOI 10.1016/j.compag.2015.08.027.
   Mashinchi MR, 2016, INFORM FUSION, V27, P161, DOI 10.1016/j.inffus.2015.04.001.
   Nilsback M.E., 2006, P 2006 IEEE COMPUTER, VVolume 2, P1447, DOI DOI 10.1109/CVPR.2006.42.
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS \& IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47.
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623.
   Parkhi OM, 2014, PROC CVPR IEEE, P1693, DOI 10.1109/CVPR.2014.219.
   Parkhi OM, 2012, PROC CVPR IEEE, P3498, DOI 10.1109/CVPR.2012.6248092.
   Peng XJ, 2014, IEEE SIGNAL PROC LET, V21, P1022, DOI 10.1109/LSP.2014.2320530.
   Perez-Ortiz M, 2015, APPL SOFT COMPUT, V37, P533, DOI 10.1016/j.asoc.2015.08.027.
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1\_11.
   Perronnin F, 2007, PROC CVPR IEEE, P2272.
   Salehi S, 2015, KNOWL-BASED SYST, V80, P78, DOI 10.1016/j.knosys.2015.02.018.
   Salehi S, 2015, KNOWL-BASED SYST, V76, P200, DOI 10.1016/j.knosys.2014.12.017.
   Sanchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x.
   Sanchez J, 2012, PATTERN RECOGN LETT, V33, P2216, DOI 10.1016/j.patrec.2012.07.019.
   Shekoofa A, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0097288.
   Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8.
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663.
   Tellaeche A, 2011, APPL SOFT COMPUT, V11, P908, DOI 10.1016/j.asoc.2010.01.011.
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579.
   Vedaldi A, 2012, IEEE T PATTERN ANAL, V34, P480, DOI 10.1109/TPAMI.2011.153.
   Vinyals O, 2012, ADV NEURAL INFORM PR, P2834.
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018.
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207.
   Xiao Y, 2014, IEEE T IMAGE PROCESS, V23, P823, DOI 10.1109/TIP.2013.2295756.
   Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123.
   Yu ZH, 2013, AGR FOREST METEOROL, V174, P65, DOI 10.1016/j.agrformet.2013.02.011.
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, P1713, DOI 10.1109/TIP.2016.2531289.
   Zhu YJ, 2016, BIOSYST ENG, V143, P28, DOI 10.1016/j.biosystemseng.2015.12.015.},
Number-of-Cited-References = {46},
Times-Cited = {12},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {29},
Journal-ISO = {Appl. Soft. Comput.},
Doc-Delivery-Number = {EW2ZH},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000402364000003},
DA = {2023-08-12},
}

@article{ WOS:000429355800003,
Author = {Pang, Cheng and Yao, Hongxun and Sun, Xiaoshuai and Zhao, Sicheng and
   Yu, Wei},
Title = {Rediscover flowers structurally},
Journal = {MULTIMEDIA TOOLS AND APPLICATIONS},
Year = {2018},
Volume = {77},
Number = {7},
Pages = {7851-7863},
Month = {APR},
Abstract = {Existing methods for flower classification are usually focused on
   segmentation of the foreground, followed by extraction of features.
   After extracting the features from the foreground, global pooling is
   performed for final classification. Although this pipeline can be
   applied to many recognition tasks, however, these approaches have not
   explored structural cues of the flowers due to the large variation in
   their appearances. In this paper, we argue that structural cues are
   essential for flower recognition. We present a novel approach that
   explores structural cues to extract features. The proposed method
   encodes the structure of flowers into the final feature vectors for
   classification by operating on salient regions, which is robust to
   appearance variations. In our framework, we first segment the flower
   accurately by refining the existing segmentation method, and then we
   generate local features using our approach. We combine our local feature
   with global-pooled features for classification. Evaluations on the
   Oxford Flower dataset shows that by introducing the structural cues and
   locally pooling of some off-the-shelf features, our method outperforms
   the state-of-the-arts which employ specific designed features and metric
   learning.},
Publisher = {SPRINGER},
Address = {VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Yao, HX (Corresponding Author), Harbin Inst Technol, Sch Comp Sci \& Technol, 92 West Dazhi St, Harbin 150001, Heilongjiang, Peoples R China.
   Pang, Cheng; Yao, Hongxun; Sun, Xiaoshuai; Zhao, Sicheng; Yu, Wei, Harbin Inst Technol, Sch Comp Sci \& Technol, 92 West Dazhi St, Harbin 150001, Heilongjiang, Peoples R China.},
DOI = {10.1007/s11042-017-4679-9},
ISSN = {1380-7501},
EISSN = {1573-7721},
Keywords = {Image classification; Fine-grained classification; Saliency detection;
   Feature extraction},
Keywords-Plus = {ATTENTION MAP},
Research-Areas = {Computer Science; Engineering},
Web-of-Science-Categories  = {Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory \& Methods; Engineering,
   Electrical \& Electronic},
Author-Email = {h.yao@hit.edu.cn},
Affiliations = {Harbin Institute of Technology},
ResearcherID-Numbers = {Yu, Wei/GPX-1311-2022
   },
ORCID-Numbers = {Pang, Cheng/0000-0001-7829-8992},
Cited-References = {Akata Z, 2015, PROC CVPR IEEE, P2927, DOI 10.1109/CVPR.2015.7298911.
   Angelova A, 2012, DEV DEPLOYMENT LARGE.
   Angelova A, 2013, PROC CVPR IEEE, P811, DOI 10.1109/CVPR.2013.110.
   Angelova A, 2013, IEEE WORK APP COMP, P39, DOI 10.1109/WACV.2013.6474997.
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505.
   Branson S, 2014, INT J COMPUT VISION, V108, P3, DOI 10.1007/s11263-014-0698-4.
   Chai YN, 2011, IEEE I CONF COMP VIS, P2579, DOI 10.1109/ICCV.2011.6126546.
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401.
   Guru DS, 2011, MATH COMPUT MODEL, V54, P1030, DOI 10.1016/j.mcm.2010.11.032.
   Guru DS., 2010, INT J COMPUTERS APPL, V1, P21.
   Kanan C, 2010, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2010.5539947.
   Khan F.S., 2011, ADV NEURAL INFORM PR, P1323.
   Krause J, 2015, PROC CVPR IEEE, P5546, DOI 10.1109/CVPR.2015.7299194.
   Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170.
   Lu Y, 2012, PROC CVPR IEEE, P1067, DOI 10.1109/CVPR.2012.6247785.
   Mancas M, 2006, IEEE IMAGE PROC, P445, DOI 10.1109/ICIP.2006.312489.
   Mattos AB, 2014, IEEE IMAGE PROC, P5197, DOI 10.1109/ICIP.2014.7026052.
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS \& IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47.
   Nilsback Maria-Elena, 2007, BMVC, V2007, P1.
   Nilsback ME, 2009, AUTOMATIC VISUAL FLO.
   Parkhi OM, 2012, PROC CVPR IEEE, P3498, DOI 10.1109/CVPR.2012.6248092.
   Parkhi OM, 2011, IEEE I CONF COMP VIS, P1427, DOI 10.1109/ICCV.2011.6126398.
   ROSCH E, 1976, COGNITIVE PSYCHOL, V8, P382, DOI 10.1016/0010-0285(76)90013-X.
   Vedaldi A, 2012, IEEE T PATTERN ANAL, V34, P480, DOI 10.1109/TPAMI.2011.153.
   Wah C, 2015, IEEE WINT CONF APPL, P502, DOI 10.1109/WACV.2015.73.
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018.
   Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1\_54.},
Number-of-Cited-References = {27},
Times-Cited = {3},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {7},
Journal-ISO = {Multimed. Tools Appl.},
Doc-Delivery-Number = {GB8WK},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000429355800003},
DA = {2023-08-12},
}

@inproceedings{ WOS:000257096000162,
Author = {Kirchoff, Bruce and Remington, David and Fu, Lixin and Sadri, Fereidoon},
Book-Group-Author = {IEEE},
Title = {A new type of image-based key},
Booktitle = {BMEI 2008: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON BIOMEDICAL
   ENGINEERING AND INFORMATICS, VOL 1},
Series = {International Conference on Biomedical Engineering and Informatics},
Year = {2008},
Pages = {825+},
Note = {1st International Conference on Biomedical Engineering and Informatics,
   Sanya, PEOPLES R CHINA, MAY 27-30, 2008},
Organization = {Tianjin Univ Technol; IEEE Comp Soc},
Abstract = {Keys are character based tools for plant identification. They are based
   on the decomposition of the plant into very small, atomistic parts.
   These parts are described with the technical and often arcane
   terminology of plant taxonomy. Even the best electronic keys (Delta,
   Lucid) make use of this terminology. Keys are not based on pattern
   recognition, the forte of visual experts. Instead they demand that the
   user look at the plant as if it consisted of a series of isolated parts
   that are classified by name. Keys would be more effective if they were
   visually based. They would be easier to use for visual experts because
   accurate perception is their providence. They would also be easier to
   use for novices because they would not depend on knowledge of arcane
   terminology. This paper proposed an innovative image-based key system
   for species recognition.},
Publisher = {IEEE COMPUTER SOC},
Address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Kirchoff, B (Corresponding Author), UNC Greensboro, Dept Biol, Greensboro, NC 27402 USA.
   Kirchoff, Bruce; Remington, David, UNC Greensboro, Dept Biol, Greensboro, NC 27402 USA.
   Fu, Lixin; Sadri, Fereidoon, UNC Greensboro, Dept Comp Sci, Greensboro, NC 27402 USA.},
DOI = {10.1109/BMEI.2008.301},
ISSN = {1948-2914},
ISBN = {978-0-7695-3118-2},
Keywords-Plus = {CHARACTERS},
Research-Areas = {Engineering; Mathematical \& Computational Biology},
Web-of-Science-Categories  = {Engineering, Biomedical; Mathematical \& Computational Biology},
Author-Email = {kirchoff@uncg.edu
   lfu@uncg.edu},
Affiliations = {University of North Carolina; University of North Carolina Greensboro;
   University of North Carolina; University of North Carolina Greensboro},
ResearcherID-Numbers = {fu, lixin/AAD-4107-2022},
Cited-References = {{[}Anonymous], 2002, PLANT SYSTEMATICS PH.
   {[}Anonymous], 2006, PLANT SYSTEMATICS.
   Friedman J., 2001, INTRO STAT LEARNING, V1.
   Kirchoff BK, 2004, SYST BIOL, V53, P1, DOI 10.1080/10635150490424376.
   Kirchoff BK, 2007, TAXON, V56, P479, DOI 10.1002/tax.562018.
   Walters DR, 1996, VASCULAR PLANT TAXON.},
Number-of-Cited-References = {6},
Times-Cited = {2},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BHW79},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000257096000162},
DA = {2023-08-12},
}

@article{ WOS:000948074500001,
Author = {Beloiu, Mirela and Heinzmann, Lucca and Rehush, Nataliia and Gessler,
   Arthur and Griess, Verena C.},
Title = {Individual Tree-Crown Detection and Species Identification in
   Heterogeneous Forests Using Aerial RGB Imagery and Deep Learning},
Journal = {REMOTE SENSING},
Year = {2023},
Volume = {15},
Number = {5},
Month = {MAR},
Abstract = {Automatic identification and mapping of tree species is an essential
   task in forestry and conservation. However, applications that can
   geolocate individual trees and identify their species in heterogeneous
   forests on a large scale are lacking. Here, we assessed the potential of
   the Convolutional Neural Network algorithm, Faster R-CNN, which is an
   efficient end-to-end object detection approach, combined with
   open-source aerial RGB imagery for the identification and geolocation of
   tree species in the upper canopy layer of heterogeneous temperate
   forests. We studied four tree species, i.e., Norway spruce (Picea abies
   (L.) H. Karst.), silver fir (Abies alba Mill.), Scots pine (Pinus
   sylvestris L.), and European beech (Fagus sylvatica L.), growing in
   heterogeneous temperate forests. To fully explore the potential of the
   approach for tree species identification, we trained single-species and
   multi-species models. For the single-species models, the average
   detection accuracy (F1 score) was 0.76. Picea abies was detected with
   the highest accuracy, with an average F1 of 0.86, followed by A. alba
   (F1 = 0.84), F. sylvatica (F1 = 0.75), and Pinus sylvestris (F1 = 0.59).
   Detection accuracy increased in multi-species models for Pinus
   sylvestris (F1 = 0.92), while it remained the same or decreased slightly
   for the other species. Model performance was more influenced by site
   conditions, such as forest stand structure, and less by illumination.
   Moreover, the misidentification of tree species decreased as the number
   of species included in the models increased. In conclusion, the
   presented method can accurately map the location of four individual tree
   species in heterogeneous forests and may serve as a basis for future
   inventories and targeted management actions to support more resilient
   forests.},
Publisher = {MDPI},
Address = {ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND},
Type = {Article},
Language = {English},
Affiliation = {Beloiu, M (Corresponding Author), Swiss Fed Inst Technol, Inst Terr Ecosyst, Dept Environm Syst Sci, CH-8092 Zurich, Switzerland.
   Beloiu, Mirela; Heinzmann, Lucca; Gessler, Arthur; Griess, Verena C., Swiss Fed Inst Technol, Inst Terr Ecosyst, Dept Environm Syst Sci, CH-8092 Zurich, Switzerland.
   Rehush, Nataliia, Swiss Fed Inst Forest, Forest Resources \& Management, Snow \& Landscape WSL, CH-8903 Birmensdorf, Switzerland.
   Gessler, Arthur, Swiss Fed Inst Forest, Forest Dynam, Snow \& Landscape Res WSL, CH-8903 Birmensdorf, Switzerland.},
DOI = {10.3390/rs15051463},
Article-Number = {1463},
EISSN = {2072-4292},
Keywords = {forest monitoring; Convolutional Neural Network (CNN); conifer and
   deciduous species; temperate forest; tree species geolocation},
Keywords-Plus = {CONVOLUTIONAL NEURAL-NETWORKS; UAV IMAGERY; CLASSIFICATION; CNN},
Research-Areas = {Environmental Sciences \& Ecology; Geology; Remote Sensing; Imaging
   Science \& Photographic Technology},
Web-of-Science-Categories  = {Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science \& Photographic Technology},
Author-Email = {mirela.beloiu@usys.ethz.ch},
Affiliations = {Swiss Federal Institutes of Technology Domain; ETH Zurich; Swiss Federal
   Institutes of Technology Domain; Swiss Federal Institute for Forest,
   Snow \& Landscape Research},
ResearcherID-Numbers = {Rehush, Nataliia/AAX-4553-2021
   Gessler, Arthur/C-7121-2008
   Griess, Verena C/D-1405-2010
   },
ORCID-Numbers = {Rehush, Nataliia/0000-0003-4966-1945
   Gessler, Arthur/0000-0002-1910-9589
   Griess, Verena C/0000-0002-3856-3736
   Beloiu, Mirela/0000-0002-3592-8170},
Cited-References = {Achim A, 2022, FORESTRY, V95, P143, DOI 10.1093/forestry/cpab047.
   Ahlswede S, 2023, EARTH SYST SCI DATA, V15, P681, DOI 10.5194/essd-15-681-2023.
   {[}Anonymous], LWF LONG TERM FOREST.
   {[}Anonymous], SWISSTOPO SWISSIMAGE.
   {[}Anonymous], SWISSTOPO SWISSBOUND.
   {[}Anonymous], ROUNDSHOT 360 DEGREE.
   Beloiu M., 2021, P EGU GEN ASSEMBLY C, DOI {[}10.5194/egusphere-egu21-14548, DOI 10.5194/EGUSPHERE-EGU21-14548].
   Beloiu M, 2022, FOR ECOSYST, V9, DOI 10.1016/j.fecs.2022.100002.
   Beloiu M, 2022, FOREST ECOL MANAG, V509, DOI 10.1016/j.foreco.2022.120075.
   Bienz R., 2021, TREE SPECIES SEGMENT.
   Brandtberg T, 1997, SCAND J FOREST RES, V12, P89, DOI 10.1080/02827589709355388.
   Brodrick PG, 2019, TRENDS ECOL EVOL, V34, P734, DOI 10.1016/j.tree.2019.03.006.
   Cavender-Bares J, 2022, NAT ECOL EVOL, V6, P506, DOI 10.1038/s41559-022-01702-5.
   Chadwick AJ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12244104.
   Choi K, 2022, ISPRS J PHOTOGRAMM, V190, P165, DOI 10.1016/j.isprsjprs.2022.06.004.
   Correia DLP, 2020, IEEE ACCESS, V8, P13151, DOI 10.1109/ACCESS.2020.2965462.
   La Rosa LEC, 2021, ISPRS J PHOTOGRAMM, V179, P35, DOI 10.1016/j.isprsjprs.2021.07.001.
   de Lima RAF, 2022, NAT ECOL EVOL, V6, P656, DOI 10.1038/s41559-022-01738-7.
   Deng ZP, 2018, ISPRS J PHOTOGRAMM, V145, P3, DOI 10.1016/j.isprsjprs.2018.04.003.
   dos Santos AA, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19163595.
   Ecke S, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14133205.
   FAO and UNEP, 2020, STATE WORLDS FORESTS, DOI 10.4060/ca8642-n.
   Fassnacht FE, 2016, REMOTE SENS ENVIRON, V186, P64, DOI 10.1016/j.rse.2016.08.013.
   Fricker GA, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11192326.
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074.
   Grossberg AJ, 2018, SCI DATA, V5, DOI {[}10.1038/sdata.2018.173, 10.1038/sdata.2018.214, 10.1038/s41597-018-0002-5].
   Hartl FH, 2016, CAN J FOREST RES, V46, P163, DOI 10.1139/cjfr-2015-0264.
   Hoeser T, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101667.
   Immitzer M, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8030166.
   Jaskierniak D, 2021, ISPRS J PHOTOGRAMM, V171, P171, DOI 10.1016/j.isprsjprs.2020.10.016.
   Kalin U, 2019, REMOTE SENS ENVIRON, V223, P143, DOI 10.1016/j.rse.2018.12.021.
   Katal N, 2022, FRONT PLANT SCI, V13, DOI 10.3389/fpls.2022.805738.
   Kattenborn T, 2021, ISPRS J PHOTOGRAMM, V173, P24, DOI 10.1016/j.isprsjprs.2020.12.010.
   Kattenborn T, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-53797-9.
   Korpela I, 2014, SILVA FENN, V48, DOI 10.14214/sf.1087.
   Kuznetsova A, 2020, INT J COMPUT VISION, V128, P1956, DOI 10.1007/s11263-020-01316-z.
   Lechner AM, 2020, ONE EARTH, V2, P405, DOI 10.1016/j.oneear.2020.05.001.
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1\_48.
   Lines ER, 2022, Arxiv, DOI {[}arXiv:2212.09937, 10.48550/arXiv.2212.09937, DOI 10.48550/ARXIV.2212.09937].
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0\_2.
   Lopatin J, 2019, REMOTE SENS ECOL CON, V5, P302, DOI 10.1002/rse2.109.
   Lumnitz S, 2021, ISPRS J PHOTOGRAMM, V175, P144, DOI 10.1016/j.isprsjprs.2021.01.016.
   Natesan S., 2019, INT ARCH PHOTOGRAMME, V4213, P475, DOI {[}DOI 10.5194/ISPRS-ARCHIVES-XLII-2-W13-475-2019, 10.5194/isprs-archives-XLII-2-W13-475-2019].
   Neuner S, 2015, GLOBAL CHANGE BIOL, V21, P935, DOI 10.1111/gcb.12751.
   Onishi M, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-79653-9.
   Osco LP, 2020, ISPRS J PHOTOGRAMM, V160, P97, DOI 10.1016/j.isprsjprs.2019.12.010.
   Parvathi S, 2021, BIOSYST ENG, V202, P119, DOI 10.1016/j.biosystemseng.2020.12.002.
   Pearse GD, 2020, ISPRS J PHOTOGRAMM, V168, P156, DOI 10.1016/j.isprsjprs.2020.08.005.
   Plesoianu AI, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12152426.
   Puliti S, 2022, INT J APPL EARTH OBS, V112, DOI 10.1016/j.jag.2022.102946.
   Randin CF, 2020, REMOTE SENS ENVIRON, V239, DOI 10.1016/j.rse.2019.111626.
   Redmon J., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.91.
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031.
   Rigling A, 2015, FOREST REPORT 2015: CONDITION AND USE OF SWISS FORESTS, P1.
   Sandric I, 2022, GEOCARTO INT, V37, P10459, DOI 10.1080/10106049.2022.2036824.
   Schiefer F, 2020, ISPRS J PHOTOGRAMM, V170, P205, DOI 10.1016/j.isprsjprs.2020.10.015.
   Shang X, 2014, IEEE J-STARS, V7, P2481, DOI 10.1109/JSTARS.2013.2282166.
   Sylvain JD, 2019, ISPRS J PHOTOGRAMM, V156, P14, DOI 10.1016/j.isprsjprs.2019.07.010.
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324.
   Waser LT, 2021, ISPRS J PHOTOGRAMM, V180, P209, DOI 10.1016/j.isprsjprs.2021.08.017.
   Weinstein B, 2021, ELIFE, V10, DOI 10.7554/eLife.62922.
   Weinstein B, 2020, ECOL INFORM, V56, DOI 10.1016/j.ecoinf.2020.101061.
   Weinstein BG, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111309.
   WSL Swiss National Forest Inventory (NFI), DATA SURV 2009 2017.
   Xu M., 2019, PROC CVPR IEEE, V3, P5.
   Yan SJ, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13030479.
   Yu Li, 2021, 2021 IEEE 6th International Conference on Signal and Image Processing (ICSIP), P28, DOI 10.1109/ICSIP52628.2021.9688693.
   Zamboni P, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13132482.
   Zhang C, 2020, ISPRS J PHOTOGRAMM, V169, P280, DOI 10.1016/j.isprsjprs.2020.09.025.
   Zhang C, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14040874.},
Number-of-Cited-References = {70},
Times-Cited = {0},
Usage-Count-Last-180-days = {11},
Usage-Count-Since-2013 = {11},
Journal-ISO = {Remote Sens.},
Doc-Delivery-Number = {9V0EJ},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000948074500001},
OA = {Green Published, gold},
DA = {2023-08-12},
}

@article{ WOS:000255410100015,
Author = {Yovel, Yossi and Franz, Matthias Otto and Stilz, Peter and Schnitzler,
   Hans-Ulrich},
Title = {Plant classification from bat-like echolocation signals},
Journal = {PLOS COMPUTATIONAL BIOLOGY},
Year = {2008},
Volume = {4},
Number = {3},
Month = {MAR},
Abstract = {Classification of plants according to their echoes is an elementary
   component of bat behavior that plays an important role in spatial
   orientation and food acquisition. Vegetation echoes are, however, highly
   complex stochastic signals: from an acoustical point of view, a plant
   can be thought of as a three-dimensional array of leaves reflecting the
   emitted bat call. The received echo is therefore a superposition of many
   reflections. In this work we suggest that the classification of these
   echoes might not be such a troublesome routine for bats as formerly
   thought. We present a rather simple approach to classifying signals from
   a large database of plant echoes that were created by ensonifying plants
   with a frequency-modulated bat-like ultrasonic pulse. Our algorithm uses
   the spectrogram of a single echo from which it only uses features that
   are undoubtedly accessible to bats. We used a standard machine learning
   algorithm ( SVM) to automatically extract suitable linear combinations
   of time and frequency cues from the spectrograms such that
   classification with high accuracy is enabled. This demonstrates that
   ultrasonic echoes are highly informative about the species membership of
   an ensonified plant, and that this information can be extracted with
   rather simple, biologically plausible analysis. Thus, our findings
   provide a new explanatory basis for the poorly understood observed
   abilities of bats in classifying vegetation and other complex objects.},
Publisher = {PUBLIC LIBRARY SCIENCE},
Address = {1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA},
Type = {Article},
Language = {English},
Affiliation = {Yovel, Y (Corresponding Author), Univ Tubingen, Inst Zool, Tubingen, Germany.
   Yovel, Yossi; Stilz, Peter; Schnitzler, Hans-Ulrich, Univ Tubingen, Inst Zool, Tubingen, Germany.
   Franz, Matthias Otto, Max Planck Inst Biol Cybernet, Tubingen, Germany.},
DOI = {10.1371/journal.pcbi.1000032},
Article-Number = {e1000032},
EISSN = {1553-7358},
Keywords-Plus = {SONAR; OBJECT; RECOGNITION; OLFACTION; BEHAVIOR; TARGETS; FRUIT},
Research-Areas = {Biochemistry \& Molecular Biology; Mathematical \& Computational Biology},
Web-of-Science-Categories  = {Biochemical Research Methods; Mathematical \& Computational Biology},
Author-Email = {yossiyovel@hotmail.com},
Affiliations = {CIVIS; Eberhard Karls University of Tubingen; Max Planck Society},
ResearcherID-Numbers = {mosbah, mohd rizar/N-2825-2016
   Pillay, Sesharam/E-8068-2010
   Raleva, Sofiya/A-3114-2011
   Yousfi, Mohamed/A-5754-2012
   Randall, Vance/C-9387-2009
   },
ORCID-Numbers = {Yousfi, Mohamed/0000-0003-4831-8635
   Franz, Matthias/0000-0003-3789-8849
   Yovel, Yossi/0000-0001-5429-9245},
Cited-References = {Cristianini N., 2000, INTRO SUPPORT VECTOR, V1st ed., P93, DOI DOI 10.1017/CBO9780511801389.
   DROR IE, 1995, NEURAL NETWORKS, V8, P149, DOI 10.1016/0893-6080(94)00057-S.
   Fergus R., 2003, P IEEE C COMP VIS PA.
   Firzlaff U, 2007, PLOS BIOL, V5, P1174, DOI 10.1371/journal.pbio.0050100.
   Ghose K, 2003, J ACOUST SOC AM, V114, P1120, DOI 10.1121/1.1589754.
   Graf ABA, 2006, NEURAL COMPUT, V18, P143, DOI 10.1162/089976606774841611.
   Griffiths TD, 2004, NAT REV NEUROSCI, V5, P887, DOI 10.1038/nrn1538.
   Grunwald JE, 2004, P NATL ACAD SCI USA, V101, P5670, DOI 10.1073/pnas.0308029101.
   Kalko EKV, 1998, FUNCT ECOL, V12, P364, DOI 10.1046/j.1365-2435.1998.00198.x.
   Kao G, 2000, INT J ROBOT RES, V19, P895, DOI 10.1177/02783640022067850.
   Kuc R, 1997, J ACOUST SOC AM, V102, P689, DOI 10.1121/1.419658.
   McKerrow P, 2001, IEEE SENS J, V1, P245, DOI 10.1109/7361.983464.
   Moss CF, 1995, {*}{*}NON-TRADITIONAL{*}{*}, P87.
   Muller R, 2000, J ACOUST SOC AM, V108, P836, DOI 10.1121/1.429617.
   Muller R, 2003, NETWORK-COMP NEURAL, V14, P595, DOI 10.1088/0954-898X/14/3/311.
   Nabout A., 1994, Proceedings of the IEEE Southwest Symposium on Image Analysis and Interpretation, P48, DOI 10.1109/IAI.1994.336686.
   OSWAL J, 1988, ANIMAL SONAR SYSTEMS, P413.
   PRESS WH, 2002, NUMERICAL RECIPES C, P547.
   Schaub A, 2007, J COMP PHYSIOL A, V193, P1185, DOI 10.1007/s00359-007-0269-z.
   Schaub A, 2007, BEHAV ECOL SOCIOBIOL, V61, P513, DOI 10.1007/s00265-006-0279-9.
   SCHMIDT S, 1992, J ACOUST SOC AM, V91, P2203, DOI 10.1121/1.403654.
   Schnitzler HU, 2003, TRENDS ECOL EVOL, V18, P386, DOI 10.1016/S0169-5347(03)00185-X.
   SCHOLKOPF B, 2002, LEARNING KERNELS SUP, P189.
   Simmons JA, 1998, P NATL ACAD SCI USA, V95, P12647, DOI 10.1073/pnas.95.21.12647.
   SKOLNIK MI, 1970, RADAR HDB, P50.
   Thies W, 1998, BEHAV ECOL SOCIOBIOL, V42, P397, DOI 10.1007/s002650050454.
   von Helversen D, 2004, J COMP PHYSIOL A, V190, P515, DOI 10.1007/s00359-004-0492-9.
   von Helversen D, 2003, J COMP PHYSIOL A, V189, P327, DOI 10.1007/s00359-003-0405-3.
   von Helversen D, 1999, NATURE, V398, P759, DOI 10.1038/19648.
   Wichmann F. A., 2005, ADV NEURAL INFORM PR, P1489.},
Number-of-Cited-References = {30},
Times-Cited = {57},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {15},
Journal-ISO = {PLoS Comput. Biol.},
Doc-Delivery-Number = {294MM},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000255410100015},
OA = {gold, Green Published, Green Submitted},
DA = {2023-08-12},
}

@article{ WOS:000347753600017,
Author = {Zhao, Zhong-Qiu and Ma, Lin-Hai and Cheung, Yiu-ming and Wu, Xindong and
   Tang, Yuanyan and Chen, Chun Lung Philip},
Title = {ApLeaf: An efficient android-based plant leaf identification system},
Journal = {NEUROCOMPUTING},
Year = {2015},
Volume = {151},
Number = {3},
Pages = {1112-1119},
Month = {MAR 3},
Abstract = {To automatically identify plant species is very useful for ecologists,
   amateur botanists, educators, and so on. The Leafsnap is the first
   successful mobile application system which tackles this problem.
   However, the Leafsnap is based on the IOS platform. And to the best of
   our knowledge, as the mobile operation system, the Android is more
   popular than the IOS. In this paper, an Android-based mobile application
   designed to automatically identify plant species according to the
   photographs of tree leaves is described. In this application, one leaf
   image can be either a digital image from one existing leaf image
   database or a picture collected by a camera. The picture should be a
   single leaf placed on a light and untextured background without other
   clutter. The identification process consists of three steps: leaf image
   segmentation, feature extraction, and species identification. The demo
   system is evaluated on the ImageCLEF2012 Plant Identification database
   which contains 126 tree species from the French Mediterranean area. The
   outputs of the system to users are the top several species which match
   the query leaf image the best, as well as the textual descriptions and
   additional images about plant leaves, flowers, etc. Our system works
   well with state-of-the-art identification performance. (C) 2014 Elsevier
   B.V. All rights reserved.},
Publisher = {ELSEVIER},
Address = {RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Zhao, ZQ (Corresponding Author), Hefei Univ Technol, Coll Comp Sci \& Informat Engn, Hefei 230009, Peoples R China.
   Zhao, Zhong-Qiu; Ma, Lin-Hai; Wu, Xindong, Hefei Univ Technol, Coll Comp Sci \& Informat Engn, Hefei 230009, Peoples R China.
   Zhao, Zhong-Qiu; Cheung, Yiu-ming, Hong Kong Baptist Univ, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.
   Cheung, Yiu-ming, Hong Kong Baptist Univ, Beijing Normal Univ, United Int Coll, Hong Kong, Hong Kong, Peoples R China.
   Wu, Xindong, Univ Vermont, Dept Comp Sci, Burlington, VT 05405 USA.
   Tang, Yuanyan; Chen, Chun Lung Philip, Univ Macau, Fac Sci \& Technol, Macau, Peoples R China.},
DOI = {10.1016/j.neucom.2014.02.077},
ISSN = {0925-2312},
EISSN = {1872-8286},
Keywords = {Android application; Image retrieval; Plant identification; Feature
   fusion},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence},
Affiliations = {Hefei University of Technology; Hong Kong Baptist University; Beijing
   Normal University; Beijing Normal University - Hong Kong Baptist
   University United International College; Hong Kong Baptist University;
   University of Vermont; University of Macau},
ResearcherID-Numbers = {Chen, C. L. Philip/O-2657-2016
   Wu, Xindong/AAB-6713-2022
   Cheung, Yiu-ming/E-2050-2015},
ORCID-Numbers = {Chen, C. L. Philip/0000-0001-5451-7230
   Wu, Xindong/0000-0003-2396-1704
   Cheung, Yiu-ming/0000-0001-7629-4648},
Funding-Acknowledgement = {National Natural Science Foundation of China {[}61375047, 61005007,
   61273297, 61272366, 61175121]; 973 Program of China {[}2013CB329604];
   863 Program of China {[}2012AA011005]; Hong Kong Scholars Program
   {[}XJ2012012]; Program for Changjiang Scholars and Innovative Research
   Team in University (PCSIRT) of the Ministry of Education, China
   {[}IRT13059]; National Science Foundation of Fujian Province
   {[}2013J06014]; China Postdoctoral Science Foundation {[}2013M540510];
   Hong Kong Baptist University {[}FRG2/12-13/082]; SRF for ROCS, SEM},
Funding-Text = {This research was supported by the National Natural Science Foundation
   of China (Nos. 61375047, 61005007, 61273297, 61272366 and 61175121), the
   973 Program of China (No. 2013CB329604), the 863 Program of China (No.
   2012AA011005), the Hong Kong Scholars Program (No. XJ2012012), the
   Program for Changjiang Scholars and Innovative Research Team in
   University (PCSIRT) of the Ministry of Education, China (No. IRT13059),
   the grant of the National Science Foundation of Fujian Province (No.
   2013J06014), China Postdoctoral Science Foundation (No. 2013M540510),
   the Faculty Research Grant of Hong Kong Baptist University under
   Projects FRG2/12-13/082, and the Project-sponsored by SRF for ROCS, SEM.},
Cited-References = {Aggarwal A, 2009, LECT NOTES COMPUT SC, V5687, P15, DOI 10.1007/978-3-642-03685-9\_2.
   {[}Anonymous], 1995, STORAGE RETRIEVAL IM, DOI {[}10.1117/12.205308, DOI 10.1117/12.205308].
   Berrin Y.A., 2012, IMAGECLEF 2012.
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340.
   Burrus C.S., INTRO WAVELETS WAVEL, P23.
   Goeau H., 2012, IMAGECLEF 2012.
   Gurchan E., DIGITAL IMAGE PROCES.
   HARALICK RM, 1985, COMPUT VISION GRAPH, V29, P100, DOI 10.1016/S0734-189X(85)90153-7.
   Hermes T., 1995, P 1995 C CTR ADV STU, P30.
   Kumar N, 2012, LECT NOTES COMPUT SC, V7573, P502, DOI 10.1007/978-3-642-33709-3\_36.
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012.
   Ma JQ, 2009, WISM: 2009 INTERNATIONAL CONFERENCE ON WEB INFORMATION SYSTEMS AND MINING, PROCEEDINGS, P61, DOI 10.1109/WISM.2009.20.
   Manay S, 2006, IEEE T PATTERN ANAL, V28, P1602, DOI 10.1109/TPAMI.2006.208.
   Peng Z., 2012, IMAGECLEF2012.
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413.
   Wang M, 2012, IEEE T IMAGE PROCESS, V21, P4649, DOI 10.1109/TIP.2012.2207397.
   Wang XF, 2010, PATTERN RECOGN, V43, P603, DOI 10.1016/j.patcog.2009.08.002.
   Zhao ZQ, 2009, IEEE MULTIMEDIA, V16, P34, DOI {[}10.1109/MMUL.2009.99, 10.1109/MMUL.2009.62].
   Zhao ZQ, 2004, PATTERN RECOGN LETT, V25, P1351, DOI 10.1016/j.patrec.2004.05.008.
   Zhi-Chun Huang, 2010, 2010 International Conference on Machine Learning and Cybernetics (ICMLC 2010), P719, DOI 10.1109/ICMLC.2010.5580566.},
Number-of-Cited-References = {20},
Times-Cited = {52},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {69},
Journal-ISO = {Neurocomputing},
Doc-Delivery-Number = {AY7QG},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000347753600017},
DA = {2023-08-12},
}

@article{ WOS:000792783600001,
Author = {Wu, Tsan-Yu and Yeh, Kuan-Ting and Hsu, Hao-Chun and Yang, Chih-Kai and
   Tsai, Ming-Jer and Kuo, Yan-Fu},
Title = {Identifying Fagaceae and Lauraceae species using leaf images and
   convolutional neural networks},
Journal = {ECOLOGICAL INFORMATICS},
Year = {2022},
Volume = {68},
Month = {MAY},
Abstract = {Lauraceae and Fagaceae are two large woody plant families that are
   predominant in the low-and middle-altitude regions in Taiwan. The highly
   interspecific similarity between some species of the family brings
   limitations on the management and utilization. This work proposed an
   approach for identifying 15 Lauraceae species and 20 Fagaceae species
   using leaf images and convolutional neural networks (CNNs). Leaf
   specimens of 35 species were collected from the northern, central, and
   southern parts of Taiwan. Images of the leaves were acquired using
   flatbed scanners. Three CNN architectures-DenseNet-121, MobileNet V2,
   and Xception-were trained. Xception achieved the highest mean test
   accuracy of 99.39\%, and MobileNet V2 required the shortest mean test
   time of 17.1 ms per image using a GPU. The saliency maps revealed that
   the characteristics learned by models matched the leaf features used by
   botanists. A pruning algorithm, gate decorator, was applied to the
   trained models for reducing the number of parameters and number of
   floating-point operations of the MobileNet V2 by 55.4\% and 69.1\%,
   respectively, while the model accuracy was maintained at 92.03\%. Thus,
   MobileNet V2 has the potential to be used for identifying the Lauraceae
   and Fagaceae species on mobile devices.},
Publisher = {ELSEVIER},
Address = {RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Kuo, YF (Corresponding Author), Natl Taiwan Univ, Dept Biomechatron Engn, 1,Sect 4,Roosevelt Rd, Taipei 106, Taiwan.
   Wu, Tsan-Yu; Yeh, Kuan-Ting; Hsu, Hao-Chun; Kuo, Yan-Fu, Natl Taiwan Univ, Dept Biomechatron Engn, 1,Sect 4,Roosevelt Rd, Taipei 106, Taiwan.
   Yang, Chih-Kai; Tsai, Ming-Jer, Natl Taiwan Univ, Coll Bioresources \& Agr, Expt Forest, Nantou, Taiwan.
   Yang, Chih-Kai, Natl Pingtung Univ Sci \& Technol, Dept Forestry, Pingtung, Taiwan.
   Tsai, Ming-Jer, Natl Taiwan Univ, Sch Forestry \& Resource Conservat, Taipei, Taiwan.},
DOI = {10.1016/j.ecoinf.2021.101513},
Article-Number = {101513},
ISSN = {1574-9541},
EISSN = {1878-0512},
Keywords = {Plant identification; Deep learning; Leaf morphology; Pruning; Saliency
   map},
Keywords-Plus = {IDENTIFICATION; TAIWAN; NRDNA},
Research-Areas = {Environmental Sciences \& Ecology},
Web-of-Science-Categories  = {Ecology},
Author-Email = {ykuo@ntu.edu.tw},
Affiliations = {National Taiwan University; National Taiwan University; National
   Pingtung University Science \& Technology; National Taiwan University},
ORCID-Numbers = {Hsu, Hao-Chun/0000-0003-0134-0288
   Kuo, Yan-Fu/0000-0002-5886-5643},
Funding-Acknowledgement = {Ministry of Science and Technology, Taiwan {[}107-2313-B-002-013-MY3]},
Funding-Text = {Funding This work was supported by the Ministry of Science and
   Technology, Taiwan {[}grant number 107-2313-B-002-013-MY3] .},
Cited-References = {Backes AR, 2009, INT J PATTERN RECOGN, V23, P1145, DOI 10.1142/S0218001409007508.
   Balasaravanan T, 2006, SILVAE GENET, V55, P119, DOI 10.1515/sg-2006-0017.
   Byng JW, 2016, BOT J LINN SOC, V181, P1, DOI 10.1111/boj.12385.
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195.
   De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z.
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848.
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409.
   Endemic Species Research Institute, 2017, RED LIST VASC PLANTS.
   Fukushima K., 1982, COMPETITION COOPERAT, P267, DOI DOI 10.1007/978-3-642-46466-9\_18.
   Ghazi MM, 2017, NEUROCOMPUTING, V235, P228, DOI 10.1016/j.neucom.2017.01.018.
   Han S, 2015, ADV NEUR IN, V28.
   Hossain J., 2010, Proceedings of the 13th International Conference on Computer and Information Technology (ICCIT 2010), P458, DOI 10.1109/ICCITECHN.2010.5723901.
   Hsieh C.F., 1997, TROPICS, V6, P361.
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243.
   Hwang MH, 2002, URSUS, V13, P111.
   IPNI, 2021, CANEPHORA CAPITATA W.
   Jaderberg M., 2014, PREPRINT.
   Joly A, 2015, LECT NOTES COMPUT SC, V9283, P462, DOI 10.1007/978-3-319-24027-5\_46.
   Khan A, 2003, DIABETES CARE, V26, P3215, DOI 10.2337/diacare.26.12.3215.
   Kingma D. P., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1412.6980.
   Kondo K, 2007, BIOL PHARM BULL, V30, P1497, DOI 10.1248/bpb.30.1497.
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386.
   Kuo CC, 2003, J MAMMAL, V84, P1330, DOI 10.1644/BOS-039.
   LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9, DOI 10.1007/3-540-49430-8\_2.
   Lee C., Q J FOR RES, V37, P69.
   Lee CH, 2019, T ASABE, V62, P1055, DOI 10.13031/trans.13302.
   Lee HJ, 2006, J ETHNOPHARMACOL, V103, P208, DOI 10.1016/j.jep.2005.08.009.
   Lee S, 2017, 24TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2017), DOI {[}10.1016/j.patcog.2017.05.015, 10.14722/ndss.2017.23457].
   Lee SH, 2015, IEEE IMAGE PROC, P452, DOI 10.1109/ICIP.2015.7350839.
   Lin CT, 2007, PHARM BIOL, V45, P638, DOI 10.1080/13880200701538708.
   Lin CT, 2017, BOT STUD, V58, DOI 10.1186/s40529-017-0206-6.
   Musarella CM, 2018, PHYTOKEYS, P79, DOI 10.3897/phytokeys.113.30330.
   Pang XH, 2011, CLADISTICS, V27, P165, DOI 10.1111/j.1096-0031.2010.00328.x.
   Paszke A., 2017, P NIPS W.
   POWO, 2021, PLANTS WORLD ONL.
   Ren BQ, 2010, MOL ECOL RESOUR, V10, P594, DOI 10.1111/j.1755-0998.2009.02815.x.
   ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586.
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4\_28.
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474.
   Schroeder C.A., 1976, CALIF AVOCADO SOC YB, V59, P30.
   Simonyan K., 2014, PROC WORKSHOP ICLR.
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556.
   Singh K., 2019, INT J SIGNAL PROCESS, V3, P67.
   Stevens P.F., 2001, ANGIOSPERM PHYLOGENY.
   Sun Y, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/7361042.
   Szegedy C., 2015, CVPR, P1, DOI {[}10.1109/CVPR.2015.7298594, DOI 10.1109/CVPR.2015.7298594].
   Umachigi SP, 2008, TROP J PHARM RES, V7, P913.
   Wang Wei-gang, 2007, Forestry Studies in China, V9, P132, DOI 10.1007/s11632-007-0020-4.
   Yang HW, 2019, COMPUT ELECTRON AGR, V162, P739, DOI 10.1016/j.compag.2019.05.003.
   You Z., 2019, ADV NEURAL INFORM PR, P2133.
   Yu XJ, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11101255.
   Zhang C., 2016, ARXIV161103530.
   Zhao C., 2019, PROC IEEE C COMPUT V, P2780.
   Zhou A., 2017, PREPRINT.
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907.},
Number-of-Cited-References = {55},
Times-Cited = {3},
Usage-Count-Last-180-days = {5},
Usage-Count-Since-2013 = {12},
Journal-ISO = {Ecol. Inform.},
Doc-Delivery-Number = {1B9XO},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000792783600001},
DA = {2023-08-12},
}

@article{ WOS:000575968000001,
Author = {Yan, Shuai and Yue, Yinzi and Su, Lianlin and Hao, Min and Wang,
   Xiaopeng and Zuo, Ting},
Title = {Development of Electrochemical Oscillation Method for Identification
   ofPrunus persica, Prunus davidiana, andPrunus armeniacaNuts},
Journal = {FRONTIERS IN CHEMISTRY},
Year = {2020},
Volume = {8},
Month = {SEP 11},
Abstract = {In this work, an electrochemical oscillation system has been developed
   using the Belousov-Zhabotinsky reaction. The effect of the combination
   of each reagent, reaction temperature, and stirring speed on the
   induction period, oscillating period, and oscillating life were
   optimized. The nuts ofPrunus persica, Prunus davidiana, andPrunus
   armeniacahave been widely used for medical purposes. The proposed
   electrochemical oscillation system was then used for the identification
   ofP. persica, P. davidiana, andP. armeniaca. Three nuts exhibited very
   different electrochemical oscillation profiles. The dendrogram was
   divided into three main principal infrageneric clades. Each cluster only
   contains one species, suggesting that no outlier was observed in this
   study. Based on the discussed results, we proposed a simple method for
   herbal medicine identification.},
Publisher = {FRONTIERS MEDIA SA},
Address = {AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND},
Type = {Article},
Language = {English},
Affiliation = {Wang, XP (Corresponding Author), Nanjing Univ Chinese Med, Suzhou TCM Hosp, Suzhou, Peoples R China.
   Zuo, T (Corresponding Author), Henan Univ Chinese Med, Sch Pharm, Zhengzhou, Peoples R China.
   Yan, Shuai; Yue, Yinzi; Wang, Xiaopeng, Nanjing Univ Chinese Med, Suzhou TCM Hosp, Suzhou, Peoples R China.
   Su, Lianlin, Nanjing Univ Chinese Med, Sch Pharm, Nanjing, Peoples R China.
   Hao, Min, Zhejiang Chinese Med Univ, Sch Pharm, Hangzhou, Peoples R China.
   Zuo, Ting, Henan Univ Chinese Med, Sch Pharm, Zhengzhou, Peoples R China.},
DOI = {10.3389/fchem.2020.00748},
Article-Number = {748},
ISSN = {2296-2646},
Keywords = {electrochemical oscillation; Belousov-Zhabotinsky; plant identification;
   herbal medicine; Prunusspp},
Keywords-Plus = {POTENTIAL OSCILLATION; CHROMATOGRAPHIC FINGERPRINTS;
   LIQUID-CHROMATOGRAPHY; PATTERN-RECOGNITION; RATIONAL APPROACH; QUALITY;
   AUTHENTICATION; MEDICINES; PLANTS},
Research-Areas = {Chemistry},
Web-of-Science-Categories  = {Chemistry, Multidisciplinary},
Author-Email = {wxpeng2004@163.com
   381165010@qq.com},
Affiliations = {Nanjing University of Chinese Medicine; Nanjing University of Chinese
   Medicine; Zhejiang Chinese Medical University; Henan University of
   Traditional Chinese Medicine},
Funding-Acknowledgement = {Natural Science Foundation of Jiangsu Province {[}BK20180219]; National
   Natural Science Foundation of China {[}81804098]; Jiangsu Youth Medical
   Talents Project {[}QNRC2016255]; Macao Young Scholars Program
   {[}AM2020020]},
Funding-Text = {This work was funded by Natural Science Foundation of Jiangsu Province
   (BK20180219), National Natural Science Foundation of China (81804098),
   Jiangsu Youth Medical Talents Project (QNRC2016255), and Macao Young
   Scholars Program (AM2020020).},
Cited-References = {Afshar S, 2020, J PHARMACEUT BIOMED, V188, DOI 10.1016/j.jpba.2020.113393.
   Alfifi HY, 2016, J MATH CHEM, V54, P1632, DOI 10.1007/s10910-016-0641-8.
   Aliakbarzadeh G, 2016, ANAL BIOANAL CHEM, V408, P3295, DOI 10.1007/s00216-016-9400-8.
   Bai H, 2017, J ELECTROCHEM SOC, V164, pE78, DOI 10.1149/2.1241704jes.
   Chan PF, 2019, J ELECTROCHEM SOC, V166, pD891, DOI 10.1149/2.1181914jes.
   Chen DD, 2017, J CHIN MED ASSOC, V80, P288, DOI 10.1016/j.jcma.2016.11.009.
   Cui YL, 2019, FOOD CHEM, V293, P144, DOI 10.1016/j.foodchem.2019.04.101.
   Custers D, 2017, TALANTA, V164, P490, DOI 10.1016/j.talanta.2016.12.008.
   Dai TT, 2019, MICROCHEM J, V150, DOI 10.1016/j.microc.2019.104175.
   Deconinck E, 2017, TALANTA, V170, P441, DOI 10.1016/j.talanta.2017.04.028.
   Devi GK, 2017, MICROB PATHOGENESIS, V102, P120, DOI 10.1016/j.micpath.2016.11.026.
   Ding LF, 2019, INT J ELECTROCHEM SC, V14, P585, DOI 10.20964/2019.01.63.
   Donno D, 2016, J FOOD SCI TECH MYS, V53, P1071, DOI 10.1007/s13197-015-2115-6.
   Esteki M, 2019, FOOD RES INT, V122, P303, DOI 10.1016/j.foodres.2019.04.025.
   Flores IS, 2020, FITOTERAPIA, V142, DOI 10.1016/j.fitote.2020.104500.
   Fouladgar M, 2020, J MOL LIQ, V311, DOI 10.1016/j.molliq.2020.113314.
   Fu L, 2020, BIOSENS BIOELECTRON, V159, DOI 10.1016/j.bios.2020.112212.
   Fu L, 2019, SENSOR ACTUAT B-CHEM, V298, DOI 10.1016/j.snb.2019.126836.
   Gan ZL, 2016, J CHROMATOGR B, V1011, P99, DOI 10.1016/j.jchromb.2015.12.051.
   Hou ZF, 2019, J CHROMATOGR B, V1133, DOI 10.1016/j.jchromb.2019.121827.
   Huang YL, 2019, J ANAL APPL PYROL, V137, P70, DOI 10.1016/j.jaap.2018.11.011.
   Jin JZ, 2017, J CHEM SOC PAKISTAN, V39, P947.
   Karimi-Maleh H, 2020, J MOL LIQ, V314, DOI 10.1016/j.molliq.2020.113588.
   Karimi-Maleh H, 2020, MATER CHEM PHYS, V250, DOI 10.1016/j.matchemphys.2020.123042.
   Karimi-Maleh H, 2020, J MOL LIQ, V310, DOI 10.1016/j.molliq.2020.113185.
   Kharbach M, 2020, J PHARMACEUT BIOMED, V177, DOI 10.1016/j.jpba.2019.112849.
   Li T, 2016, ACTA PHARM SIN B, V6, P148, DOI 10.1016/j.apsb.2016.01.001.
   Li Y, 2020, J PHARMACEUT BIOMED, V185, DOI 10.1016/j.jpba.2020.113215.
   Sibug-Torres SM, 2019, ANAL METHODS-UK, V11, P721, DOI {[}10.1039/c8ay02698j, 10.1039/C8AY02698J].
   Miyazaki K, 2016, J APPL ELECTROCHEM, V46, P1067, DOI 10.1007/s10800-016-0987-4.
   Mohanraj J, 2020, J COLLOID INTERF SCI, V566, P463, DOI 10.1016/j.jcis.2020.01.089.
   Mohtashami S, 2018, IND CROP PROD, V111, P226, DOI 10.1016/j.indcrop.2017.09.055.
   Mukouyama Y, 2017, J ELECTROCHEM SOC, V164, pH1, DOI 10.1149/2.0011702jes.
   Nawabi MY, 2019, INT J ELECTROCHEM SC, V14, P8676, DOI 10.20964/2019.09.08.
   Maia LFO, 2019, J ANAL CHEM+, V74, P1232, DOI 10.1134/S1061934819120074.
   Pawar RS, 2017, PLANTA MED, V83, P921, DOI 10.1055/s-0043-107881.
   Peng H, 2017, J ELECTROCHEM SCI EN, V7, P139, DOI 10.5599/jese.406.
   Selvakumari E, 2017, J ACAD IND RES, V5, P149.
   Shekari N, 2018, FORENSIC SCI INT, V286, P213, DOI 10.1016/j.forsciint.2018.03.022.
   Sibug-Torres SM, 2019, ANAL METHODS-UK, V11, P5511, DOI {[}10.1039/c9ay01714c, 10.1039/C9AY01714C].
   Sun LL, 2018, J PHARMACEUT BIOMED, V160, P323, DOI 10.1016/j.jpba.2018.08.003.
   Sun YP, 2019, CURR PHARM ANAL, V15, P456, DOI 10.2174/1573412914666180716143939.
   Szeremeta D, 2017, J LIQ CHROMATOGR R T, V40, P304, DOI 10.1080/10826076.2017.1298033.
   Tavana T, 2020, J PHARMACEUT BIOMED, V189, DOI 10.1016/j.jpba.2020.113397.
   Ullah S, 2019, INT J ELECTROCHEM SC, V14, P5563, DOI 10.20964/2019.06.07.
   Wang CX, 2020, EUR FOOD RES TECHNOL, V246, P795, DOI 10.1007/s00217-020-03446-7.
   Wang Y., 2017, CHIN J EXP TRADIT ME, V2017, P14, DOI {[}10.1186/s13020-018-0171-3, DOI 10.1186/S13020-018-0171-3].
   Xie PS, 2006, J CHROMATOGR A, V1112, P171, DOI 10.1016/j.chroma.2005.12.091.
   Xu YT, 2020, BIOELECTROCHEMISTRY, V133, DOI 10.1016/j.bioelechem.2020.107455.
   Xue YD, 2017, CHEM CENT J, V11, DOI 10.1186/s13065-017-0299-8.
   Yang YY, 2016, TRAC-TREND ANAL CHEM, V82, P68, DOI 10.1016/j.trac.2016.04.011.
   Ying J, 2020, REV MEX ING QUIM, V19, P585, DOI 10.24275/rmiq/Mat741.
   Zabihpour T, 2020, MICROCHEM J, V154, DOI 10.1016/j.microc.2019.104572.
   Zhou H, 2020, ELECTROCHIM ACTA, V337, DOI 10.1016/j.electacta.2020.135798.
   Zhu CS, 2016, CHIN J NAT MEDICINES, V14, P177, DOI 10.1016/S1875-5364(16)30014-0.},
Number-of-Cited-References = {55},
Times-Cited = {5},
Usage-Count-Last-180-days = {4},
Usage-Count-Since-2013 = {17},
Journal-ISO = {Front. Chem.},
Doc-Delivery-Number = {NX8QG},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000575968000001},
OA = {Green Published, gold},
DA = {2023-08-12},
}

@inproceedings{ WOS:000720289000058,
Author = {Ben Atitallah, Safa and Driss, Maha and Boulila, Wadii and Koubaa, Anis
   and Atitallah, Nesrine and Ben Ghezala, Henda},
Editor = {Watrobski, J and Salabun, W and Toro, C and Zanni-Merk, C and Howlett, RJ and Jain, LC},
Title = {An Enhanced Randomly Initialized Convolutional Neural Network for
   Columnar Cactus Recognition in Unmanned Aerial Vehicle imagery},
Booktitle = {KNOWLEDGE-BASED AND INTELLIGENT INFORMATION \& ENGINEERING SYSTEMS (KSE
   2021)},
Series = {Procedia Computer Science},
Year = {2021},
Volume = {192},
Pages = {573-581},
Note = {25th KES International Conference on Knowledge-Based and Intelligent
   Information \& Engineering Systems (KES), Szczecin, POLAND, SEP 08-10,
   2021},
Organization = {KES Int},
Abstract = {Recently, Convolutional Neural Networks (CNNs) have made a great
   performance for remote sensing image classification. Plant recognition
   using CNNs is one of the active deep learning research topics due to its
   added-value in different related fields, especially environmental
   conservation and natural areas preservation. Automatic recognition of
   plants in protected areas helps in the surveillance process of these
   zones and ensures the sustainability of their ecosystems. In this work,
   we propose an Enhanced Randomly Initialized Convolutional Neural Network
   (ERI-CNN) for the recognition of columnar cactus, which is an endemic
   plant that exists in the Tehuacan-Cuicatlan Valley in southeastern
   Mexico. We used a public dataset created by a group of researchers that
   consists of more than 20000 remote sensing images. The experimental
   results confirm the effectiveness of the proposed model compared to
   other models reported in the literature like InceptionV3 and the
   modified LeNet-5 CNN. Our ERI-CNN provides 98\% of accuracy, 97\% of
   precision, 97\% of recall, 97.5\% as f1-score, and 0.056 loss. (C) 2021
   The Authors. Published by Elsevier B.V. This is an open access article
   under the CC BY-NC-ND license
   (https://crativecommons.org/licenses/by-nc-nd/4.0) Peer-review under
   responsibility of the scientific committee of KES International.},
Publisher = {ELSEVIER SCIENCE BV},
Address = {SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Ben Atitallah, S (Corresponding Author), Univ Manouba, Natl Sch Comp Sci, RIADI Lab, Manouba, Tunisia.
   Ben Atitallah, Safa; Driss, Maha; Boulila, Wadii; Ben Ghezala, Henda, Univ Manouba, Natl Sch Comp Sci, RIADI Lab, Manouba, Tunisia.
   Driss, Maha; Boulila, Wadii, Taibah Univ, Coll Comp Sci \& Engn, IS Dept, Medina, Saudi Arabia.
   Koubaa, Anis, Prince Sultan Univ, Robot \& Internet Things Lab, Riyadh, Saudi Arabia.
   Atitallah, Nesrine, Arab Open Univ, Fac Comp Studies, Riyadh, Saudi Arabia.
   Atitallah, Nesrine, Univ Sfax, Natl Engn Sch Sfax, CES Lab, Sfax, Tunisia.},
DOI = {10.1016/j.procs.2021.08.059},
ISSN = {1877-0509},
Keywords = {Convolutional neural networks; Weight initialization; Randomization;
   Remote sensing images; Recognition; Columnar cactus},
Research-Areas = {Automation \& Control Systems; Computer Science; Engineering;
   Mathematics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Computer Science, Information Systems; Computer Science,
   Theory \& Methods; Engineering, Electrical \& Electronic; Mathematics,
   Applied},
Author-Email = {safa.benatitallah@ensi-uma.tn},
Affiliations = {Universite de la Manouba; Taibah University; Prince Sultan University;
   Arab Open University-Saudi Arabia; Universite de Sfax; Ecole Nationale
   dIngenieurs de Sfax (ENIS)},
ResearcherID-Numbers = {Ben Atitallah, Safa/ISB-0135-2023
   Ben Ghezala, Henda Hajjami/AAK-7052-2021
   },
ORCID-Numbers = {Ben Ghezala, Henda Hajjami/0000-0002-6874-1388
   Driss, Maha/0000-0001-8236-8746
   Ben Atitallah, safa/0000-0003-0796-3507},
Cited-References = {Ben Atitallah S, 2020, COMPUT SCI REV, V38, DOI 10.1016/j.cosrev.2020.100303.
   Boulila W, 2021, COMPUT ELECTRON AGR, V182, DOI 10.1016/j.compag.2021.106014.
   Boulila W, 2017, J COMPUT SCI-NETH, V23, P58, DOI 10.1016/j.jocs.2017.10.006.
   Chebbi I, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP).
   Chi MM, 2016, P IEEE, V104, P2207, DOI 10.1109/JPROC.2016.2598228.
   Dai HN, 2020, ENTERP INF SYST-UK, V14, P1279, DOI 10.1080/17517575.2019.1633689.
   Delgado JA, 2019, FRONT SUSTAIN FOOD S, V3, DOI 10.3389/fsufs.2019.00054.
   Dudek G, 2019, LECT NOTES COMPUT SC, V11506, P517, DOI 10.1007/978-3-030-20521-8\_43.
   Ferchichi Ahlem, 2017, Vietnam Journal of Computer Science, V4, P195, DOI 10.1007/s40595-016-0088-7.
   Gallicchio C, 2020, RECENT TRENDS LEARNI, P43, DOI DOI 10.1007/978-3-030-43883-8.
   Hajjaji Y, 2021, COMPUT SCI REV, V39, DOI 10.1016/j.cosrev.2020.100318.
   Hong D., 2020, IEEE T GEOSCI ELECT, V59, P4340.
   Hu G., GEOCARTO INT, P1.
   Kattenborn T, 2020, REMOTE SENS ECOL CON, V6, P472, DOI 10.1002/rse2.146.
   Kingma D. P., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1412.6980.
   LI H, 2020, INT C APPL CRYPT NET, P127, DOI DOI 10.1016/B978-0-12-818981-8.00007-2.
   Li WJ, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9010022.
   Lopez-Jimenez E, 2019, ECOL INFORM, V52, P131, DOI 10.1016/j.ecoinf.2019.05.005.
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015.
   Meng T, 2020, INFORM FUSION, V57, P115, DOI 10.1016/j.inffus.2019.12.001.
   Mohammadi M, 2018, IEEE COMMUN SURV TUT, V20, P2923, DOI 10.1109/COMST.2018.2844341.
   Nezami S, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12071070.
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0.
   Stoyanova M, 2020, IEEE COMMUN SURV TUT, V22, P1191, DOI 10.1109/COMST.2019.2962586.
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594.
   Tian CW, 2020, NEURAL NETWORKS, V131, P251, DOI 10.1016/j.neunet.2020.07.025.
   Yuan QQ, 2020, REMOTE SENS ENVIRON, V241, DOI 10.1016/j.rse.2020.111716.
   Zechen Zheng, 2019, 2019 IEEE International Conferences on Ubiquitous Computing \& Communications (IUCC) and Data Science and Computational Intelligence (DSCI) and Smart Computing, Networking and Services (SmartCNS), P118, DOI 10.1109/IUCC/DSCI/SmartCNS.2019.00048.
   Zhu YX, 2019, NEUROCOMPUTING, V365, P191, DOI 10.1016/j.neucom.2019.07.016.
   Zou WT, 2019, IEEE ACCESS, V7, P46621, DOI 10.1109/ACCESS.2019.2907999.},
Number-of-Cited-References = {30},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {2},
Doc-Delivery-Number = {BS4LU},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000720289000058},
OA = {gold, Green Submitted},
DA = {2023-08-12},
}

@article{ WOS:000974774900009,
Author = {Greene, Alexander M. and Teixidor-Toneu, Irene and Odonne, Guillaume},
Title = {To Pick or Not to Pick: Photographic Voucher Specimens as an Alternative
   Method to Botanical Collecting in Ethnobotany},
Journal = {JOURNAL OF ETHNOBIOLOGY},
Year = {2023},
Volume = {43},
Number = {1, SI},
Pages = {44-56},
Month = {MAR},
Abstract = {The identification of plants according to the Linnaean system of
   taxonomy is a cornerstone of ethnobotany, allowing the discipline to be
   a comparative science. To accomplish plant identification,
   ethnobotanists have long relied on the collection of voucher specimens
   and their deposition in herbaria. Here we critically analyze the role of
   botanical collecting in ethnobotany and bring attention to a range of
   issues that can complicate, and sometimes hamper, the practice. In lieu
   of traditional herbarium specimens, the collection of photographic
   vouchers and their deposition in digital repositories is proposed as an
   alternative method for ethnobotanical research. The ever-improving
   quality and ubiquity of smartphone cameras, photographic citizen science
   applications like Pl@ntnet and iNaturalist, and deep learning techniques
   of automated photo identification are discussed as elements that are
   contributing to a slow revolution in the role of digital data in the
   field sciences. Guidelines for when plant herbarium specimens versus
   photographic vouchers should be considered required are laid out.
   Although botanical collecting will doubtless and with good reason remain
   a foundational practice in ethnobotany, we present the use of
   photographic vouchers as a valid, scientifically rigorous and, in some
   situations, preferred method of identification.},
Publisher = {SAGE PUBLICATIONS INC},
Address = {2455 TELLER RD, THOUSAND OAKS, CA 91320 USA},
Type = {Article},
Language = {English},
Affiliation = {Greene, AM (Corresponding Author), Ctr Natl Rech Scientif CNRS, Lab Ecol Evolut Interact Systemes Amazoniens LEEI, 275 Route Montabo, F-97334 Cayenne, France.
   Greene, Alexander M.; Odonne, Guillaume, Ctr Natl Rech Scientif CNRS, Lab Ecol Evolut Interact Systemes Amazoniens LEEI, 275 Route Montabo, F-97334 Cayenne, France.
   Greene, Alexander M., Univ Kent, Sch Anthropol \& Conservat, Ctr Biocultural Div, Canterbury, Kent, England.
   Teixidor-Toneu, Irene, Univ Oslo, Nat Hist Museum, Oslo, Norway.},
DOI = {10.1177/02780771231162190},
ISSN = {0278-0771},
EISSN = {2162-4496},
Keywords = {photographic vouchers; herbarium specimens; ethnobiology; botany;
   methods; automated identification},
Keywords-Plus = {SACRED GROVES; IDENTIFICATION; FIELD; ETHNOBIOLOGY; PLANTS},
Research-Areas = {Anthropology; Life Sciences \& Biomedicine - Other Topics},
Web-of-Science-Categories  = {Anthropology; Biology},
Author-Email = {accidentalshrike@gmail.com},
Affiliations = {University of Kent; University of Oslo},
Funding-Acknowledgement = {``Investissement d'Avenir{''} grant {[}ANR-10-LABX-25-01];
   Prime80-DiaspoREs projects from the CNRS ``Mission pour
   l'Interdisciplinarite et les Initiatives Transverses{''} (MITI)},
Funding-Text = {This work was funded by an ``Investissement d'Avenir{''} grant managed
   by the Agence Nationale de la Recherche (Labex CEBA: ANR-10-LABX-25-01)
   and by the Prime80-DiaspoREs projects from the CNRS ``Mission pour
   l'Interdisciplinarite et les Initiatives Transverses{''} (MITI).},
Cited-References = {Affouard A., 2021, BIODIVERSITY INFORM, V5, P0, DOI {[}10.3897/biss.5.73857., DOI 10.3897/BISS.5.73857].
   Agarwal G, 2006, TAXON, V55, P597, DOI 10.2307/25065637.
   Alexiades M.N., 1996, SELECTED GUIDELINES.
   Amith J., 2013, DOCUMENTATION NAHUAT.
   Andel T. van, 2007, Ethnobotany Research and Applications, V5, P351.
   {[}Anonymous], 1995, ETHNOBOTANY METHODS.
   {[}Anonymous], 2004, FIELD METHOD, DOI DOI 10.1177/1525822X04266844.
   Bhagwat S., 2010, SACRED NATURAL SITES, V1, P45, DOI DOI 10.4324/9781849776639-12/CONSERVATION-BIODIVERSITY-SACRED-NATURALSITES-ASIA-AFRICA-REVIEW-SCIENTIFIC-LITERATURE-NIGEL-DUDLEY-SHONIL-BHAGWAT-LIZA-HIGGINS-ZOGIB-BARBARA-LASSEN-BASVERSCHUUREN-ROBERT-WILD.
   Bonnet P., 2015, AUTOMATED FOREST RES, P158.
   Bonnet P, 2016, MULTIMED TOOLS APPL, V75, P1647, DOI 10.1007/s11042-015-2607-4.
   Botella C, 2018, APPL PLANT SCI, V6, DOI 10.1002/aps3.1029.
   Boumediene S, 2016, COLONISATION SAVOIR.
   Bourgeois T. le, 2012, Aliens: The Invasive Species Bulletin, P39.
   British Columbia Ministry of Forests, 1996, TECHNIQUES PROCEDURE.
   Cabalzar A., 2017, MANUAL ETNOBOTANICA.
   Canteiro C, 2019, CONSERV BIOL, V33, P523, DOI 10.1111/cobi.13291.
   Castagnetti F, 2021, FRONT SUSTAIN FOOD S, V5, DOI 10.3389/fsufs.2021.646719.
   Culley TM, 2013, APPL PLANT SCI, V1, DOI 10.3732/apps.1300076.
   Day L., 2012, AGRION, V16, P16.
   de Grenade R, 2016, AGR HUM VALUES, V33, P455, DOI 10.1007/s10460-015-9621-z.
   Deil U., 2005, SILVA CARELICA, V49, P185.
   Donegan TM, 2008, ZOOTAXA, P37, DOI 10.11646/zootaxa.1761.1.4.
   Echeverria A, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13020735.
   Fearnbach H, 2012, ECOL APPL, V22, P1689.
   Ferreira AC, 2020, METHODS ECOL EVOL, V11, P1072, DOI 10.1111/2041-210X.13436.
   Funk VA, 2017, BIODIVERS DATA J, V5, DOI 10.3897/BDJ.5.e11625.
   Funk VA, 2018, TAXON, V67, P3, DOI 10.12705/671.1.
   Gardiner LM, 2016, BOT J LINN SOC, V182, P543, DOI 10.1111/boj.12402.
   Garg A, 2013, CURR SCI INDIA, V104, P596.
   Gomez-Bellver C, 2019, TAXON, V68, P1321, DOI 10.1002/tax.12162.
   Heberling JM, 2018, APPL PLANT SCI, V6, DOI 10.1002/aps3.1193.
   Heberling JM, 2017, AM J BOT, V104, P963, DOI 10.3732/ajb.1700125.
   Heinrich M, 2019, PHYTOMEDICINE, V53, P332, DOI 10.1016/j.phymed.2018.04.061.
   Heinrich M, 2009, J ETHNOPHARMACOL, V124, P1, DOI 10.1016/j.jep.2009.03.043.
   Hickman EJ, 2017, AUST SYST BOT, V30, P291, DOI 10.1071/SB16059.
   Hunn Eugene, 2007, Journal of Ethnobiology, V27, P1, DOI 10.2993/0278-0771(2007)27{[}1:EIFP]2.0.CO;2.
   Irving J. T. W., THEATRUM BOT, P17.
   Irving J. T. W., THEATRUM BOT, P33.
   IUCN, 1989, IUCN POL STAT RES IN.
   Joly, 2017, PLANT IDENTIFICATION.
   Joly A, 2019, LECT NOTES COMPUT SC, V11696, P387, DOI 10.1007/978-3-030-28577-7\_29.
   Kasper-Pakosz R, 2016, J ETHNOBIOL ETHNOMED, V12, DOI 10.1186/s13002-016-0117-8.
   Kaur P, 2020, MED SCI LAW, V60, P131, DOI 10.1177/0025802419893168.
   Kelly MJ, 2001, J MAMMAL, V82, P440, DOI 10.1644/1545-1542(2001)082<0440:CAPMIS>2.0.CO;2.
   Kew Royal Botanic Gardens, 2021, SCI STRAT 2021 2025.
   Kiefer D. S., 2015, P NATL ACAD SCI USA, V4, P1, DOI {[}10.4172/2327-5162.1000186., DOI 10.4172/2327-5162.1000186].
   Kosterin Oleg E., 2012, Cambodian Journal of Natural History, V2, P150.
   Krell FT, 2017, INSECT SYST DIVER, V1, DOI 10.1093/isd/ixx004.
   Kulits P., 2021, ACM SIGCAS C COMPUTI, P88, DOI {[}10.1145/3460112.3471947, DOI 10.1145/3460112.3471947].
   Kury L., 2017, PORT J SOC SCI, V16.
   LaFrankie JV, 2015, APPL PLANT SCI, V3, DOI 10.3732/apps.1400116.
   Loos A, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-49.
   Luczaj LJ, 2010, J ETHNOBIOL ETHNOMED, V6, DOI 10.1186/1746-4269-6-36.
   McAlvay AC, 2021, J ETHNOBIOL, V41, P170, DOI 10.2993/0278-0771-41.2.170.
   Mesaglio T, 2021, WILDLIFE RES, V48, P289, DOI 10.1071/WR20154.
   Miller TL., 2019, PLANT KIN MULTISPECI.
   Miyazaki Y, 2014, BIODIVERS CONSERV, V23, P2383, DOI 10.1007/s10531-014-0724-4.
   Moreno-Black G., 1996, Agriculture and Human Values, V13, P3, DOI 10.1007/BF01538222.
   My Lien Thi Nguyen, 2005, Ethnobotany Research and Applications, V3, P5.
   Nabhan G. P., 2016, J ETHNOBIOL, P13.
   Nelson G, 2019, PHILOS T R SOC B, V374, DOI 10.1098/rstb.2017.0391.
   Nesbitt M, 2014, CURATING BIOCULTURAL, P313.
   Nualart N, 2017, BOT REV, V83, P303, DOI 10.1007/s12229-017-9188-z.
   Odonne G, 2021, J ETHNOPHARMACOL, V279, DOI 10.1016/j.jep.2021.114384.
   Odonne G., 2017, FLORA GUIANAS NEWSLE, V19, P51.
   Odonne G, 2013, J ETHNOPHARMACOL, V146, P127, DOI 10.1016/j.jep.2012.12.014.
   Ormsby A, 2013, CONSERV SOC, V11, P187, DOI 10.4103/0972-4923.115722.
   Otter J, 2021, J MED TOXICOL, V17, P42, DOI 10.1007/s13181-020-00803-6.
   Panyadee P, 2018, ECON BOT, V72, P1, DOI 10.1007/s12231-018-9404-8.
   Pignal M., 2013, B BIBLIOTHEQUES FRAN, V58, P27.
   Plieninger T, 2020, PEOPLE NAT, V2, P1237, DOI 10.1002/pan3.10158.
   Reisser Julia, 2008, Endangered Species Research, V5, P73, DOI 10.3354/esr00113.
   Reyes-Garcia V, 2021, J ETHNOPHARMACOL, V278, DOI 10.1016/j.jep.2021.114295.
   Sarkinen T, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0043808.
   Poot-Pool WS, 2015, ECON BOT, V69, P203, DOI 10.1007/s12231-015-9313-z.
   Schiller C, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-95616-0.
   Seregin PA, 2021, BIODIVERS DATA J, V9, DOI 10.3897/BDJ.9.e73013.
   Sullivan BL, 2014, BIOL CONSERV, V169, P31, DOI 10.1016/j.biocon.2013.11.003.
   Sun Y, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/7361042.
   TERASHIMA H, 1994, ANTHROPOL SCI, V102, P3, DOI 10.1537/ase.102.3.
   The Plant Conservation Roundtable, 1986, GUID COLL PLANTS.
   Thomas E, 2007, ECON BOT, V61, P376, DOI 10.1663/0013-0001(2007)61{[}376:WWITFA]2.0.CO;2.
   Turland NJ, 2018, REGNUM VEG, V159, P1.
   Unger J, 2016, BMC EVOL BIOL, V16, DOI 10.1186/s12862-016-0827-5.
   Uyeda KA, 2020, ENVIRON MONIT ASSESS, V192, DOI 10.1007/s10661-020-08522-9.
   Van Horn G, 2018, PROC CVPR IEEE, P8769, DOI 10.1109/CVPR.2018.00914.
   Vanderplank S., 2020, SAN BASILIO BIODIVER.
   Veldman S, 2020, J ETHNOPHARMACOL, V250, DOI 10.1016/j.jep.2019.112495.
   Verschuuren B., 2010, SACRED NATURAL SITES.
   Viveiros de Castro Eduardo, 1992, ENEMYS POINT VIEW HU.
   Voeks R, 2018, GEOGR REV, V108, P545, DOI 10.1111/gere.12291.
   Von Reis S., 1995, ETHNOBOTANY EVOLUTIO, P40.
   Waldchen J, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1005993.
   Weckerle CS, 2018, J ETHNOPHARMACOL, V210, P125, DOI 10.1016/j.jep.2017.08.018.
   Western Australia Herbarium, 2008, COLL HERB SPEC GUID.
   White S, 2006, IEEE SYMPOSIUM ON 3D USER INTERFACES 2006, PROCEEDINGS, P119, DOI 10.1109/TRIDUI.2006.1618281.
   Willis CG, 2017, TRENDS ECOL EVOL, V32, P531, DOI 10.1016/j.tree.2017.03.015.
   WinklerPrins Antoinette, 2010, Bol. Mus. Para. Emílio Goeldi. Ciênc. hum., V5, P571.
   Winterton SL, 2020, ZOOTAXA, V4816, P361, DOI 10.11646/zootaxa.4816.3.6.
   Wittmann J., 2019, CITIZEN SCI THEORY P, V4, P1, DOI {[}DOI 10.5334/CSTP.131, 10.5334/cstp.131.].
   Zucca M., 2019, REV FRANCAISE ADM PU, VN169, P195, DOI {[}10.3917/rfap.169.0195, DOI 10.3917/RFAP.169.0195].},
Number-of-Cited-References = {101},
Times-Cited = {0},
Usage-Count-Last-180-days = {3},
Usage-Count-Since-2013 = {3},
Journal-ISO = {J. Ethnobiol.},
Doc-Delivery-Number = {E3SK6},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)},
Unique-ID = {WOS:000974774900009},
OA = {hybrid},
DA = {2023-08-12},
}

@inproceedings{ WOS:000383945000126,
Author = {Kumar, V, Sathiesh and Gogul, I and Raj, Deepan M. and Pragadesh, S. K.
   and Sebastin, Sarathkumar J.},
Editor = {Mathew, J and DasKrishna, D and Jose, J},
Title = {Smart Autonomous Gardening Rover with Plant Recognition using Neural
   Networks},
Booktitle = {PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING
   AND COMMUNICATIONS},
Series = {Procedia Computer Science},
Year = {2016},
Volume = {93},
Pages = {975-981},
Note = {6th International Conference on Advances in Computing and Communications
   (ICACC), Rajagiri Sch Engn \& Technol, Kochi, INDIA, SEP 06-08, 2016},
Abstract = {Modernization of our environment (pruning trees for constructing tall
   buildings) results in climatic changes and ecological imbalance. To
   mitigate the effect, gardening (to plant trees and shrubs) becomes more
   and more important than just a hobby. Besides, maintenance of a garden
   is a tedious process and also time-consuming. Often the gardener lacks
   in knowledge about the requirements of plant (nutrient and the amount of
   water to be sprayed) to enhance its growth. In this regard, it is
   necessary to build an autonomous gardening robotic vehicle which
   automatically identifies and classifies the plant species using feature
   extraction algorithms (Scale Invariant Feature Transform (SIFT),
   Speeded-Up Robust Features (SURF), Oriented FAST and Rotated BRIEF
   (ORB)) and neural networks, respectively. It also measures the key
   parameters for gardening such as temperature, humidity, heat level, wind
   speed, wind direction and soil moisture. The data acquired from the
   on-board sensors of the gardening rover are sent to the cloud storage
   platform on a regular basis. Based on the acquired data and history,
   future predictions are made to maintain the garden more effectively and
   efficiently. A website and an android application are developed for
   monitoring and controlling the rover from a remote area. This system is
   a combination of new technologies involving an interdisciplinary
   approach to carry out precision gardening using Internet of Things
   (IoT). (C) 2016 Published by Elsevier B.V.},
Publisher = {ELSEVIER SCIENCE BV},
Address = {SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Kumar, VS (Corresponding Author), Anna Univ, Madras Inst Technol, Dept Elect Engn, Madras 600044, Tamil Nadu, India.
   Kumar, Sathiesh, V; Gogul, I; Raj, Deepan M.; Pragadesh, S. K., Anna Univ, Madras Inst Technol, Dept Elect Engn, Madras 600044, Tamil Nadu, India.
   Sebastin, Sarathkumar J., Anna Univ, Madras Inst Technol, Dept Aerosp Engn, Madras 600044, Tamil Nadu, India.},
DOI = {10.1016/j.procs.2016.07.289},
ISSN = {1877-0509},
Keywords = {Intelligent agriculture robotics; floriculture; horticulture;
   arboriculture; plant recognition methods; neural networks; Internet of
   things},
Research-Areas = {Computer Science; Engineering; Telecommunications},
Web-of-Science-Categories  = {Computer Science, Theory \& Methods; Engineering, Electrical \&
   Electronic; Telecommunications},
Author-Email = {sathiieesh@gmail.com},
Affiliations = {Anna University; Anna University Chennai; Madras Institute of
   Technology; Anna University; Anna University Chennai; Madras Institute
   of Technology},
ResearcherID-Numbers = {Kumar, Sathiesh/AAW-8609-2020
   },
ORCID-Numbers = {Kumar, Sathiesh/0000-0002-0269-2333
   Santhi Krishnamoorthy, Pragadesh/0000-0002-0300-2605},
Cited-References = {Alfredo Fernando, 2013, IEEE IND ELECTRON M, V7, p48 .
   {[}Anonymous], J INT BUSINESS STUDI.
   Askraba S, 2013, J LIGHTWAVE TECHNOL, V31, P822, DOI 10.1109/JLT.2013.2237883.
   Bolten JD, 2010, IEEE J-STARS, V3, P57, DOI 10.1109/JSTARS.2009.2037163.
   Das J, 2015, IEEE INT CON AUTO SC, P462, DOI 10.1109/CoASE.2015.7294123.
   Durmus H., 2015, 4 INT C AGR, P49.
   Fan Baojie, 2013, 7 INT C IM GRAPH ICI, p313 .
   Kone CT, 2015, IEEE SENS J, V15, P5734, DOI 10.1109/JSEN.2015.2442259.
   Shaout A, 2015, 2015 11TH INTERNATIONAL COMPUTER ENGINEERING CONFERENCE (ICENCO), P58, DOI 10.1109/ICENCO.2015.7416326.
   Vicente-Guijalba F, 2015, IEEE T GEOSCI REMOTE, V53, P3278, DOI 10.1109/TGRS.2014.2372897.},
Number-of-Cited-References = {10},
Times-Cited = {13},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {18},
Doc-Delivery-Number = {BF7BN},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000383945000126},
OA = {gold},
DA = {2023-08-12},
}

@article{ WOS:000640472400003,
Author = {Vizcarra, Gerson and Bermejo, Danitza and Mauricio, Antoni and Zarate
   Gomez, Ricardo and Dianderas, Erwin},
Title = {The Peruvian Amazon forestry dataset: A leaf image classification corpus},
Journal = {ECOLOGICAL INFORMATICS},
Year = {2021},
Volume = {62},
Month = {MAY},
Abstract = {Forest census allows getting precise data for logging planning and
   elaboration of the forest management plan. Species identification
   blunders carry inadequate forest management plans and high risks inside
   forest concessions. Hence, an identification protocol prevents the
   exploitation of non-commercial or endangered timber species. The current
   Peruvian legislation allows the incorporation of non-technical experts,
   called ?materos?, during the identification. Materos use common names
   given by the folklore and traditions of their communities instead of
   formal ones, which generally lead to misclassifications. In the real
   world, logging companies hire materos instead of botanists due to
   cost/time limitations. Given such a motivation, we explore an end-to-end
   software solution to automatize the species identification. This paper
   introduces the Peruvian Amazon Forestry Dataset, which includes 59,441
   leaves samples from ten of the most profitable and endangered timbertree
   species. The proposal contemplates a background removal algorithm to
   feed a pre-trained CNN by the ImageNet dataset. We evaluate the
   quantitative (accuracy metric) and qualitative (visual interpretation)
   impacts of each stage by ablation experiments. The results show a
   96.64\% training accuracy and 96.52\% testing accuracy on the VGG-19
   model. Furthermore, the visual interpretation of the model evidences
   that leaf venations have the highest correlation in the plant
   recognition task.},
Publisher = {ELSEVIER},
Address = {RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Dianderas, E (Corresponding Author), Inst Invest Amazonia Peruana IIAP, GESCON, Av A Quinones Km 2,5, Iquitos 16007, Loreto, Peru.
   Vizcarra, Gerson; Bermejo, Danitza; Mauricio, Antoni; Zarate Gomez, Ricardo; Dianderas, Erwin, Inst Invest Amazonia Peruana IIAP, GESCON, Av A Quinones Km 2,5, Iquitos 16007, Loreto, Peru.
   Bermejo, Danitza, Univ Nacl Altiplano, Puno, Peru.},
DOI = {10.1016/j.ecoinf.2021.101268},
EarlyAccessDate = {MAR 2021},
Article-Number = {101268},
ISSN = {1574-9541},
EISSN = {1878-0512},
Keywords = {Leaves dataset; Peruvian Amazon; Deep learning; Visual interpretation;
   Interpretation},
Keywords-Plus = {CONVOLUTIONAL NEURAL-NETWORKS; IDENTIFICATION; RECOGNITION; SYSTEM},
Research-Areas = {Environmental Sciences \& Ecology},
Web-of-Science-Categories  = {Ecology},
Author-Email = {gerson.vizcarra@ucsp.edu.pe
   danitza.bermejo@gmail.com
   manasses.mauricio@ucsp.edu.pe
   rzarate@iiap.gob.pe
   edianderas@iiap.gob.pe},
Affiliations = {Universidad Nacional del Altiplano},
ORCID-Numbers = {Bermejo, Danitza/0000-0003-1176-1633
   Dianderas, Erwin/0000-0003-3568-2235
   Vizcarra Aguilar, Gerson/0000-0002-3549-8924},
Funding-Acknowledgement = {``Fondo Nacional de Desarrollo Cientifico, Tecnologico y de Innovacion
   Tecnologica (FONDECYT){''}, Peru, an initiative of the ``Consejo
   Nacional de Ciencia, Tecnologia e Innovacion Tecnologica (CONCYTEC){''},
   Peru {[}022-2018-FONDECYT-BM-IADT-AV]},
Funding-Text = {The present work was carried out under the grant
   022-2018-FONDECYT-BM-IADT-AV, thanks to the ``Fondo Nacional de
   Desarrollo Cientifico, Tecnologico y de Innovacion Tecnologica
   (FONDECYT){''}, Peru, an initiative of the ``Consejo Nacional de
   Ciencia, Tecnologia e Innovacion Tecnologica (CONCYTEC){''}, Peru.},
Cited-References = {Al W., 2008, CLIM CHANG FOOD SEC.
   {[}Anonymous], 2017, ARXIV, DOI {[}DOI 10.48550/ARXIV.1702.08608, 10.48550/arXiv.1702.08608].
   Barbedo JGA, 2016, BIOSYST ENG, V144, P52, DOI 10.1016/j.biosystemseng.2016.01.017.
   Azlah MAF, 2019, COMPUTERS, V8, DOI 10.3390/computers8040077.
   Barre P, 2017, ECOL INFORM, V40, P50, DOI 10.1016/j.ecoinf.2017.05.005.
   Barros AC, 1999, ADV ECON BOTANY, V13, P153.
   Belhumeur PN, 2008, LECT NOTES COMPUT SC, V5305, P116, DOI 10.1007/978-3-540-88693-8\_9.
   Brito B., 2006, 4 IUCN C ENV LAW C I.
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851.
   Chulif S., 2019, CLEF WORKING NOTES.
   Cruz A, 2019, COMPUT ELECTRON AGR, V157, P63, DOI 10.1016/j.compag.2018.12.028.
   da Silva LA, 2019, COMPUT ELECTRON AGR, V156, P360, DOI 10.1016/j.compag.2018.11.040.
   Ellis B., 2009, MANUAL LEAF ARCHITEC, DOI {[}DOI 10.1079/9781845935849.0000, 10.1079/9781845935849.0000].
   Emin Orhan X.P.A., 2018, INT C LEARN REPR.
   Fang M, 2009, ISIP: 2009 INTERNATIONAL SYMPOSIUM ON INFORMATION PROCESSING, PROCEEDINGS, P109.
   Fearnside PM, 2008, AN ACAD BRAS CIENC, V80, P101, DOI 10.1590/S0001-37652008000100006.
   Fearnside PM, 2012, CLIM POLICY, V12, P70, DOI 10.1080/14693062.2011.581571.
   Finer M, 2014, SCI REP-UK, V4, DOI 10.1038/srep04719.
   Goeau H., 2017, CLEF C LABS EV FOR 1.
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1.
   Grinblat GL, 2016, COMPUT ELECTRON AGR, V127, P418, DOI 10.1016/j.compag.2016.07.003.
   Hongli Fani, 2013, 2013 Fifth International Conference on Computational and Information Sciences (ICCIS 2013), P298, DOI 10.1109/ICCIS.2013.86.
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243.
   Jeon WS, 2017, INT J FUZZY LOG INTE, V17, P26, DOI 10.5391/IJFIS.2017.17.1.26.
   Kamilaris A, 2018, COMPUT ELECTRON AGR, V147, P70, DOI 10.1016/j.compag.2018.02.016.
   Kaya A, 2019, COMPUT ELECTRON AGR, V158, P20, DOI 10.1016/j.compag.2019.01.041.
   Keenan RJ, 2015, FOREST ECOL MANAG, V352, P9, DOI 10.1016/j.foreco.2015.06.014.
   Keni ND, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P298, DOI 10.1109/SPIN.2017.8049963.
   Kingma D. P., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1412.6980.
   Kornblith S, 2019, PROC CVPR IEEE, P2656, DOI 10.1109/CVPR.2019.00277.
   Krause J, 2016, LECT NOTES COMPUT SC, V9907, P301, DOI 10.1007/978-3-319-46487-9\_19.
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386.
   Kumar N, 2012, LECT NOTES COMPUT SC, V7573, P502, DOI 10.1007/978-3-642-33709-3\_36.
   Larese MG, 2014, EXPERT SYST APPL, V41, P4638, DOI 10.1016/j.eswa.2014.01.029.
   Larese MG, 2014, PATTERN RECOGN, V47, P158, DOI 10.1016/j.patcog.2013.06.012.
   Lee S, 2017, 24TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2017), DOI {[}10.1016/j.patcog.2017.05.015, 10.14722/ndss.2017.23457].
   Ni F, 2018, IEEE IMAGE PROC, P1223, DOI 10.1109/ICIP.2018.8451605.
   Novotny P, 2013, BIOSYST ENG, V115, P444, DOI 10.1016/j.biosystemseng.2013.04.007.
   O'Neill GA, 2001, BIODIVERS CONSERV, V10, P837, DOI 10.1023/A:1016644706237.
   Olsen A., 2015, 2015 INT C DIG IM CO, P1, DOI {[}10.1109/DICTA.2015.7371274, DOI 10.1109/DICTA.2015.7371274].
   Park J, 2008, J SYST SOFTWARE, V81, P71, DOI 10.1016/j.jss.2007.05.001.
   Pinedo-Vasquez M., 1992, Ecological Economics, V6, P163, DOI 10.1016/0921-8009(92)90011-G.
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X.
   Qian WQ, 2020, COMPUT ELECTRON AGR, V174, DOI 10.1016/j.compag.2020.105519.
   Rashad M. Z., 2011, International Journal of Computer Science \& Information Technology, V3, P93, DOI 10.5121/ijcsit.2011.3407.
   Ravindran P, 2018, PLANT METHODS, V14, DOI 10.1186/s13007-018-0292-9.
   Rawat W, 2017, NEURAL COMPUT, V29, P2352, DOI {[}10.1162/NECO\_a\_00990, 10.1162/neco\_a\_00990].
   Rizk S., 2019, THESIS.
   Shah MP, 2017, IEEE IMAGE PROC, P860, DOI 10.1109/ICIP.2017.8296403.
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556.
   Singh Vivek, 2015, ABS151203385 CORR, VV4, DOI {[}DOI 10.1109/CVPR.2016.90, 10.17577/IJERTV4IS051057].
   Smilkov Daniel, 2017, SMOOTHGRAD REMOVING.
   Smith J, 2006, FOREST POLICY ECON, V8, P458, DOI 10.1016/j.forpol.2005.08.001.
   Soares B, 2010, P NATL ACAD SCI USA, V107, P10821, DOI 10.1073/pnas.0913048107.
   Sundararajan M, 2017, PR MACH LEARN RES, V70.
   Thanh TKN, 2018, LECT NOTES ARTIF INT, V10751, P565, DOI 10.1007/978-3-319-75417-8\_53.
   Thanikkal JG, 2017, 2017 RECENT DEVELOPMENTS IN CONTROL, AUTOMATION AND POWER ENGINEERING (RDCAPE), P404, DOI 10.1109/RDCAPE.2017.8358305.
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815.
   Too EC, 2019, COMPUT ELECTRON AGR, V161, P272, DOI 10.1016/j.compag.2018.03.032.
   Waldchen J, 2018, ARCH COMPUT METHOD E, V25, P507, DOI 10.1007/s11831-016-9206-z.
   Wittmann F, 2006, J BIOGEOGR, V33, P1334, DOI 10.1111/j.1365-2699.2006.01495.x.
   Wu SG, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, VOLS 1-3, P120.
   Zhang SW, 2020, NEUROCOMPUTING, V408, P246, DOI 10.1016/j.neucom.2019.09.113.
   Zhao C, 2015, PATTERN RECOGN, V48, P3203, DOI 10.1016/j.patcog.2015.04.004.},
Number-of-Cited-References = {64},
Times-Cited = {5},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {12},
Journal-ISO = {Ecol. Inform.},
Doc-Delivery-Number = {RN6PD},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000640472400003},
OA = {hybrid},
DA = {2023-08-12},
}

@article{ WOS:000292711500012,
Author = {Zhang, Y. and Slaughter, D. C.},
Title = {Hyperspectral species mapping for automatic weed control in tomato under
   thermal environmental stress},
Journal = {COMPUTERS AND ELECTRONICS IN AGRICULTURE},
Year = {2011},
Volume = {77},
Number = {1},
Pages = {95-104},
Month = {JUN},
Abstract = {This work studied the impacts of variations in environmental temperature
   on hyperspectral imaging features in the visible and near infrared
   regions for robust species identification for weed mapping in tomato
   production. Six major Californian processing tomato cultivars, black
   nightshade (Solanum nigrum L) and redroot pigweed (Amaranthus
   retroflexus L) were grown under a variety of diurnal temperature ranges
   simulating conditions common in the Californian springtime planting
   period and one additional treatment simulating greenhouse growing
   conditions. The principal change in canopy reflectance with varying
   temperature occurred in the 480-670 and 720-810 nm regions. The overall
   classification rate ranged from 62.5\% to 91.6\% when classifiers
   trained under single temperatures were applied to plants grown at
   different temperatures. Eliminating the 480-670 nm region from the
   classifier's feature set mitigated the temperature effect by stabilizing
   the total crop vs. weed classification rate at 86.4\% over the
   temperature ranges. A site-specific recalibration method was also
   successful in alleviating the bias created by calibrating the models on
   the extreme temperatures and increased the classification accuracy to
   90.3\%. A global calibration method, incorporating all four temperature
   conditions in the classifier feature space, provided the best average
   total classification accuracy of 92.2\% out of the methods studied, and
   was fairly robust to the varying diurnal temperature conditions. (C)
   2011 Elsevier B.V. All rights reserved.},
Publisher = {ELSEVIER SCI LTD},
Address = {THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Zhang, Y (Corresponding Author), Univ Calif Davis, Dept Biol \& Agr Engn, 1 Shields Ave, Davis, CA 95616 USA.
   Zhang, Y.; Slaughter, D. C., Univ Calif Davis, Dept Biol \& Agr Engn, Davis, CA 95616 USA.},
DOI = {10.1016/j.compag.2011.04.001},
ISSN = {0168-1699},
EISSN = {1872-7107},
Keywords = {Hyperspectral imaging; Machine learning; Plant identification; Weed
   control; Temperature; Tomato},
Keywords-Plus = {DIFFERENTIATION; DISCRIMINATION; QUALITY; PLANTS},
Research-Areas = {Agriculture; Computer Science},
Web-of-Science-Categories  = {Agriculture, Multidisciplinary; Computer Science, Interdisciplinary
   Applications},
Author-Email = {yunzhang@ucdavis.edu},
Affiliations = {University of California System; University of California Davis},
Funding-Acknowledgement = {California Tomato Research Institute},
Funding-Text = {This project has been partially funded by the California Tomato Research
   Institute. The authors acknowledge the technical assistance provided by
   Eric Staab, Burt Vannucci, Mir Shafii, Roger Chetelat, Garry Person and
   Dennis Lewis from University of California, Davis.},
Cited-References = {{[}Anonymous], 2001, PATTERN CLASSIFICATI.
   Biller RH, 1998, J AGR ENG RES, V71, P357, DOI 10.1006/jaer.1998.0334.
   Borregaard T, 2000, J AGR ENG RES, V75, P389, DOI 10.1006/jaer.1999.0519.
   CHANDLER JM, 1992, WEEDS COTTON CHARACT, P85.
   CRUZCASTILLO JG, 1994, HORTSCIENCE, V29, P1115, DOI 10.21273/HORTSCI.29.10.1115.
   Everitt B., 1978, GRAPHICAL TECHNIQUES.
   Gowen AA, 2007, TRENDS FOOD SCI TECH, V18, P590, DOI 10.1016/j.tifs.2007.06.001.
   GUYOT G, 1990, EAST SCH AG, P19.
   Henry WB, 2004, WEED SCI, V52, P788, DOI 10.1614/WS-03-051R.
   HERTZOG C, 1986, EDUC PSYCHOL MEAS, V46, P349, DOI 10.1177/001316448604600208.
   Klawonn F, 2006, ICDM 2006: Sixth IEEE International Conference on Data Mining, Workshops, P643.
   MCGIFFEN ME, 1992, WEED SCI, V40, P220, DOI 10.1017/S004317450005726X.
   MONACO TJ, 1981, WEED SCI, V29, P394, DOI 10.1017/S0043174500039874.
   Nightingale GT, 1933, BOT GAZ, V95, P35, DOI 10.1086/334365.
   {*}PTAB, 2010, 2010 PROC TOM ACT VA.
   {*}PTAB, 2009, 2009 FIN REP.
   SAS INSTITUTE INC., 2007, SAS ONLINEDOC 9 2.
   SAVITZKY A, 1964, ANAL CHEM, V36, P1627, DOI 10.1021/ac60214a047.
   Shenk JS., 2008, HDB NEAR INFRARED AN, P347.
   Slaughter DC, 2008, COMPUT ELECTRON AGR, V61, P63, DOI 10.1016/j.compag.2007.05.008.
   Slaughter DC, 2008, WEED TECHNOL, V22, P378, DOI 10.1614/WT-07-104.1.
   Slaughter DC, 2004, T ASAE, V47, P1907, DOI 10.13031/2013.17800.
   Staab E., 2009, 096635 ASABE.
   STEINIER J, 1972, ANAL CHEM, V44, P1906, DOI 10.1021/ac60319a045.
   THOMPSON JF, 1991, CROP PROT, V10, P254, DOI 10.1016/0261-2194(91)90002-9.
   {*}UC IPM, PEST MAN GUID TOM UC.
   UC IPM, 2007, CAL WEATH DAT.
   {*}USDA, 2007, AGR CHEM US 2006 VEG.
   {*}USDA, 2010, USDA VEG 2009 SUM.
   Vrindts E., 2002, Precision Agriculture, V3, P63, DOI 10.1023/A:1013326304427.
   Zwiggelaar R, 1998, CROP PROT, V17, P189, DOI 10.1016/S0261-2194(98)00009-X.},
Number-of-Cited-References = {31},
Times-Cited = {22},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {27},
Journal-ISO = {Comput. Electron. Agric.},
Doc-Delivery-Number = {791ZY},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000292711500012},
DA = {2023-08-12},
}

@inproceedings{ WOS:000366126400026,
Author = {Rueda-Plata, Diego and Ramos-Pollan, Raul and Gonzalez, Fabio A.},
Editor = {Nunez, M and Nguyen, NT and Camacho, D and Trawinski, B},
Title = {Supervised Greedy Layer-Wise Training for Deep Convolutional Networks
   with Small Datasets},
Booktitle = {COMPUTATIONAL COLLECTIVE INTELLIGENCE (ICCCI 2015), PT I},
Series = {Lecture Notes in Artificial Intelligence},
Year = {2015},
Volume = {9329},
Pages = {275-284},
Note = {7th International Conference on Computational Collective Intelligence
   (ICCCI), Madrid, SPAIN, SEP 21-23, 2015},
Organization = {Univ Complutense Madrid; Univ Autonama Madrid; Wroclaw Univ Technol},
Abstract = {Deep convolutional neural networks (DCNs) are increasingly being used
   with considerable success in image classification tasks trained over
   large datasets. However, such large datasets are not always available or
   affordable in many applications areas where we would like to apply DCNs,
   having only datasets of the order of a few thousands labelled images,
   acquired and annotated through lenghty and costly processes (such as in
   plant recognition, medical imaging, etc.). In such cases DCNs do not
   generally show competitive performance and one must resort to fine-tune
   networks that were costly pretrained with large generic datasets where
   there is no a-priori guarantee that they would work well in specialized
   domains. In this work we propose to train DCNs with a greedy layer-wise
   method, analogous to that used in unsupervised deep networks. We show
   how, for small datasets, this method outperforms DCNs which do not use
   pretrained models and results reported in the literature with other
   methods. Additionally, our method learns more interpretable and cleaner
   visual features. Our results are also competitive as compared with
   convolutional methods based on pretrained models when applied to general
   purpose datasets, and we obtain them with much smaller datasets (1.2
   million vs. 10K images) at a fraction of the computational cost. We
   therefore consider this work a first milestone in our quest to
   successfully use DCNs for small specialized datasets.},
Publisher = {SPRINGER-VERLAG BERLIN},
Address = {HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Ramos-Pollan, R (Corresponding Author), Univ Ind Santander, Bucaramanga, Colombia.
   Rueda-Plata, Diego; Ramos-Pollan, Raul, Univ Ind Santander, Bucaramanga, Colombia.
   Gonzalez, Fabio A., Univ Nacl Colombia, Bogota, Colombia.},
DOI = {10.1007/978-3-319-24069-5\_26},
ISSN = {0302-9743},
EISSN = {1611-3349},
ISBN = {978-3-319-24069-5; 978-3-319-24068-8},
Keywords = {Convolutional networks; Deep learning; Greedy layer-wise training},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Robotics},
Author-Email = {sandiego206@gmail.com
   rramosp@uis.edu.co
   fagonzalezo@unal.edu.co},
Affiliations = {Universidad Industrial de Santander; Universidad Nacional de Colombia},
ORCID-Numbers = {Rueda, Diego/0000-0003-2818-3323},
Cited-References = {Bengio Y, 2007, P ADV NEUR INF PROC, V19, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024.
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50.
   Erhan D, 2010, J MACH LEARN RES, V11, P625.
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251.
   Hinton Geoffrey E., 2012, NEURAL NETWORKS TRIC, P599, DOI 10.1007/978-3-642-35289-8\_32.
   Jia Y., 2014, P 22 ACM INT C MULT, P675.
   Juneja M, 2013, PROC CVPR IEEE, P923, DOI 10.1109/CVPR.2013.124.
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386.
   Larochelle H, 2009, J MACH LEARN RES, V10, P1.
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791.
   Nilsback M.-E., 2006, P IEEE COMP SOC C CO, V2, P1447, DOI DOI 10.1109/CVPR.2006.42.
   Nilsback M-E., 2008, P IND C COMP VIS GRA.
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003.
   Vincent P, 2010, J MACH LEARN RES, V11, P3371.
   Zhang Hao, 2006, 2006 IEEE COMPUTER S, V2, P2126, DOI {[}DOI 10.1109/CVPR.2006.301, 10.1109/CVPR.2006.301].},
Number-of-Cited-References = {15},
Times-Cited = {14},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {14},
Doc-Delivery-Number = {BE0IZ},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000366126400026},
DA = {2023-08-12},
}

@article{ WOS:000294499600005,
Author = {Kebapci, Hanife and Yanikoglu, Berrin and Unal, Gozde},
Title = {Plant Image Retrieval Using Color, Shape and Texture Features},
Journal = {COMPUTER JOURNAL},
Year = {2011},
Volume = {54},
Number = {9, SI},
Pages = {1475-1490},
Month = {SEP},
Abstract = {We present a content-based image retrieval system for plant image
   retrieval, intended especially for the house plant identification
   problem. A plant image consists of a collection of overlapping leaves
   and possibly flowers, which makes the problem challenging. We studied
   the suitability of various well-known color, shape and texture features
   for this problem, as well as introducing some new texture matching
   techniques and shape features. Feature extraction is applied after
   segmenting the plant region from the background using the max-flow
   min-cut technique. Results on a database of 380 plant images belonging
   to 78 different types of plants show promise of the proposed new
   techniques and the overall system: in 55\% of the queries, the correct
   plant image is retrieved among the top-15 results. Furthermore, the
   accuracy goes up to 73\% when a 132-image subset of well-segmented plant
   images are considered.},
Publisher = {OXFORD UNIV PRESS},
Address = {GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Yanikoglu, B (Corresponding Author), Sabanci Univ, Fac Engn \& Nat Sci, TR-34956 Istanbul, Turkey.
   Kebapci, Hanife; Yanikoglu, Berrin; Unal, Gozde, Sabanci Univ, Fac Engn \& Nat Sci, TR-34956 Istanbul, Turkey.},
DOI = {10.1093/comjnl/bxq037},
ISSN = {0010-4620},
EISSN = {1460-2067},
Keywords = {image retrieval; plants; Gabor wavelets; SIFT},
Keywords-Plus = {MAIZE PLANT; IDENTIFICATION},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Hardware \& Architecture; Computer Science,
   Information Systems; Computer Science, Software Engineering; Computer
   Science, Theory \& Methods},
Author-Email = {berrin@sabanciuniv.edu},
Affiliations = {Sabanci University},
ResearcherID-Numbers = {Yanikoglu, Berrin/AAE-4843-2022
   Unal, Gozde/A-2360-2013},
ORCID-Numbers = {Yanikoglu, Berrin/0000-0001-7403-7592
   Unal, Gozde/0000-0001-5942-8966},
Cited-References = {Abbasi S, 1997, LECT NOTES COMPUT SC, V1252, P284.
   Abbasi S, 1999, MULTIMEDIA SYST, V7, P467, DOI 10.1007/s005300050147.
   {[}Anonymous], 1992, DIGITAL IMAGE PROCES.
   {[}Anonymous], 2000, DIGITAL SIGNAL PROC.
   Arevalillo-Herraez M, 2008, PATTERN RECOGN LETT, V29, P2174, DOI 10.1016/j.patrec.2008.08.003.
   Bach JR, 1996, P SOC PHOTO-OPT INS, V2670, P76, DOI 10.1117/12.234785.
   Backes AR, 2010, PATTERN RECOGN LETT, V31, P44, DOI 10.1016/j.patrec.2009.08.007.
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60.
   Bruno OM, 2008, INFORM SCIENCES, V178, P2722, DOI 10.1016/j.ins.2008.01.023.
   Eakins JP, 2002, PATTERN RECOGN, V35, P3, DOI 10.1016/S0031-3203(01)00038-3.
   El-Ghazal A, 2007, LECT NOTES COMPUT SC, V4633, P650.
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146.
   Ford Jr L.R., 1956, CANADIAN J MATH, V8, P399, DOI {[}10.4153/CJM-1956-045-5, DOI 10.4153/CJM-1956-045-5].
   Han J, 2007, IMAGE VISION COMPUT, V25, P1474, DOI 10.1016/j.imavis.2006.12.015.
   Haralick R., 1992, COMPUTER ROBOT VISIO, DOI 10.5555/573190.
   Iqbal Q, 2002, INT C PATT RECOG, P438, DOI 10.1109/ICPR.2002.1048333.
   Jain AK, 1996, PATTERN RECOGN, V29, P1233, DOI 10.1016/0031-3203(95)00160-3.
   JIA J, 1992, J AGR ENG RES, V52, P169, DOI 10.1016/0021-8634(92)80058-Z.
   Ledwich L, 2004, AUSTR C ROB AUT.
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005.
   LIN FY, 2008, ICIC, V3, P432.
   Liu CJ, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P270, DOI 10.1109/ICCV.2001.937635.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Lowe DG., 1999, P 7 IEEE INT C COMPU, V2, P1150, DOI {[}10.1109/iccv.1999.790410, DOI 10.1109/ICCV.1999.790410].
   Ma WY, 1996, PROC CVPR IEEE, P425, DOI 10.1109/CVPR.1996.517107.
   MAN QK, 2008, ICIC, V3, P192.
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803.
   Park JS, 2004, LECT NOTES COMPUT SC, V3332, P146.
   Perez AJ, 2000, COMPUT ELECTRON AGR, V25, P197, DOI 10.1016/S0168-1699(99)00068-X.
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720.
   Sena DG, 2003, BIOSYST ENG, V85, P449, DOI 10.1016/S1537-5110(03)00098-9.
   Shim SO, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P493.
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972.
   Sonka M., 1993, IMAGE PROCESSING ANA.
   Sural S., 2002, P INT C IMAGE PROCES, pII, DOI {[}10.1109/ICIP.2002.1040019, DOI 10.1109/ICIP.2002.1040019].
   TICO M, 2000, P NORD SIGN PROC S N, P157.
   VELTKAMP RC, 2000, CONTENT BASED IMAGE.
   Venters C, 2000, REV CONTENT BASED IM.
   WANG J, 2005, IEEE INT C IM PROC, P1256.
   Wang Z, 2003, IEE P-VIS IMAGE SIGN, V150, P34, DOI 10.1049/ip-vis:20030160.
   Wang ZY, 2000, LECT NOTES COMPUT SC, V1929, P477.
   Woebbecke D.M., 1993, OPTICS AGR FORESTRY, P208, DOI DOI 10.1117/12.144030.
   Wong YM, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P2206.
   Yahiaoui I, 2006, LECT NOTES COMPUT SC, V4261, P357.
   Yonekawa S, 1996, T ASAE, V39, P1525, DOI 10.13031/2013.27647.
   Zarit B. D., 1999, Proceedings International Workshop on Recognition, Analysis, and Tracking of Faces and Gestures in Real-Time Systems. In Conjunction with ICCV'99 (Cat. No.PR00378), P58, DOI 10.1109/RATFG.1999.799224.
   ZHANG MID, 2000, P 1 IEEE PAC RIM C M, P392.},
Number-of-Cited-References = {47},
Times-Cited = {33},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {21},
Journal-ISO = {Comput. J.},
Doc-Delivery-Number = {815AX},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000294499600005},
DA = {2023-08-12},
}

@inproceedings{ WOS:000383091300010,
Author = {Herdiyeni, Yeni and Ginanjar, Asep Rahmat and Anggoro, M. Rake Linggar
   and Douady, Stephane and Zuhud, Ervizal A. M.},
Editor = {Koppen, M and Xue, B and Takagi, H and Abraham, A and Muda, AK and Ma, K},
Title = {MedLeaf: Mobile Biodiversity Informatics Tool for Mapping and
   Identifying Indonesian Medicinal Plants},
Booktitle = {PROCEEDINGS OF THE 2015 SEVENTH INTERNATIONAL CONFERENCE OF SOFT
   COMPUTING AND PATTERN RECOGNITION (SOCPAR 2015)},
Series = {International Conference on Soft Computing and Pattern Recognition},
Year = {2015},
Pages = {54-59},
Note = {7th International Conference of Soft Computing and Pattern Recognition
   (SoCPaR), Kyushu Univ, Ohashi Campus, Fukuoka, JAPAN, NOV 13-15, 2015},
Organization = {IEEE; Machine Intelligence Res Labs; Kyushu Univ, Res Ctr Appl
   Perceptual Sci; IEEE SMC Japan Chapter},
Abstract = {We presents a mobile biodiversity informatics tools for identifying and
   mapping Indonesian medicinal plants. The system - called MedLeaf - has
   been developed as a prototype data resource for documenting,
   integrating, disseminating, and identifying of Indonesian medicinal
   plants. Identification of medicinal plant is done automatically based on
   digital image processing. Fuzzy Local Binary Pattern (LBP) and
   geometrical features are used to extract leaves features. Probabilistic
   Neural Network is used as classifier for discrimination. Data set
   consist of 85 species of Indonesian medicinal plants with 3,502 leaves
   digital images. Our results indicate that combination of leaves features
   outperform than using single features with accuracy 88.5\%. The
   distribution of medicinal plants can be shown on mobile phone using GIS
   application. The application is essential to help people identify the
   medicinal plants and disseminate information of medicinal plants
   distribution in Indonesia.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Herdiyeni, Y (Corresponding Author), Bogor Agr Univ, Fac Math \& Nat Sci, Dept Comp Sci, Java, Indonesia.
   Herdiyeni, Yeni; Ginanjar, Asep Rahmat; Anggoro, M. Rake Linggar, Bogor Agr Univ, Fac Math \& Nat Sci, Dept Comp Sci, Java, Indonesia.
   Douady, Stephane, Univ Paris Diderot, Lab Matiere \& Syst Complex, Paris, France.
   Zuhud, Ervizal A. M., Bogor Agr Univ, Fac Forestry, Dept Forest Resources Conservat \& Ecotourism, Java, Indonesia.},
ISSN = {2381-7542},
ISBN = {978-1-4673-9360-7},
Keywords = {biodiversity informatics; medicinal plants; FLBP; leaves texture; leaves
   shape},
Research-Areas = {Computer Science; Engineering},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science, Theory \&
   Methods; Engineering, Electrical \& Electronic},
Author-Email = {yeni.herdiyeni@ipb.ac.id
   stephane.douady@univ-paris-diderot.fr},
Affiliations = {Bogor Agricultural University; UDICE-French Research Universities;
   Universite Paris Cite; Bogor Agricultural University},
ResearcherID-Numbers = {DOUADY, Stephane/C-4498-2018
   Herdiyeni, Yeni/GPK-6559-2022
   Amzu, Ervizal/GQP-3483-2022},
ORCID-Numbers = {DOUADY, Stephane/0000-0002-3416-886X
   Herdiyeni, Yeni/0000-0002-3389-1730
   },
Cited-References = {Anami B. S., 2012, INT J MACHINE LEARNI, V2.
   {[}Anonymous], 1988, BIODIVERSITY.
   APJII, 2013, PROFIL PENGGUNA INTE.
   Arino AH, 2011, BMC BIOINFORMATICS, V12, DOI 10.1186/1471-2105-12-S15-S4.
   Butler D, 2006, NATURE, V439, P6, DOI 10.1038/439006a.
   Damayanti E. K., 2011, INT WORKSH LINK BIOD.
   Herdiyeni Y., 2012, P INT C ADV COMP SCI.
   {[}IUCN WWF WHO], 1986, GUID CONS MED PLANTS.
   Jenkins M., 2002, WORD ATLAS BIODIVERS.
   Keramidas E.G., 2008, NOISE ROBUST STAT FE.
   Kittler J., 1998, COMBINING CLASSIFIER.
   Maier D., 2000, NSF USGS NASA WORKSH.
   Meyer C., 2015, PEERJ PREPRINTS.
   Mitra R., 2007, ASIA PACIFIC BIOTECH, P726.
   Mittermeier C. G, 1997, CEMEX.
   Ojala T., 2002, IEEE T PAMI, V24, P2037.
   Pahalawatta K., 2008, THESIS.
   Peterson AT, 2010, SYST BIODIVERS, V8, P159, DOI 10.1080/14772001003739369.
   Prasvita D.S., 2013, INT J ADV SCI ENG IN, V3, P5, DOI {[}10.18517/ijaseit.3.2.287, DOI 10.18517/IJASEIT.3.2.287].
   Sarkar IN, 2007, BRIEF BIOINFORM, V8, P347, DOI 10.1093/bib/bbm037.
   Schnase JL, 2003, INFORM SYST, V28, P339, DOI 10.1016/S0306-4379(02)00070-4.
   Soberon J, 2004, PHILOS T R SOC B, V359, P689, DOI 10.1098/rstb.2003.1439.
   Tan KL, 2003, MULTIMED TOOLS APPL, V19, P111, DOI 10.1023/A:1022142527536.
   Wilson EO, 2005, P NATL ACAD SCI USA, V102, P6520, DOI 10.1073/pnas.0501936102.},
Number-of-Cited-References = {24},
Times-Cited = {3},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BF6HR},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000383091300010},
DA = {2023-08-12},
}

@article{ WOS:000087018800030,
Author = {Burks, TF and Shearer, SA and Payne, FA},
Title = {Classification of weed species using color texture features and
   discriminant analysis},
Journal = {TRANSACTIONS OF THE ASAE},
Year = {2000},
Volume = {43},
Number = {2},
Pages = {441-448},
Month = {MAR-APR},
Abstract = {The environmental impact of herbicide utilization has stimulated
   research into new methods of weed control, such as selective herbicide
   application on highly infested crop areas. This research utilized the
   Color Go-occurrence Method (CCM) to determine whether traditional
   statistical discriminant analysis call be used to discriminate between
   six different classes of groundcover: The weed species evaluated were
   giant foxtail, crabgrass, common lambsquarter; velvetleaf; and ivyleaf
   morningglory, along with a soil image data set. The between species
   discriminant analysis showed that the CCM texture statistics procedure
   was able to classify between five weed species and soil with an accuracy
   of 93\% using hue and saturation statistics, only. A significant
   accomplishment of this work was the elimination of the intensity texture
   features from the model, which reduces computational requirements by
   one-third.},
Publisher = {AMER SOC AGRICULTURAL ENGINEERS},
Address = {2950 NILES RD, ST JOSEPH, MI 49085-9659 USA},
Type = {Article},
Language = {English},
Affiliation = {Burks, TF (Corresponding Author), Univ Kentucky, Dept Agr \& Biosyst Engn, 128 Agr Engn Bldg, Lexington, KY 40546 USA.
   Univ Kentucky, Dept Agr \& Biosyst Engn, Lexington, KY 40546 USA.},
ISSN = {0001-2351},
Keywords = {machine vision; image processing; precision farming; herbicide
   application; leaf and plant identification},
Keywords-Plus = {IDENTIFICATION},
Research-Areas = {Agriculture},
Web-of-Science-Categories  = {Agricultural Engineering},
Affiliations = {University of Kentucky},
ResearcherID-Numbers = {Shearer, Scott/C-8055-2012
   },
ORCID-Numbers = {Shearer, Scott/0000-0003-4419-5586},
Cited-References = {{[}Anonymous], 1985, VISION MAN MACHINE.
   {[}Anonymous], 1973, LINEAR STAT INFERENC.
   Bridges D.C., 1992, CROP LOSES DUE WEEDS, P1.
   BURKS TF, 1997, THESIS U KENTUCKY LE.
   CHAISATTAPAGON C, 1991, 913508 ASAE.
   FRANZ E, 1991, T ASAE, V34, P682.
   FRANZ E, 1990, 907040 ASAE.
   Haralick R. M., 1974, Remote Sensing of Environment, V3, P3, DOI 10.1016/0034-4257(74)90033-9.
   HARALICK RM, 1973, IEEE T GEOSCI REMOTE, VGE11, P171, DOI 10.1109/TGE.1973.294312.
   Julesz B., 1962, IRE T INF THEORY, V8, P84, DOI DOI 10.1109/TIT.1962.1057698.
   Meyer GE, 1998, T ASAE, V41, P1189, DOI 10.13031/2013.17244.
   OHTA Y, 1985, KNOWLEDGE BASED INTE.
   {*}SAS, 1985, SAS US GUID STAT.
   SHEARER SA, 1990, T ASAE, V33, P2037.
   SHEARER SA, 1986, THESIS OHIO STATE U.
   TANG L, 1999, 993036 ASAE.
   THOMPSON JF, 1991, CROP PROT, V10, P254, DOI 10.1016/0261-2194(91)90002-9.
   WANG N, 1999, 993037 ASAE.
   WOEBBECKE DM, 1995, T ASAE, V38, P259, DOI 10.13031/2013.27838.
   WYSZECKI G, 1992, COLOR SCI CONCEPTS M, P117.
   ZHANG N, 1995, T ASAE, V38, P965, DOI 10.13031/2013.27890.},
Number-of-Cited-References = {21},
Times-Cited = {63},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {9},
Journal-ISO = {Trans. ASAE},
Doc-Delivery-Number = {313UZ},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000087018800030},
DA = {2023-08-12},
}

@article{ WOS:000508746900022,
Author = {Su, Wen-Hao and Slaughter, David C. and Fennimore, Steven A.},
Title = {Non-destructive evaluation of photostability of crop signaling compounds
   and dose effects on celery vigor for precision plant identification
   using computer vision},
Journal = {COMPUTERS AND ELECTRONICS IN AGRICULTURE},
Year = {2020},
Volume = {168},
Month = {JAN},
Abstract = {Vegetable crops grown in the field are particularly vulnerable to
   competition from weeds at the seedling stage. To avoid yield loss, weeds
   must be removed early in the crop cycle. Shortages of farm laborers for
   hand weeding and lack of effective vegetable herbicides is stimulating
   the development of intelligent weeders. One challenge for development of
   effective intelligent weeders is the precision differentiation of
   vegetable crops and weeds. Crop signaling is a technique that enables
   rapid and accurate identification of target crops. In this study, an
   appropriate dose of fluorescent compounds allowed the vegetable crop
   locations in the field to be reliably detectable by smart machines. The
   study examined protocols for crop root treatment, computer vision system
   development, crop signal detection and biomass evaluation. Rhodamine B
   (Rh-B) is a fluorescent compound with unique optical properties.
   Different doses of Rh-B were applied to the celery roots for various
   durations prior to transplantation to assess Rh-B transport in the
   plant, its photostability and potential impact on seedling growth in the
   natural outdoor environment of a farm. Systemic Rh-B absorbed via the
   roots moved throughout the celery plant in 24 h. Compared with 60 ppm
   solution of Rh-B, higher doses of Rh-B including 90, 180, and 270 ppm
   resulted in greater absorption by the plant, but such three
   concentrations injured the plant. The biomass test results showed that
   the treatment of celery roots for two days with a 60 ppm solution of
   Rh-B was safe for celery plants. This Rh-B dosage had good
   photostability in celery seedlings for about 5 weeks after
   transplanting. An effective dose of systemic Rh-B allowed for the rapid
   identification of celery plants at early growth stages, thereby
   facilitating the automatic differentiation of weeds and crops by a
   robotic machine vision system.},
Publisher = {ELSEVIER SCI LTD},
Address = {THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Su, WH (Corresponding Author), Univ Calif Davis, One Shields Ave, Davis, CA 95616 USA.
   Su, WH (Corresponding Author), USDA, 1636 East Alisal St, Salinas, CA 93905 USA.
   Su, Wen-Hao; Slaughter, David C., Univ Calif Davis, Dept Biol \& Agr Engn, One Shields Ave, Davis, CA 95616 USA.
   Su, Wen-Hao; Fennimore, Steven A., Univ Calif Davis, Dept Plant Sci, Salinas, CA USA.},
DOI = {10.1016/j.compag.2019.105155},
Article-Number = {105155},
ISSN = {0168-1699},
EISSN = {1872-7107},
Keywords = {Robot-plant interaction; Crop signaling; Rhodamine B; Photobleaching;
   Celery biomass},
Keywords-Plus = {RHODAMINE-B; SPECTRAL INDEXES; BLUEBERRY FRUIT; WEED-CONTROL; ROOT
   UPTAKE; TRANSLOCATION; CLASSIFICATION; LEAVES; PHOTODEGRADATION;
   INFECTION},
Research-Areas = {Agriculture; Computer Science},
Web-of-Science-Categories  = {Agriculture, Multidisciplinary; Computer Science, Interdisciplinary
   Applications},
Author-Email = {whssu@ucdavis.edu},
Affiliations = {University of California System; University of California Davis;
   University of California System; University of California Davis},
ResearcherID-Numbers = {Su, Wen-Hao/Q-2431-2019},
ORCID-Numbers = {Su, Wen-Hao/0000-0003-1745-4722},
Funding-Acknowledgement = {United States Department of Agriculture (USDA), National Institute of
   Food and Agriculture (NIFA) under the Specialty Crop Research Initiative
   (SCR') grant {[}USDA-NIFA-SCRI-004530]; California Tomato Research
   Institute; California Leafy Greens Research Program},
Funding-Text = {The authors would like to acknowledge the funding from the United States
   Department of Agriculture (USDA), National Institute of Food and
   Agriculture (NIFA), under the Specialty Crop Research Initiative (SCR')
   grant ID USDA-NIFA-SCRI-004530, the California Tomato Research
   Institute, and the California Leafy Greens Research Program. The authors
   also acknowledge Leland Neilson and John S Rachuy, from the University
   of California, Davis for their technical assistance in the completion of
   this research.},
Cited-References = {Abdalla A, 2019, COMPUT ELECTRON AGR, V162, P1057, DOI 10.1016/j.compag.2019.05.051.
   {[}Anonymous], 4 INT S SEED TRANSPL.
   Blackburn JS, 2011, NAT PROTOC, V6, P229, DOI 10.1038/nprot.2010.170.
   BRIGGS GG, 1982, PESTIC SCI, V13, P495, DOI 10.1002/ps.2780130506.
   Eggeling C, 1998, ANAL CHEM, V70, P2651, DOI 10.1021/ac980027p.
   Field MS, 2002, QTRACER2 PROGRAM TRA.
   Gao JF, 2018, BIOSYST ENG, V170, P39, DOI 10.1016/j.biosystemseng.2018.03.006.
   Gao ZM, 2019, COMPUT ELECTRON AGR, V167, DOI 10.1016/j.compag.2019.105025.
   Han XM, 2003, MATER LETT, V57, P1355, DOI 10.1016/S0167-577X(02)01241-7.
   HSU FC, 1990, PLANT PHYSIOL, V93, P1573, DOI 10.1104/pp.93.4.1573.
   Inoue J, 1998, PESTIC SCI, V54, P8, DOI 10.1002/(SICI)1096-9063(199809)54:1\&lt;8::AID-PS793\&gt;3.0.CO;2-E.
   Khaled AY, 2018, APPL SPECTROSC REV, V53, P36, DOI 10.1080/05704928.2017.1352510.
   Lappartient AG, 1999, PLANT J, V18, P89, DOI 10.1046/j.1365-313X.1999.00416.x.
   Larsson M, 2017, COMPUT BIOL MED, V85, P106, DOI 10.1016/j.compbiomed.2016.04.005.
   Lee W. S., 1999, Precision Agriculture, V1, P95, DOI 10.1023/A:1009977903204.
   Li M, 1997, POSTHARVEST BIOL TEC, V12, P273, DOI 10.1016/S0925-5214(97)00059-8.
   Liang PS, 2015, BIOSYST ENG, V137, P64, DOI 10.1016/j.biosystemseng.2015.07.010.
   LINDSEY GD, 1983, NORTHWEST SCI, V57, P16.
   Liu ZQ, 2004, PEST MANAG SCI, V60, P434, DOI 10.1002/ps.816.
   O'Brien J, 2000, EUR J BIOCHEM, V267, P5421, DOI 10.1046/j.1432-1327.2000.01606.x.
   Pu HB, 2014, FOOD BIOPROCESS TECH, V7, P3088, DOI 10.1007/s11947-014-1330-x.
   Qiu RC, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11222658.
   Qu P, 1998, J MOL CATAL A-CHEM, V129, P257, DOI 10.1016/S1381-1169(97)00185-4.
   Satchivi NM, 2014, ACS SYM SER, V1171, P41.
   Shaner DL, 2009, WEED SCI, V57, P118, DOI 10.1614/WS-08-050.1.
   Slaughter DC, 2008, COMPUT ELECTRON AGR, V61, P63, DOI 10.1016/j.compag.2007.05.008.
   SONG LL, 1995, BIOPHYS J, V68, P2588, DOI 10.1016/S0006-3495(95)80442-X.
   Spurr EB, 2002, NEW ZEAL J ZOOL, V29, P187, DOI 10.1080/03014223.2002.9518302.
   Su W T, 2019, P 2019 ASABE ANN INT, P1.
   Su WH, 2019, BIOSYST ENG, V186, P156, DOI 10.1016/j.biosystemseng.2019.07.009.
   Su WH, 2019, FOOD ENG REV, V11, P142, DOI 10.1007/s12393-019-09191-2.
   Su WH, 2019, J FOOD MEAS CHARACT, V13, P1218, DOI 10.1007/s11694-019-00037-3.
   Su WH, 2019, DRY TECHNOL, V37, P1113, DOI 10.1080/07373937.2018.1487450.
   Su WH, 2019, BIOSYST ENG, V180, P70, DOI 10.1016/j.biosystemseng.2019.01.005.
   Su WH, 2018, COMPR REV FOOD SCI F, V17, P220, DOI 10.1111/1541-4337.12317.
   Su WH, 2018, COMPR REV FOOD SCI F, V17, P104, DOI 10.1111/1541-4337.12314.
   Su WH, 2017, COMPUT ELECTRON AGR, V140, P361, DOI 10.1016/j.compag.2017.06.013.
   Su WH, 2017, COMPUT ELECTRON AGR, V139, P41, DOI 10.1016/j.compag.2017.04.017.
   Su WH, 2017, J FOOD ENG, V200, P59, DOI 10.1016/j.jfoodeng.2016.12.014.
   Su WH, 2017, CRIT REV FOOD SCI, V57, P1039, DOI 10.1080/10408398.2015.1082966.
   Su WH, 2016, COMPUT ELECTRON AGR, V130, P69, DOI 10.1016/j.compag.2016.09.015.
   Su WH, 2016, COMPUT ELECTRON AGR, V127, P561, DOI 10.1016/j.compag.2016.07.007.
   Su WH, 2016, COMPUT ELECTRON AGR, V125, P113, DOI 10.1016/j.compag.2016.04.034.
   Su WH, 2016, TALANTA, V155, P347, DOI 10.1016/j.talanta.2016.04.041.
   Sun DW, 2000, J FOOD ENG, V44, P245, DOI 10.1016/S0260-8774(00)00024-8.
   Nguyen TL, 2017, COMPLEXITY, P1, DOI {[}10.1155/2017/3083745, 10.1109/CLEOE-EQEC.2017.8086935].
   Tian LF, 1998, COMPUT ELECTRON AGR, V21, P153, DOI 10.1016/S0168-1699(98)00037-4.
   Tiwari G, 2013, POSTHARVEST BIOL TEC, V86, P221, DOI 10.1016/j.postharvbio.2013.07.009.
   WATANABE T, 1977, J PHYS CHEM-US, V81, P1845, DOI 10.1021/j100534a012.
   Wilhelm P, 2007, J PHOTOCH PHOTOBIO A, V185, P19, DOI 10.1016/j.jphotochem.2006.05.003.
   Wu XQ, 2013, ENVIRON INT, V60, P15, DOI 10.1016/j.envint.2013.07.015.
   Xie CQ, 2017, COMPUT ELECTRON AGR, V135, P154, DOI 10.1016/j.compag.2016.12.015.
   Yang C, 2014, COMPUT ELECTRON AGR, V109, P23, DOI 10.1016/j.compag.2014.08.009.
   Yang C, 2012, BIOSYST ENG, V113, P351, DOI 10.1016/j.biosystemseng.2012.09.009.
   Yang W, 2019, IEEE ACCESS, V7, P118239, DOI 10.1109/ACCESS.2019.2936892.
   Zhang Y, 2012, CROP PROT, V41, P96, DOI 10.1016/j.cropro.2012.05.007.
   Zhang Y, 2012, ISPRS J PHOTOGRAMM, V69, P65, DOI 10.1016/j.isprsjprs.2012.02.006.
   Zhang Z, 2016, IEEE J-STARS, V9, P640, DOI 10.1109/JSTARS.2015.2493887.},
Number-of-Cited-References = {58},
Times-Cited = {11},
Usage-Count-Last-180-days = {3},
Usage-Count-Since-2013 = {24},
Journal-ISO = {Comput. Electron. Agric.},
Doc-Delivery-Number = {KE7QT},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000508746900022},
OA = {Bronze},
DA = {2023-08-12},
}

@article{ WOS:000424259400003,
Author = {Dyrmann, Mads and Christiansen, Peter and Midtiby, Henrik Skov},
Title = {Estimation of plant species by classifying plants and leaves in
   combination},
Journal = {JOURNAL OF FIELD ROBOTICS},
Year = {2018},
Volume = {35},
Number = {2},
Pages = {202-212},
Month = {MAR},
Abstract = {Information on which weed species are present within agricultural fields
   is a prerequisite when using robots for site-specific weed management.
   This study proposes a method of improving robustness in shape-based
   classifying of seedlings toward natural shape variations within each
   plant species. To do so, leaves are separated from plants and classified
   individually together with the classification of the whole plant. The
   classification is based on common, rotation-invariant features. Based on
   previous classifications of leaves and plants, confidence in correct
   assignment is created for the plants and leaves, and this confidence is
   used to determine the species of the plant. By using this approach, the
   classification accuracy of eight plants species at early growth stages
   is increased from 93.9\% to 96.3\%.},
Publisher = {WILEY},
Address = {111 RIVER ST, HOBOKEN 07030-5774, NJ USA},
Type = {Article},
Language = {English},
Affiliation = {Dyrmann, M (Corresponding Author), Univ Southern Denmark, Maersk Mc Kinney Moller Inst, Odense, Denmark.
   Dyrmann, Mads; Midtiby, Henrik Skov, Univ Southern Denmark, Maersk Mc Kinney Moller Inst, Odense, Denmark.
   Christiansen, Peter, Aarhus Univ, Dept Engn, Aarhus, Denmark.},
DOI = {10.1002/rob.21734},
ISSN = {1556-4959},
EISSN = {1556-4967},
Keywords = {automated weed control; Bayes belief integration; classifier fusion;
   computer vision; excessive green; phenotyping; plant classification},
Keywords-Plus = {IDENTIFICATION; ALGORITHM; FEATURES; INDEXES; IMAGES},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {mady@mmmi.sdu.dk},
Affiliations = {University of Southern Denmark; Aarhus University},
ResearcherID-Numbers = {Midtiby, Henrik Skov/A-9246-2008
   },
ORCID-Numbers = {Midtiby, Henrik Skov/0000-0002-3310-5680
   Dyrmann, Mads/0000-0002-6510-1609
   Christiansen, Peter/0000-0003-1854-587X},
Funding-Acknowledgement = {GUDP (Gront Udviklings-og Demonstrations Program) under the Danish
   Ministry for Food, Agriculture and Fisheries},
Funding-Text = {The work was funded by GUDP (Gront Udviklings-og Demonstrations Program)
   under the Danish Ministry for Food, Agriculture and Fisheries.},
Cited-References = {{[}Anonymous], PUBLIC IMAGE DATABAS.
   {[}Anonymous], ELECT LETT.
   {[}Anonymous], 12898 EUR.
   {[}Anonymous], IMPORTANCE HERBICIDE.
   {[}Anonymous], AM SOC AGR ENG ASAE.
   {[}Anonymous], MINING MASSIVE DATA.
   {[}Anonymous], OFFICIAL J EUR UNION.
   {[}Anonymous], 24 INT C IM VIS COMP.
   {[}Anonymous], TECHNICAL REPORT.
   Astrand B, 2002, AUTON ROBOT, V13, P21, DOI 10.1023/A:1015674004201.
   Cerutti G, 2013, COMPUT VIS IMAGE UND, V117, P1482, DOI 10.1016/j.cviu.2013.07.003.
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199.
   Christensen S, 2003, WEED RES, V43, P276, DOI 10.1046/j.1365-3180.2003.00344.x.
   Cope JS, 2012, EXPERT SYST APPL, V39, P7562, DOI 10.1016/j.eswa.2012.01.073.
   Du JX, 2007, APPL MATH COMPUT, V185, P883, DOI 10.1016/j.amc.2006.07.072.
   Gerhards R, 2012, WEED RES, V52, P6, DOI 10.1111/j.1365-3180.2011.00893.x.
   Gerhards R, 1997, J AGRON CROP SCI, V178, P219, DOI 10.1111/j.1439-037X.1997.tb00494.x.
   Giselsson TM, 2013, SENSORS-BASEL, V13, P5585, DOI 10.3390/s130505585.
   Hearn DJ, 2009, TAXON, V58, P934, DOI 10.1002/tax.583021.
   KUHL FP, 1982, COMPUT VISION GRAPH, V18, P236, DOI 10.1016/0146-664X(82)90034-X.
   Meier U., 1997, BBCH MONOGRAPH.
   Meyer GE, 2008, COMPUT ELECTRON AGR, V63, P282, DOI 10.1016/j.compag.2008.03.009.
   Midtiby HS, 2012, BIOSYST ENG, V111, P83, DOI 10.1016/j.biosystemseng.2011.10.011.
   Neto JC, 2006, COMPUT ELECTRON AGR, V50, P121, DOI 10.1016/j.compag.2005.09.004.
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076.
   Peura M., 1997, Proceedings of the Third International Workshop on Visual Form. Advances in Visual Form Analysis, P443.
   Ruta D., 2000, Computing and Information Systems, V7, P1.
   Sogaard HT, 2007, BIOSYST ENG, V96, P315, DOI 10.1016/j.biosystemseng.2006.11.009.
   Tang L, 2000, T ASAE, V43, P1019, DOI 10.13031/2013.2970.
   Timmermann C., 2003, Precision Agriculture, V4, P249, DOI 10.1023/A:1024988022674.
   Weis M, 2008, GESUNDE PFLANZ, V60, P171, DOI 10.1007/s10343-008-0195-1.
   WOEBBECKE DM, 1995, T ASAE, V38, P259, DOI 10.13031/2013.27838.
   XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943.},
Number-of-Cited-References = {33},
Times-Cited = {13},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {28},
Journal-ISO = {J. Field Robot.},
Doc-Delivery-Number = {FV0PT},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000424259400003},
DA = {2023-08-12},
}

@article{ WOS:000804789800104,
Author = {Jiang, Zihan and Zhang, Renbo and Guo, Yubo and Hu, Mingrui and He, Liu
   and Li, Fumin and Zhu, Zimin},
Title = {Noise Interference Reduction in Vision Module of Intelligent Plant
   Cultivation Robot Using Better Cycle GAN},
Journal = {IEEE SENSORS JOURNAL},
Year = {2022},
Volume = {22},
Number = {11},
Pages = {11045-11055},
Month = {JUN 1},
Abstract = {The vision recognition module is one of the very important modules in
   the normal operation of the intelligent plant cultivation robot. In the
   original vision module, by improving the original YOLOV3(The algorithm
   proposed in YOLOv3: An Incremental Improvement), a more excellent YOLOV3
   was obtained to recognize plants under normal conditions. However, the
   improved YOLOV3 does not perform well in the visual recognition process
   when there is a lot of noise interference. To make the visual
   recognition module continue to work properly, in this paper, the better
   Cycle GAN (generative adversarial networks) model is proposed to deal
   with noise based on three common noises, and finally, through a lot of
   experiments, it is proved that the improvement has some significance for
   the vision recognition module, which extends the use of the vision
   recognition module and makes the intelligent plant cultivation robot
   avoid the interference of noise.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Zhu, ZM (Corresponding Author), Northeast Forestry Univ, Coll Informat \& Comp Engn, Harbin 150040, Peoples R China.
   Jiang, Zihan; Li, Fumin; Zhu, Zimin, Northeast Forestry Univ, Coll Informat \& Comp Engn, Harbin 150040, Peoples R China.
   Zhang, Renbo, Northeastern Univ, Coll Comp Sci \& Engn, Shenyang 110000, Peoples R China.
   Guo, Yubo, Northeast Forestry Univ, Coll Mech \& Elect Engn, Harbin 150040, Peoples R China.
   Hu, Mingrui, Changzhou Univ, Ali Sch Big Data, Changzhou 213164, Peoples R China.
   He, Liu, Sichuan Univ Sci \& Engn, Sch Biol Engn, Yibin 644000, Peoples R China.},
DOI = {10.1109/JSEN.2022.3164915},
ISSN = {1530-437X},
EISSN = {1558-1748},
Keywords = {Generative adversarial networks; Image recognition; Feature extraction;
   Robots; Generators; Visualization; Noise reduction; Plant recognition;
   robot; cyclegan; self-attention; denoising},
Keywords-Plus = {ATTENTION},
Research-Areas = {Engineering; Instruments \& Instrumentation; Physics},
Web-of-Science-Categories  = {Engineering, Electrical \& Electronic; Instruments \& Instrumentation;
   Physics, Applied},
Author-Email = {1095773538@qq.com
   zhangrenbo0628neu@163.com
   1227052776@qq.com
   2921615268@qq.com
   1224407977@qq.com
   1262842929@qq.com
   279745779@qq.com},
Affiliations = {Northeast Forestry University - China; Northeastern University - China;
   Northeast Forestry University - China; Changzhou University; Sichuan
   University of Science \& Engineering},
ResearcherID-Numbers = {Zhang, Renbo/GPV-6125-2022
   Jiang, ZiHan/ABB-5339-2021
   },
ORCID-Numbers = {Zhang, Renbo/0000-0002-1539-2583
   Jiang, ZiHan/0000-0002-1177-8833
   Guo, Yubo/0000-0002-2620-8243},
Funding-Acknowledgement = {College of Information and Computer Engineering, Northeast Forestry
   University},
Funding-Text = {This work was supported by the College of Information and Computer
   Engineering, Northeast Forestry University. The associate editor
   coordinating the review of this article and approving it for publication
   was Prof. Kazuaki Sawada.},
Cited-References = {Arjovsky M, 2017, PR MACH LEARN RES, V70.
   Belghazi M. I., 2018, ARXIV180201071.
   Bochkovskiy A., 2020, YOLOV4 OPTIMAL SPEED.
   Bowman S. R., 2015, CORR.
   Chaudhuri T, 2021, IEEE SENS J, V21, P7908, DOI 10.1109/JSEN.2020.3044388.
   Du HC, 2020, IEEE SENS J, V20, P11943, DOI 10.1109/JSEN.2019.2960318.
   Fan JP, 2015, IEEE T IMAGE PROCESS, V24, P4172, DOI 10.1109/TIP.2015.2457337.
   Funt B, 2000, EIGHTH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P112.
   Gemici Mevlana, 2018, ARXIV180509575.
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622.
   Guo CL, 2020, PROC CVPR IEEE, P1777, DOI 10.1109/CVPR42600.2020.00185.
   Han K, 2020, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR42600.2020.00165.
   He ML, 2020, IEEE INT C INT ROBOT, P7723, DOI 10.1109/IROS45743.2020.9341528.
   He ML, 2019, IEEE ACCESS, V7, P148531, DOI 10.1109/ACCESS.2019.2946855.
   He ML, 2019, IND ROBOT, V46, P682, DOI 10.1108/IR-12-2018-0260.
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI {[}10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372].
   Huang X, 2016, PROC IEEE C COMPUT V, P5077.
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632.
   Jegham I, 2021, IEEE SENS J, V21, P1918, DOI 10.1109/JSEN.2020.3019258.
   Jiang Y, 2017, IGGRAPH ASIA 2017 TECHNICAL BRIEFS (SA'17), DOI 10.1145/3145749.3149440.
   Jiang ZH, 2021, IEEE SENS J, V21, P19279, DOI 10.1109/JSEN.2021.3077272.
   Li CY, 2022, IEEE T PATTERN ANAL, V44, P4225, DOI 10.1109/TPAMI.2021.3063604.
   Li DL, 2020, IEEE SENS J, V20, P6582, DOI 10.1109/JSEN.2020.2976576.
   Li JW, 2020, IEEE ACCESS, V8, P179857, DOI 10.1109/ACCESS.2020.3028088.
   Li QL, 2021, IEEE SENS J, V21, P7458, DOI 10.1109/JSEN.2019.2921803.
   Lu HD, 2022, IEEE SENS J, V22, P17464, DOI 10.1109/JSEN.2021.3069452.
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304.
   Martinel N, 2020, IEEE T IMAGE PROCESS, V29, P7306, DOI 10.1109/TIP.2020.3000904.
   Miyato T., 2018, ARXIV180205957.
   Nowozin S., 2016, P ADV NEUR INF PROC, V29, P1.
   Qi GJ, 2020, INT J COMPUT VISION, V128, P1118, DOI 10.1007/s11263-019-01265-2.
   Redmon J, 2018, Arxiv, DOI arXiv:1804.02767.
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690.
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075.
   Sun YH, 2017, IEEE ICC.
   Tian C, 2020, IEEE SENS J, V20, P11935, DOI 10.1109/JSEN.2019.2959704.
   Vasavi S, 2021, IEEE SENS J, V21, P11417, DOI 10.1109/JSEN.2020.3007883.
   Vaswani A, 2017, ADV NEUR IN, V30.
   Wang C, 2021, IEEE SENS J, V21, P6468, DOI 10.1109/JSEN.2020.3040354.
   Wang SH, 2022, IEEE SENS J, V22, P17431, DOI 10.1109/JSEN.2021.3062442.
   Wei Xiang, 2018, ARXIV180301541.
   Xie YX, 2020, IEEE SENS J, V20, P359, DOI 10.1109/JSEN.2019.2942106.
   Yang JJ, 2020, IEEE ACCESS, V8, P103385, DOI 10.1109/ACCESS.2020.2999449.
   Yu LT, 2017, AAAI CONF ARTIF INTE, P2852.
   Zhao J, 2016, 2016 IEEE MTT-S INTERNATIONAL WIRELESS SYMPOSIUM (IWS), DOI 10.1109/ICSSSM.2016.7538614.
   Zheng LK, 2021, MEAS SCI TECHNOL, V32, DOI 10.1088/1361-6501/abfbaa.
   Zheng ZH, 2020, AAAI CONF ARTIF INTE, V34, P12993.},
Number-of-Cited-References = {47},
Times-Cited = {1},
Usage-Count-Last-180-days = {16},
Usage-Count-Since-2013 = {45},
Journal-ISO = {IEEE Sens. J.},
Doc-Delivery-Number = {1T5TE},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000804789800104},
DA = {2023-08-12},
}

@inproceedings{ WOS:000687834500067,
Author = {Pushpa, B. R. and Athira, P. R.},
Book-Group-Author = {IEEE},
Title = {Plant Species Recognition Based on Texture and Geometric Features of
   Leaf},
Booktitle = {ICSPC'21: 2021 3RD INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND
   COMMUNICATION (ICPSC)},
Series = {International Conference on Signal Processing and Communications SPCOM},
Year = {2021},
Pages = {315-320},
Note = {3rd International Conference on Signal Processing and Communication
   (ICPSC), Coimbatore, INDIA, MAY 13-14, 2021},
Organization = {Karunya Inst Technol \& Sci, Dept Elect \& Commun Engn; IEEE},
Abstract = {This paper proposed a methodology for classification and feature
   extraction of plant leaves. based on texture and geometric features. In
   India, a wide variety of medicinal plants are available, manual
   identification of the leaf is very problematic as it consume more time.
   Identifying a plant based on leaf features is a challenging task. For
   plant recognition most significant features such as geometry, shape,
   texture, color and vein patterns of leaf are utilized. In the first
   stage of proposed work leaf images are preprocessed to remove noise and
   to enhance the image that suits for further procedure. Texture features
   and geometrical features of leaves are computed. Finally, the extracted
   features are fed to the Multiple Support Vector Machine (MSVM)
   classifier. The experiments are carried out on a self-built database
   that contains 1800 images belonging to twenty different plant species.
   The selected texture and geometric features achieved an accuracy of
   96\%.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Pushpa, BR (Corresponding Author), Amrita Vishwa Vidyapeetham, Amrita Sch Arts \& Sci, Dept Comp Sci, Mysuru Campus, Mysore, Karnataka, India.
   Pushpa, B. R.; Athira, P. R., Amrita Vishwa Vidyapeetham, Amrita Sch Arts \& Sci, Dept Comp Sci, Mysuru Campus, Mysore, Karnataka, India.},
DOI = {10.1109/ICSPC51351.2021.9451683},
ISSN = {2474-9168},
EISSN = {2474-915X},
ISBN = {978-1-6654-2864-4},
Keywords = {MSVM; GLCM; Zernike Moments; Morphological Features; leaf classification},
Keywords-Plus = {SHAPE-FEATURES},
Research-Areas = {Engineering; Telecommunications},
Web-of-Science-Categories  = {Engineering, Electrical \& Electronic; Telecommunications},
Author-Email = {preeths1@gmail.com
   athirapalliyalil96@gmail.com},
Affiliations = {Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham Mysuru},
Cited-References = {Aakif A, 2015, BIOSYST ENG, V139, P66, DOI 10.1016/j.biosystemseng.2015.08.003.
   Alamoudi S, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207386.
   Anant Bhardwaj, 2013, International Journal of Innovation and Applied Studies, V3, P237.
   Arivazhagan S., 2013, Agricultural Engineering International: CIGR Journal, V15, P211.
   Arun C. H., 2013, INT J COMPUTER APPL, V62, P1, DOI 10.5120/10129-4920.
   Bambil Deborah, 2020, Environment Systems \& Decisions, V40, P480, DOI 10.1007/s10669-020-09769-w.
   Chaki J, 2015, PATTERN RECOGN LETT, V58, P61, DOI 10.1016/j.patrec.2015.02.010.
   Chen YJ, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21010212.
   Ghazi MM, 2017, NEUROCOMPUTING, V235, P228, DOI 10.1016/j.neucom.2017.01.018.
   Harsani P., 2017, J ILMIAH KURSOR, P181.
   Kan H. X., 2017, Pattern Recognition and Image Analysis, V27, P581, DOI 10.1134/S105466181703018X.
   Keivani M, 2020, TRAIT SIGNAL, V37, P17, DOI 10.18280/ts.370103.
   Le TL, 2014, 5 S INF COMM TECHN H, P146.
   Manousakis Nikolaos M., 2016, 2016 Power Systems Computation Conference (PSCC), P1, DOI 10.1109/PSCC.2016.7540813.
   Mishra P. K., 2012, 2012 International Conference on Advances in Engineering, Science and Management (ICAESM), P68.
   Munisami T, 2015, PROCEDIA COMPUT SCI, V58, P740, DOI 10.1016/j.procs.2015.08.095.
   Nair BJ, 2020, INT J PHARM RES, V12, P783.
   Nijalingappa P, 2015, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON APPLIED AND THEORETICAL COMPUTING AND COMMUNICATION TECHNOLOGY (ICATCCT), P338, DOI 10.1109/ICATCCT.2015.7456906.
   Pooja V, 2017, 2017 IEEE TECHNOLOGICAL INNOVATIONS IN ICT FOR AGRICULTURE AND RURAL DEVELOPMENT (TIAR), P130, DOI 10.1109/TIAR.2017.8273700.
   Pushpa B. R., 2015, INT J APPL ENG RES I, V10.
   Pushpa BR, 2016, INT J APPL ENG RES, V11, P5142.
   Rani N. Shobha, 2020, Proceedings of Second International Conference on Inventive Research in Computing Applications (ICIRCA 2020), P213, DOI 10.1109/ICIRCA48905.2020.9183160.
   Sathaliyawala T, 2013, IMMUNITY, P1.
   Tan JW, 2020, IEEE ACM T COMPUT BI, V17, P82, DOI 10.1109/TCBB.2018.2848653.
   VijayaLakshmi B, 2016, COMPUT ELECTRON AGR, V125, P99, DOI 10.1016/j.compag.2016.04.033.
   Yigit E, 2019, COMPUT ELECTRON AGR, V156, P369, DOI 10.1016/j.compag.2018.11.036.
   Zhang CL, 2020, AGRONOMY-BASEL, V10, DOI 10.3390/agronomy10070972.},
Number-of-Cited-References = {27},
Times-Cited = {0},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {2},
Doc-Delivery-Number = {BS1DM},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000687834500067},
DA = {2023-08-12},
}

@article{ WOS:000613400300016,
Author = {Abouzahir, Saad and Sadik, Mohamed and Sabir, Essaid},
Title = {Paper Bag-of-visual-words-augmented Histogram of Oriented Gradients for
   efficient weed detection},
Journal = {BIOSYSTEMS ENGINEERING},
Year = {2021},
Volume = {202},
Pages = {179-194},
Month = {FEB},
Abstract = {As season-long weeds competition produces important yield losses, early
   detection of these plants is essential to sustain productivity. Machine
   vision as a non-destructive surveying technique requires features that
   can describe weeds in a real field case. Colours and shapes provide good
   results in controlled conditions. However, when different crops or weeds
   appear in clusters, such solutions fail to meet satisfactory
   performance. Therefore, considering features that are less specific to
   field conditions is crucial for integrated weed management. In this
   study, we provide effective use of the Histogram of Oriented Gradients
   (HOG) to improve its performance for weed detection. The concept is
   based on the Bag-of-Visual-Words (BOVW) approach. We use the HOG blocks
   as keypoints to generate the visual-words, and the features vectors are
   the histograms of these visual words. Next, we use the Backpropagation
   Neural Network to detect weeds and classify plants for three different
   crop fields. Namely, we consider sugar-beet, soybean, and carrot as
   target crops. Results demonstrate that the proposed weed detection
   system can locate weeds for site-specific treatment and selective
   spraying of herbicides. The proposed BOVW-based HOG can discriminate
   between weeds and crops with an accuracy of 97.7\%, 93\%, and 96.6\% in
   sugar-beet, carrot and soybean fields respectively. For plant
   classification, our method can classify plants with an accuracy of
   90.4\%, 92.4\%, and 94.1\% in sugar beet, carrot and soybean fields
   respectively. Our results turn out 37.6\% better than the classical HOG
   that produces an accuracy ranging from 71.2\% to 83.3\% in weed
   detection and 49.1\%-82.1\% in plant classification. (c) 2020 IAgrE.
   Published by Elsevier Ltd. All rights reserved.},
Publisher = {ACADEMIC PRESS INC ELSEVIER SCIENCE},
Address = {525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA},
Type = {Article},
Language = {English},
Affiliation = {Abouzahir, S (Corresponding Author), Hassan II Univ Casablanca, ENSEM, LRI Lab, NEST Res Grp, Casablanca, Morocco.
   Abouzahir, Saad; Sadik, Mohamed; Sabir, Essaid, Hassan II Univ Casablanca, ENSEM, LRI Lab, NEST Res Grp, Casablanca, Morocco.
   Sabir, Essaid, Univ Quebec Montreal UQAM, Dept Comp Sci, Montreal, PQ H2L 2C4, Canada.},
DOI = {10.1016/j.biosystemseng.2020.11.005},
EarlyAccessDate = {JAN 2021},
ISSN = {1537-5110},
EISSN = {1537-5129},
Keywords = {Computer vision; Weed detection; Neural Network; Bag of visual;
   Histogram of oriented gradients},
Keywords-Plus = {SUPPORT VECTOR MACHINE; RUMEX-OBTUSIFOLIUS; SPECIES DISCRIMINATION;
   CLASSIFICATION; VISION; IDENTIFICATION; CROP; SYSTEMS; RICE},
Research-Areas = {Agriculture},
Web-of-Science-Categories  = {Agricultural Engineering; Agriculture, Multidisciplinary},
Author-Email = {saad.abouzahir@ensem.ac.ma
   m.sadik@ensem.ac.ma
   e.sabir@ensem.ac.ma},
Affiliations = {Hassan II University of Casablanca; University of Quebec; University of
   Quebec Montreal},
ResearcherID-Numbers = {Abouzahir, Saad/X-7053-2019
   Sabir, Essaid/HZL-7607-2023},
ORCID-Numbers = {Abouzahir, Saad/0000-0003-4555-4181
   Sabir, Essaid/0000-0001-9946-5761},
Funding-Acknowledgement = {Moroccan Ministry of Higher Education and Scientific Research; National
   Centre for Scientific and Technical Research},
Funding-Text = {This work has been conducted within the framework of the Meteorological
   Station Project funded by the Moroccan Ministry of Higher Education and
   Scientific Research, and the National Centre for Scientific and
   Technical Research.},
Cited-References = {Abouzahir S, 2018, 2018 INTERNATIONAL CONFERENCE ON ELECTRONICS, CONTROL, OPTIMIZATION AND COMPUTER SCIENCE (ICECOCS).
   Abouzahir S, 2017, LECT NOTES COMPUT SC, V10542, P319, DOI 10.1007/978-3-319-68179-5\_28.
   Ahmed F, 2012, CROP PROT, V40, P98, DOI 10.1016/j.cropro.2012.04.024.
   Aitkenhead MJ, 2003, COMPUT ELECTRON AGR, V39, P157, DOI 10.1016/S0168-1699(03)00076-0.
   Bakhshipour A, 2018, COMPUT ELECTRON AGR, V145, P153, DOI 10.1016/j.compag.2017.12.032.
   Bakhshipour A, 2017, BIOSYST ENG, V157, P1, DOI 10.1016/j.biosystemseng.2017.02.002.
   Barrero O, 2018, PRECIS AGRIC, V19, P809, DOI 10.1007/s11119-017-9558-x.
   Binch A, 2017, COMPUT ELECTRON AGR, V140, P123, DOI 10.1016/j.compag.2017.05.018.
   Bosilj P, 2018, IEEE ROBOT AUTOM LET, V3, P2950, DOI 10.1109/LRA.2018.2848305.
   Cheng BB, 2015, LECT NOTES ARTIF INT, V9119, P517, DOI 10.1007/978-3-319-19324-3\_46.
   Csurka G., 2004, WORKSH STAT LEARN CO, V1, P1, DOI DOI 10.1234/12345678.
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177.
   Dauda S. M., 2013, Academic Research International, V4, P70.
   Farooq A, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11141692.
   Farooq A, 2019, IEEE GEOSCI REMOTE S, V16, P183, DOI 10.1109/LGRS.2018.2869879.
   Ferreira AD, 2017, COMPUT ELECTRON AGR, V143, P314, DOI 10.1016/j.compag.2017.10.027.
   Gai JY, 2020, J FIELD ROBOT, V37, P35, DOI 10.1002/rob.21897.
   Gini R, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7080315.
   Haug S, 2015, LECT NOTES COMPUT SC, V8928, P105, DOI {[}10.1007/978-3-319-16220-1-8, 10.1007/978-3-319-16220-1\_8].
   Hiremath S, 2012, WEED RES, V52, P430, DOI 10.1111/j.1365-3180.2012.00931.x.
   Hiremath S, 2013, MACH VISION APPL, V24, P845, DOI 10.1007/s00138-012-0470-0.
   Herrera PJ, 2014, SENSORS-BASEL, V14, P15304, DOI 10.3390/s140815304.
   Kaaniche MB, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P140, DOI 10.1109/AVSS.2009.26.
   Konecny J, 2014, J MACH LEARN RES, V15, P2513.
   Kumar D. A., 2016, ICTACT J IMAGE VIDEO, V6.
   Lottes P, 2017, J FIELD ROBOT, V34, P1160, DOI 10.1002/rob.21675.
   MacQueen J.B., 1967, 5 BERKELEY S MATH ST, P281, DOI DOI 10.1007/S11665-016-2173-6.
   Milioto A, 2018, IEEE INT CONF ROBOT, P2229.
   Potena C, 2017, ADV INTELL SYST COMP, V531, P105, DOI 10.1007/978-3-319-48036-7\_9.
   Rasti P, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030249.
   Rehman TU, 2019, COMPUT ELECTRON AGR, V162, P1, DOI 10.1016/j.compag.2019.03.023.
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7.
   Rumpf T, 2012, COMPUT ELECTRON AGR, V80, P89, DOI 10.1016/j.compag.2011.10.018.
   Shirzadifar A, 2018, BIOSYST ENG, V171, P143, DOI 10.1016/j.biosystemseng.2018.04.019.
   Sibil A, 2012, J NONDESTRUCT EVAL, V31, P169, DOI 10.1007/s10921-012-0132-1.
   Slaughter DC, 2008, COMPUT ELECTRON AGR, V61, P63, DOI 10.1016/j.compag.2007.05.008.
   Tang JL, 2017, COMPUT ELECTRON AGR, V135, P63, DOI 10.1016/j.compag.2017.01.001.
   Thorp K. R., 2004, Precision Agriculture, V5, P477, DOI 10.1007/s11119-004-5321-1.
   van Evert FK, 2009, WEED RES, V49, P164, DOI 10.1111/j.1365-3180.2008.00682.x.
   van Evert FK, 2011, J FIELD ROBOT, V28, P264, DOI 10.1002/rob.20377.
   Vi Nguyen Thanh Le, 2019, Information Processing in Agriculture, V6, P116, DOI 10.1016/j.inpa.2018.08.002.
   Vondricka J, 2009, PRECIS AGRIC, V10, P421, DOI 10.1007/s11119-008-9093-x.
   Wang AC, 2019, COMPUT ELECTRON AGR, V158, P226, DOI 10.1016/j.compag.2019.02.005.
   Wang YR, 2019, INT J REMOTE SENS, V40, P7356, DOI 10.1080/01431161.2018.1513669.
   WOEBBECKE DM, 1995, T ASAE, V38, P259, DOI 10.13031/2013.27838.
   Young SL, 2018, WEED TECHNOL, V32, P7, DOI 10.1017/wet.2017.70.
   Zhang CH, 2012, PRECIS AGRIC, V13, P693, DOI 10.1007/s11119-012-9274-5.},
Number-of-Cited-References = {47},
Times-Cited = {16},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {13},
Journal-ISO = {Biosyst. Eng.},
Doc-Delivery-Number = {QA4FG},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000613400300016},
DA = {2023-08-12},
}

@article{ WOS:000666785300001,
Author = {Choudhury, Md Abdul Mueed and Marcheggiani, Ernesto and Galli, Andrea
   and Modica, Giuseppe and Somers, Ben},
Title = {Mapping the Urban Atmospheric Carbon Stock by LiDAR and WorldView-3 Data},
Journal = {FORESTS},
Year = {2021},
Volume = {12},
Number = {6},
Month = {JUN},
Abstract = {Currently, the worsening impacts of urbanizations have been impelled to
   the importance of monitoring and management of existing urban trees,
   securing sustainable use of the available green spaces. Urban tree
   species identification and evaluation of their roles in atmospheric
   Carbon Stock (CS) are still among the prime concerns for city planners
   regarding initiating a convenient and easily adaptive urban green
   planning and management system. A detailed methodology on the urban tree
   carbon stock calibration and mapping was conducted in the urban area of
   Brussels, Belgium. A comparative analysis of the mapping outcomes was
   assessed to define the convenience and efficiency of two different
   remote sensing data sources, Light Detection and Ranging (LiDAR) and
   WorldView-3 (WV-3), in a unique urban area. The mapping results were
   validated against field estimated carbon stocks. At the initial stage,
   dominant tree species were identified and classified using the
   high-resolution WorldView3 image, leading to the final carbon stock
   mapping based on the dominant species. An object-based image analysis
   approach was employed to attain an overall accuracy (OA) of 71\% during
   the classification of the dominant species. The field estimations of
   carbon stock for each plot were done utilizing an allometric model based
   on the field tree dendrometric data. Later based on the correlation
   among the field data and the variables (i.e., Normalized Difference
   Vegetation Index, NDVI and Crown Height Model, CHM) extracted from the
   available remote sensing data, the carbon stock mapping and validation
   had been done in a GIS environment. The calibrated NDVI and CHM had been
   used to compute possible carbon stock in either case of the WV-3 image
   and LiDAR data, respectively. A comparative discussion has been
   introduced to bring out the issues, especially for the developing
   countries, where WV-3 data could be a better solution over the hardly
   available LiDAR data. This study could assist city planners in
   understanding and deciding the applicability of remote sensing data
   sources based on their availability and the level of expediency,
   ensuring a sustainable urban green management system.},
Publisher = {MDPI},
Address = {ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND},
Type = {Article},
Language = {English},
Affiliation = {Choudhury, MAM; Marcheggiani, E (Corresponding Author), Marche Polytech Univ, Dept Agr Food \& Environm Sci, I-60131 Ancona, Italy.
   Marcheggiani, E (Corresponding Author), Katholieke Univ Leuven, Dept Earth \& Environm Sci, Div Forest Nat \& Landscape, B-3001 Leuven, Belgium.
   Choudhury, Md Abdul Mueed; Marcheggiani, Ernesto; Galli, Andrea, Marche Polytech Univ, Dept Agr Food \& Environm Sci, I-60131 Ancona, Italy.
   Marcheggiani, Ernesto; Somers, Ben, Katholieke Univ Leuven, Dept Earth \& Environm Sci, Div Forest Nat \& Landscape, B-3001 Leuven, Belgium.
   Modica, Giuseppe, Univ Mediterranea Reggio Calabria, Dipartimento Agr, I-89122 Reggio Di Calabria, Italy.},
DOI = {10.3390/f12060692},
Article-Number = {692},
EISSN = {1999-4907},
Keywords = {urban trees; Geospatial Object-Based Image Analysis (GEOBIA); Carbon
   Stock (CS) mapping; allometric model; WorldView-3 (WV-3) imagery; aerial
   Light Detection and Ranging (LiDAR) data},
Keywords-Plus = {TREE SPECIES CLASSIFICATION; REMOTE-SENSING DATA; MACHINE LEARNING
   ALGORITHMS; LANDSAT TM DATA; ABOVEGROUND BIOMASS; FOREST STRUCTURE;
   AIRBORNE LIDAR; IMAGE-ANALYSIS; BIOPHYSICAL PARAMETERS; BUILDING
   EXTRACTION},
Research-Areas = {Forestry},
Web-of-Science-Categories  = {Forestry},
Author-Email = {m.choudhury@pm.univpm.it
   e.marcheggiani@staff.univpm.it
   a.galli@staff.univpm.it
   giuseppe.modica@unirc.it
   ben.somers@kuleuven.be},
Affiliations = {Marche Polytechnic University; KU Leuven; Universita Mediterranea di
   Reggio Calabria},
ResearcherID-Numbers = {Marcheggiani, Ernesto/AGM-7101-2022
   Modica, Giuseppe/H-3763-2012
   galli, andrea/HTP-5003-2023
   },
ORCID-Numbers = {Marcheggiani, Ernesto/0000-0002-6879-9942
   Modica, Giuseppe/0000-0002-0388-0256
   Choudhury, MD Abdul Mueed/0000-0003-0773-6021
   GALLI, Andrea/0000-0003-2683-2094
   Somers, Ben/0000-0002-7875-107X},
Cited-References = {Achard F, 2002, SCIENCE, V297, P999, DOI 10.1126/science.1070656.
   Adelabu S, 2013, J APPL REMOTE SENS, V7, DOI 10.1117/1.JRS.7.073480.
   AGD, 2005, EC VERS 5 OBJ OR IM.
   Alonzo M, 2016, URBAN FOR URBAN GREE, V17, P135, DOI 10.1016/j.ufug.2016.04.003.
   Alonzo M, 2015, REMOTE SENS ENVIRON, V162, P141, DOI 10.1016/j.rse.2015.02.025.
   Alonzo M, 2014, REMOTE SENS ENVIRON, V148, P70, DOI 10.1016/j.rse.2014.03.018.
   {[}Anonymous], 2001, LINNAEUS COMPLEAT NA.
   {[}Anonymous], 2007, ASSESSING URBAN FORE.
   {[}Anonymous], 2000, ENV INFORM PLANNING.
   Azeez OS, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9020313.
   Baines O, 2020, URBAN FOR URBAN GREE, V50, DOI 10.1016/j.ufug.2020.126653.
   Band LE, 2005, ECOSYSTEM FUNCTION IN HETEROGENEOUS LANDSCAPES, P257, DOI 10.1007/0-387-24091-8\_13.
   Banko G., 1998, REV ASSESSING ACCURA.
   Banks, 1999, P URB DAT MAN S.
   Banks J.C., 1999, URBAN ECOSYST, V3, P35, DOI DOI 10.1023/A:1009509519236.
   Behera SK, 2017, ECOL ENG, V99, P513, DOI 10.1016/j.ecoleng.2016.11.046.
   Benz UC, 2004, ISPRS J PHOTOGRAMM, V58, P239, DOI 10.1016/j.isprsjprs.2003.10.002.
   Biomass B.S.E, 1986, ROME FAO PAP, V134.
   Birdal AC, 2017, GEOMAT NAT HAZ RISK, V8, P1144, DOI 10.1080/19475705.2017.1300608.
   Blanzieri E, 2008, IEEE T GEOSCI REMOTE, V46, P1804, DOI 10.1109/TGRS.2008.916090.
   Blaschke T, 2010, ISPRS J PHOTOGRAMM, V65, P2, DOI 10.1016/j.isprsjprs.2009.06.004.
   Brack CL, 2002, ENVIRON POLLUT, V116, pS195, DOI 10.1016/S0269-7491(01)00251-2.
   Brown S., 1997, FAO Forestry Paper.
   Cairns MA, 1997, OECOLOGIA, V111, P1, DOI 10.1007/s004420050201.
   Carleer A, 2004, PHOTOGRAMM ENG REM S, V70, P135, DOI 10.14358/PERS.70.1.135.
   Carneiro FM, 2019, ENG AGR-JABOTICABAL, V39, P33, DOI {[}10.1590/1809-4430-eng.agric.v39nep33-40/2019, 10.1590/1809-4430-Eng.Agric.v39nep33-40/2019].
   Castel T, 2002, REMOTE SENS ENVIRON, V79, P30, DOI 10.1016/S0034-4257(01)00236-X.
   Caynes RJC, 2016, URBAN ECOSYST, V19, P1749, DOI 10.1007/s11252-016-0571-z.
   Chambers D, 2013, FOREST ECOL MANAG, V291, P20, DOI 10.1016/j.foreco.2012.10.046.
   Choudhury MAM, 2020, FORESTS, V11, DOI 10.3390/f11111226.
   Clewley D, 2012, REMOTE SENS-BASEL, V4, P2236, DOI 10.3390/rs4082236.
   Coelho AP, 2018, PESQUI AGROPECU TROP, V48, P109, DOI 10.1590/1983-40632018v4851523.
   COHEN J, 1968, PSYCHOL BULL, V70, P213, DOI 10.1037/h0026256.
   Coulibaly L., 2008, IGARSS 2008 2008 IEE, DOI {[}10.1109/IGARSS.2008.4779342, DOI 10.1109/IGARSS.2008.4779342].
   Dalponte M, 2008, IEEE T GEOSCI REMOTE, V46, P1416, DOI 10.1109/TGRS.2008.916480.
   de Vries S, 2013, SOC SCI MED, V94, P26, DOI 10.1016/j.socscimed.2013.06.030.
   Degerickx J, 2018, INT J APPL EARTH OBS, V73, P26, DOI 10.1016/j.jag.2018.05.021.
   Degerickx J, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12052144.
   De Pinho CMD, 2012, INT J REMOTE SENS, V33, P5973, DOI 10.1080/01431161.2012.675451.
   Duro DC, 2012, REMOTE SENS ENVIRON, V118, P259, DOI 10.1016/j.rse.2011.11.020.
   El-naggar AM, 2018, ALEX ENG J, V57, P3089, DOI 10.1016/j.aej.2018.10.001.
   Endreny T, 2017, ECOL MODEL, V360, P328, DOI 10.1016/j.ecolmodel.2017.07.016.
   Estoque RC, 2015, GEOCARTO INT, V30, P1113, DOI 10.1080/10106049.2015.1027291.
   Fang F, 2020, REMOTE SENS ENVIRON, V246, DOI 10.1016/j.rse.2020.111811.
   Fassnacht FE, 2016, REMOTE SENS ENVIRON, V186, P64, DOI 10.1016/j.rse.2016.08.013.
   Ferrini F., 2011, J BIODIVERSITY ECOLO, V1, P1.
   Fonton N. H., 2017, Open Journal of Forestry, V7, P388, DOI 10.4236/ojf.2017.74023.
   Food and Agriculture Organization, 2010, FOOD AGR ORG UN, P2012.
   Foody G, 2010, PHOTOGRAMM REC, V25, P204, DOI {[}DOI 10.1111/J.1477-9730.2010.00574\_2.X, 10.1111/j.1477-9730.2010.00574\_2.x].
   Foody GM, 2003, REMOTE SENS ENVIRON, V85, P463, DOI 10.1016/S0034-4257(03)00039-7.
   Fu BL, 2017, ECOL INDIC, V73, P105, DOI 10.1016/j.ecolind.2016.09.029.
   Gallaun H, 2010, FOREST ECOL MANAG, V260, P252, DOI 10.1016/j.foreco.2009.10.011.
   Gholoobi M, 2015, J APPL REMOTE SENS, V9, DOI 10.1117/1.JRS.9.096052.
   Ghosh A, 2014, INT J APPL EARTH OBS, V26, P49, DOI 10.1016/j.jag.2013.05.017.
   Gilbertson JK, 2017, COMPUT ELECTRON AGR, V134, P151, DOI 10.1016/j.compag.2016.12.006.
   Goodwin NR, 2009, CAN J REMOTE SENS, V35, P297, DOI 10.5589/m09-015.
   Goslee K., 2010, LEAF TECHNICIAL GUID.
   Goswami S., 2015, PEERJ, V3, DOI {[}10.7287/peerj.preprints.913v1, DOI 10.7287/PEERJ.PREPRINTS.913V1].
   Gregoire T.G., 2007, SAMPLING STRATEGIES.
   Gu H, 2016, BIOGEOSCIENCES, V13, P6321, DOI 10.5194/bg-13-6321-2016.
   Gupta D., 2012, INT J COMPUT APPL, V55, P39.
   Hansch R, 2021, IEEE GEOSCI REMOTE S, V18, P366, DOI 10.1109/LGRS.2020.2972955.
   Han RM, 2020, J SENSORS, V2020, DOI 10.1155/2020/8855509.
   Hauglin M., 2016, INA FAGRAPPORT.
   He SB, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12233928.
   Hellden U., 1980, TEST LANDSAT 2 IMAGE.
   Hossain MD, 2019, ISPRS J PHOTOGRAMM, V150, P115, DOI 10.1016/j.isprsjprs.2019.02.009.
   Houghton RA, 2012, BIOGEOSCIENCES, V9, P5125, DOI 10.5194/bg-9-5125-2012.
   Huang JF, 2019, ISPRS J PHOTOGRAMM, V151, P91, DOI 10.1016/j.isprsjprs.2019.02.019.
   Huang WL, 2019, ENVIRON RES LETT, V14, DOI 10.1088/1748-9326/ab2917.
   Hummel S, 2011, J FOREST, V109, P267.
   Hurtt G, 2019, ENVIRON RES LETT, V14, DOI 10.1088/1748-9326/ab0bbe.
   Hurtt GC, 2010, J GEOPHYS RES-BIOGEO, V115, DOI 10.1029/2009JG000937.
   Immitzer M, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8030166.
   Issa S, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12122008.
   Jabari S, 2013, ALGORITHMS, V6, P762, DOI 10.3390/a6040762.
   Jacobs, 2018, ANN REPORT.
   Jebur MN, 2014, GEOCARTO INT, V29, P792, DOI 10.1080/10106049.2013.848944.
   Jensen RR, 2012, GEOCARTO INT, V27, P443, DOI 10.1080/10106049.2011.638989.
   Jo HK, 2019, URBAN FOR URBAN GREE, V41, P48, DOI 10.1016/j.ufug.2019.03.009.
   Johnson BA, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10010073.
   Jombo S, 2020, COGENT SOC SCI, V6, DOI 10.1080/23311886.2020.1754146.
   Jones TG, 2010, REMOTE SENS ENVIRON, V114, P2841, DOI 10.1016/j.rse.2010.07.002.
   Jung M., 2013, PEERJ PREPR, DOI {[}10.7287/peerj.preprints.116v2, DOI 10.7287/PEERJ.PREPRINTS.116V2].
   Kankare V, 2013, REMOTE SENS-BASEL, V5, P2257, DOI 10.3390/rs5052257.
   Kanniah KD, 2014, IOP C SER EARTH ENV, V18, DOI 10.1088/1755-1315/18/1/012151.
   Karakus P, 2016, INT ARCH PHOTOGRAMM, V41, P235, DOI 10.5194/isprsarchives-XLI-B7-235-2016.
   Kim S, 2011, REMOTE SENS ENVIRON, V115, P3329, DOI 10.1016/j.rse.2011.07.016.
   Kim S, 2009, REMOTE SENS ENVIRON, V113, P1575, DOI 10.1016/j.rse.2009.03.017.
   Kobayashi S, 2012, REMOTE SENS-BASEL, V4, P3058, DOI 10.3390/rs4103058.
   Koch, 2013, TREE SPECIES RECOGNI, V27, P135.
   Kucharczyk M, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12122012.
   Kumar L, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9090935.
   Laliberte AS, 2006, INT GEOSCI REMOTE SE, P3923, DOI 10.1109/IGARSS.2006.1006.
   LAND INFO Worldwide Mapping L, SAT IM PRIC SAT IM S.
   Le Louarn M, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9090916.
   Lee DS, 2003, PHOTOGRAMM ENG REM S, V69, P143, DOI 10.14358/PERS.69.2.143.
   Li D, 2015, REMOTE SENS-BASEL, V7, P16917, DOI 10.3390/rs71215861.
   Li XJ, 2013, INT J REMOTE SENS, V34, P4655, DOI 10.1080/01431161.2013.780669.
   Liu LX, 2017, REMOTE SENS ENVIRON, V200, P170, DOI 10.1016/j.rse.2017.08.010.
   Losi CJ, 2003, FOREST ECOL MANAG, V184, P355, DOI 10.1016/S0378-1127(03)00160-9.
   Lu DS, 2006, INT J REMOTE SENS, V27, P1297, DOI 10.1080/01431160500486732.
   Lumnitz S, 2021, ISPRS J PHOTOGRAMM, V175, P144, DOI 10.1016/j.isprsjprs.2021.01.016.
   Makinde E.O., 2016, GEOINFORMATICS FCE C, V15, P59, DOI {[}DOI 10.14311/GI.15.2.5, 10.14311/gi.15.2.5].
   Marshall, 2013, ECOLOGICAL HETEROGEN, P107.
   Martins VS, 2020, ISPRS J PHOTOGRAMM, V168, P56, DOI 10.1016/j.isprsjprs.2020.08.004.
   Mas J.F., 2008, COMP PERFORMANCE PIX.
   Maynard CL, 2007, GISCI REMOTE SENS, V44, P68, DOI 10.2747/1548-1603.44.1.68.
   Mitchell MGE, 2018, SCI TOTAL ENVIRON, V622, P57, DOI 10.1016/j.scitotenv.2017.11.255.
   Modica G, 2020, COMPUT ELECTRON AGR, V175, DOI 10.1016/j.compag.2020.105500.
   Mokany K, 2006, GLOBAL CHANGE BIOL, V12, P84, DOI 10.1111/j.1365-2486.2005.001043.x.
   Moser G, 2013, P IEEE, V101, P631, DOI 10.1109/JPROC.2012.2211551.
   Mustafa YT, 2015, ISPRS ANN PHOTO REM, VII-2, P175, DOI 10.5194/isprsannals-II-2-W2-175-2015.
   Myeong S., 2001, URBAN ECOSYST, V5, P243, DOI DOI 10.1023/A:1025687711588.
   Myint SW, 2011, REMOTE SENS ENVIRON, V115, P1145, DOI 10.1016/j.rse.2010.12.017.
   Nitoslawski SA, 2019, SUSTAIN CITIES SOC, V51, DOI 10.1016/j.scs.2019.101770.
   Nolke N, 2021, FORESTS, V12, DOI 10.3390/f12020220.
   Nowak D.J., CHICAGOS URBAN FORES.
   Nowak DJ, 2002, ENVIRON POLLUT, V116, P381, DOI 10.1016/S0269-7491(01)00214-7.
   Orka HO, 2013, SCAND J FOREST RES, V28, P677, DOI 10.1080/02827581.2013.793386.
   Orka HO, 2009, REMOTE SENS ENVIRON, V113, P1163, DOI 10.1016/j.rse.2009.02.002.
   OUGHTON RAH, 2005, GLOBAL CHANGE BIOL, V11, P945, DOI DOI 10.1111/J.1365-2486.2005.00955.X.
   Ouma YO, 2008, ISPRS J PHOTOGRAMM, V63, P333, DOI 10.1016/j.isprsjprs.2007.10.006.
   Padwick C., 2010, P ASPRS ANN C SAN, V2630, P1.
   Panel, 2007, CLIMATE CHANGE IPCC.
   PINKHAM RS, 1987, J R STAT SOC C-APPL, V36, P370.
   Platt RV, 2008, PROF GEOGR, V60, P87, DOI 10.1080/00330120701724152.
   Plowright AA, 2016, URBAN FOR URBAN GREE, V19, P140, DOI 10.1016/j.ufug.2016.06.026.
   Pratico S, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13040586.
   Pu RL, 2020, URBAN FOR URBAN GREE, V53, DOI 10.1016/j.ufug.2020.126675.
   Pu RL, 2012, REMOTE SENS ENVIRON, V124, P516, DOI 10.1016/j.rse.2012.06.011.
   Puissant A, 2014, INT J APPL EARTH OBS, V26, P235, DOI 10.1016/j.jag.2013.07.002.
   Qian YG, 2020, ECOL PROCESS, V9, DOI 10.1186/s13717-020-00266-1.
   Qian YG, 2020, URBAN FOR URBAN GREE, V53, DOI 10.1016/j.ufug.2020.126661.
   Raciti SM, 2014, SCI TOTAL ENVIRON, V500, P72, DOI 10.1016/j.scitotenv.2014.08.070.
   Rahetlah B. V., 2014, RELATIONSHIP NORMALI.
   Rasti B, 2020, INT GEOSCI REMOTE SE, P2659, DOI 10.1109/IGARSS39084.2020.9323179.
   Ren ZB, 2015, URBAN FOR URBAN GREE, V14, P336, DOI 10.1016/j.ufug.2015.03.008.
   Robinson C, 2013, REMOTE SENS-BASEL, V5, P1001, DOI 10.3390/rs5031001.
   Rosenfeld AH, 1998, ENERG BUILDINGS, V28, P51, DOI 10.1016/S0378-7788(97)00063-7.
   Salih AAM, 2017, EGYPT J REMOTE SENS, V20, pS21, DOI 10.1016/j.ejrs.2016.12.008.
   Shen GR, 2020, URBAN FOR URBAN GREE, V51, DOI 10.1016/j.ufug.2020.126655.
   Shrestha R, 2012, REMOTE SENS-BASEL, V4, P484, DOI 10.3390/rs4020484.
   Simonson WD, 2014, METHODS ECOL EVOL, V5, P719, DOI 10.1111/2041-210X.12219.
   Simpkin P., 2017, CANOPY COVER ENGLAND, P5.
   So-In C, 2014, INT CONF DIGIT INFO, P90, DOI 10.1109/DICTAP.2014.6821663.
   Solano F, 2019, INT J APPL EARTH OBS, V83, DOI 10.1016/j.jag.2019.101912.
   Somers B, 2014, INT J APPL EARTH OBS, V31, P57, DOI 10.1016/j.jag.2014.02.006.
   Steenberg JWN, 2019, LANDSCAPE URBAN PLAN, V186, P24, DOI 10.1016/j.landurbplan.2019.02.006.
   Sturiale L, 2019, CLIMATE, V7, DOI 10.3390/cli7100119.
   Su TF, 2020, ISPRS J PHOTOGRAMM, V168, P89, DOI 10.1016/j.isprsjprs.2020.07.017.
   Tabacchi G, 2011, EUR J FOREST RES, V130, P911, DOI 10.1007/s10342-011-0481-9.
   Tzoulas K, 2007, LANDSCAPE URBAN PLAN, V81, P167, DOI 10.1016/j.landurbplan.2007.02.001.
   van Ewijk KY, 2014, REMOTE SENS ENVIRON, V150, P120, DOI 10.1016/j.rse.2014.04.026.
   Varhola A, 2013, J HYDROL, V487, P70, DOI 10.1016/j.jhydrol.2013.02.032.
   Vashum K.T., 2012, J ECOSYST ECOGRAPHY, V2, P1, DOI {[}DOI 10.4172/2157-7625.1000116, 10.4172/2157-7625.1000116].
   Vicharnakorn P, 2014, REMOTE SENS-BASEL, V6, P5452, DOI 10.3390/rs6065452.
   Wang KP, 2019, FORESTS, V10, DOI 10.3390/f10010001.
   Wang L, 2004, INT J REMOTE SENS, V25, P5655, DOI 10.1080/014311602331291215.
   Wang MY, 2020, MEAS SCI TECHNOL, V31, DOI 10.1088/1361-6501/aba322.
   Wannasiri W, 2013, REMOTE SENS-BASEL, V5, P1787, DOI 10.3390/rs5041787.
   Waser LT, 2014, REMOTE SENS-BASEL, V6, P4515, DOI 10.3390/rs6054515.
   Whittaker, 1972, P 24 BROOKH S BIOL, P281.
   Wieland M, 2014, REMOTE SENS-BASEL, V6, P2912, DOI 10.3390/rs6042912.
   Wijaya A, 2009, INT GEOSCI REMOTE SE, P1883, DOI 10.1109/IGARSS.2009.5417824.
   Wilkes P, 2018, CARBON BAL MANAGE, V13, DOI 10.1186/s13021-018-0098-0.
   Yao W, 2012, REMOTE SENS ENVIRON, V123, P368, DOI 10.1016/j.rse.2012.03.027.
   Zhang M, 2020, ISPRS INT J GEO-INF, V9, DOI 10.3390/ijgi9020064.
   Zhang Y, 2021, INT J REMOTE SENS, V42, P964, DOI 10.1080/01431161.2020.1820618.
   Zhang YL, 2020, APPL GEOGR, V117, DOI 10.1016/j.apgeog.2020.102190.
   Zheng DL, 2004, REMOTE SENS ENVIRON, V93, P402, DOI 10.1016/j.rse.2004.08.008.
   Zhou W, 2008, INT J REMOTE SENS, V29, P3119, DOI 10.1080/01431160701469065.
   Zhou WQ, 2014, REMOTE SENS-BASEL, V6, P3369, DOI 10.3390/rs6043369.
   Zhu Z, 2019, REMOTE SENS ENVIRON, V228, P164, DOI 10.1016/j.rse.2019.04.020.
   NZ J FORESTRY SCI, DOI DOI 10.1186/S40490-016-0071-1.},
Number-of-Cited-References = {175},
Times-Cited = {4},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {30},
Journal-ISO = {Forests},
Doc-Delivery-Number = {SZ8CE},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)},
Unique-ID = {WOS:000666785300001},
OA = {Green Published, gold},
DA = {2023-08-12},
}

@article{ WOS:000071267200030,
Author = {Tian, L and Slaughter, DC and Norris, RF},
Title = {Outdoor field machine vision identification of tomato seedlings for
   automated weed control},
Journal = {TRANSACTIONS OF THE ASAE},
Year = {1997},
Volume = {40},
Number = {6},
Pages = {1761-1768},
Month = {NOV-DEC},
Abstract = {A machine vision system to detect and locate tomato seedlings and weed
   planes in a commercial agricultural environment was developed and
   tested. Images acquired in agricultural outdoor tomato fields under
   natural-light-only conditions were studied extensively, and an
   environmentally adaptive image segmentation algorithm was developed to
   improve machine recognition of plants under these conditions. To
   overcome the plant leaf occlusion problem, an object partition algorithm
   was used to separate the overlapped leaves. Four morphological features
   were used in the plant leaf classification, and several structural
   features were used in a syntactic procedure to identify the whole tomato
   plant and its stem location in the field. The system was able to
   identify the majority of non-occluded target plant cotyledons, and to
   locate plant centers even when the plant was partially occluded. Of all
   the individual target crop plants, 65\% to 78\% were correctly
   identified and less than 5\% of the weeds were incorrectly identified as
   crop plants.},
Publisher = {AMER SOC AGRICULTURAL ENGINEERS},
Address = {2950 NILES RD, ST JOSEPH, MI 49085-9659 USA},
Type = {Article},
Language = {English},
Affiliation = {Tian, L (Corresponding Author), Univ Illinois, Dept Agr Engn, 1304 W Penn Ave, Urbana, IL 61801 USA.
   Univ Illinois, Dept Agr Engn, Urbana, IL 61801 USA.
   Univ Illinois, Dept Biol \& Agr Engn, Urbana, IL 61801 USA.
   Univ Illinois, Dept Vegetable Crops, Urbana, IL 61801 USA.},
ISSN = {0001-2351},
Keywords = {machine vision; pattern recognition; tomato seedling; weeds},
Keywords-Plus = {PLANT-IDENTIFICATION; FRUIT; COLOR},
Research-Areas = {Agriculture},
Web-of-Science-Categories  = {Agricultural Engineering},
Affiliations = {University of Illinois System; University of Illinois Urbana-Champaign;
   University of Illinois System; University of Illinois Urbana-Champaign;
   University of Illinois System; University of Illinois Urbana-Champaign},
Cited-References = {DESNON AG, 1987, 87037 ASAE.
   Duda RO., 1973, PATTERN CLASSIFICATI.
   FRANZ E, 1991, T ASAE, V34, P673.
   GUYER DE, 1986, T ASAE, V29, P1500.
   Hanks J. E., 1996, AGR RES, V44, P15.
   Jain A.K., 1989, FUNDAMENTALS DIGITAL.
   JIA J, 1990, SPIE OPTICS AGR, V1379, P246.
   PARRISH EA, 1977, T ASAE, V20, P822, DOI 10.13031/2013.35657.
   {*}SAS, 1990, SAS STAT US GUID.
   SHEARER SA, 1990, T ASAE, V33, P2037.
   SLAUGHTER DC, 1989, T ASAE, V32, P757.
   SLAUGHTER DC, 1996, Patent No. 5442552.
   Tian L., 1993, 933608 ASAE.
   Tian L, 1995, THESIS U CALIFORNIA.
   TUCKER JH, 1976, COMPUT BIOMED RES, V9, P93, DOI 10.1016/0010-4809(76)90033-1.
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344.
   Woebbecke D.M., 1992, SPIE OPTICS AGR FORE, V1836, p208\~{}217.
   ZHANG N, 1995, T ASAE, V38, P965, DOI 10.13031/2013.27890.},
Number-of-Cited-References = {18},
Times-Cited = {50},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {7},
Journal-ISO = {Trans. ASAE},
Doc-Delivery-Number = {YP341},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000071267200030},
DA = {2023-08-12},
}

@article{ WOS:000969337300026,
Author = {Zhou, Jiawei and Chen, Xinglong and Li, Shuhan and Dong, Runyan and
   Wang, Xinrui and Zhang, Chong and Zhang, Li},
Title = {Multispecies individual tree crown extraction and classification based
   on BlendMask and high-resolution UAV images},
Journal = {JOURNAL OF APPLIED REMOTE SENSING},
Year = {2023},
Volume = {17},
Number = {1},
Month = {JAN 1},
Abstract = {Accurate detection and segmentation of individual trees from unmanned
   aerial vehicle images is critical for forestry resource surveys and
   accurate forest management. Deep learning methods have been used for
   studies of individual tree crown segmentation, classification, and
   number of trees in mixed coniferous and broad-leaved forests, but the
   accuracy needs to be improved. Therefore, this study uses BlendMask, a
   simpler and more efficient algorithm that combines Mask R-CNN and Yolact
   algorithms to effectively combine instance-level information with
   semantic information at a finer granularity level, greatly improving
   crown segmentation accuracy and classification results. Three coniferous
   species and five broad-leaved species unmanned aerial vehicle images
   collected from the Jing Yue multispecies ecological forestry site in
   Changping District, Beijing, were used as the dataset, and the results
   were compared with Yolact and Mask R-CNN. The results show that the
   method described in this work has the highest Kappa coefficient (0.89)
   and overall accuracy (92.14\%) in the test set. For segmentation
   accuracy, coniferous species' producer's accuracy was 0.91 to 0.95,
   whereas that of broad-leaved species was 0.89 to 0.92. For species
   classification, the F1-score and mean average precision for coniferous
   species were greater than 91\%, whereas those for broad-leaved species
   were 77.64\% to 85.63\%. The accuracy of extracting stand density in low
   and medium canopy density stands was 0.9909 and 0.9422, respectively,
   whereas that in high canopy density stands was 0.8913. This study shows
   that the BlendMask model has a good effect in studying the
   classification of multiple tree species, the segmentation of individual
   tree crowns, and the statistics of the number of trees in complex forest
   areas. Compared with broad-leaved forests and high canopy density
   stands, this model is more suitable for coniferous forest and medium and
   low canopy density stand scenarios. This study provides an important
   tool for obtaining more accurate species classification, canopy
   segmentation, and resource inventory results in complex forest areas.},
Publisher = {SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS},
Address = {1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA},
Type = {Article},
Language = {English},
Affiliation = {Zhang, L (Corresponding Author), Beijing Forestry Univ, Coll Sci, Beijing, Peoples R China.
   Zhou, Jiawei; Chen, Xinglong; Li, Shuhan; Dong, Runyan; Wang, Xinrui; Zhang, Li, Beijing Forestry Univ, Coll Sci, Beijing, Peoples R China.
   Zhang, Chong, Beijing Inst Technol, Sch Optoelect, Beijing, Peoples R China.},
DOI = {10.1117/1.JRS.17.016503},
Article-Number = {016503},
EISSN = {1931-3195},
Keywords = {UAV image; BlendMask; crown segmentation; tree species identification;
   tree number detection},
Keywords-Plus = {SPECIES CLASSIFICATION; FOREST; DELINEATION; CLIMATE},
Research-Areas = {Environmental Sciences \& Ecology; Remote Sensing; Imaging Science \&
   Photographic Technology},
Web-of-Science-Categories  = {Environmental Sciences; Remote Sensing; Imaging Science \& Photographic
   Technology},
Author-Email = {zjw1355416532@bjfu.edu.cn
   lemalcxl@bjfu.edu.cn
   Lsh8696@bjfu.edu.cn
   dry15369558859DRY@bjfu.edu.cn
   wxy0224@bjfu.edu.cn
   zhangc0782@163.com
   zhang\_li@bjfu.edu.cn},
Affiliations = {Beijing Forestry University; Beijing Institute of Technology},
Funding-Acknowledgement = {Beijing Forestry University ``Beijing College Students Scientific
   Research and Entrepreneurship Action Plan {[}S202110022148]; Fundamental
   Research Funds for the Central Universities {[}2021ZY92]},
Funding-Text = {The study was funded by Beijing Forestry University ``Beijing College
   Students Scientific Research and Entrepreneurship Action Plan (Grant No.
   S202110022148) and the Fundamental Research Funds for the Central
   Universities (Grant No. 2021ZY92). We are very grateful to the students
   who assisted with the data collection and experiments. We also thank the
   anonymous reviewers for helpful comments and suggestions to this paper.
   No conflicts of interest are declared.},
Cited-References = {Anastasiia S., 2020, SENSORS-BASEL, V21, P1617.
   Aneta M., 2021, FORESTRY, V94, P464.
   Bolya D, 2022, IEEE T PATTERN ANAL, V44, P1108, DOI 10.1109/TPAMI.2020.3014297.
   Brandt M, 2020, NATURE, V587, P78, DOI 10.1038/s41586-020-2824-5.
   Cao KL, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12071128.
   Cao L, 2016, INT J APPL EARTH OBS, V49, P39, DOI 10.1016/j.jag.2016.01.007.
   Chen H., 2020, IEEE C COMPUT VISION.
   Chen JQ, 1999, BIOSCIENCE, V49, P288, DOI 10.2307/1313612.
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2\_49.
   Cho MA, 2012, REMOTE SENS ENVIRON, V125, P214, DOI 10.1016/j.rse.2012.07.010.
   Dale VH, 2001, BIOSCIENCE, V51, P723, DOI 10.1641/0006-3568(2001)051{[}0723:CCAFD]2.0.CO;2.
   {[}段劼 Duan Jie], 2010, {[}生态学报, Acta Ecologica Sinica], V30, P3206.
   Ferreira MP, 2019, ISPRS J PHOTOGRAMM, V149, P119, DOI 10.1016/j.isprsjprs.2019.01.019.
   Freudenberg M, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030312.
   George R, 2014, INT J APPL EARTH OBS, V28, P140, DOI 10.1016/j.jag.2013.11.011.
   Gomes MF, 2018, REMOTE SENS ENVIRON, V211, P184, DOI 10.1016/j.rse.2018.04.002.
   Gong P, 1997, REMOTE SENS ENVIRON, V62, P189, DOI 10.1016/S0034-4257(97)00094-1.
   Harikumar A, 2019, IEEE T GEOSCI REMOTE, V57, P1168, DOI 10.1109/TGRS.2018.2865014.
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI {[}10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322].
   Heinzel J, 2012, INT J APPL EARTH OBS, V18, P101, DOI 10.1016/j.jag.2012.01.025.
   Jawak S. D., 2013, ADV REMOTE SENS, V2, P297, DOI DOI 10.4236/ARS.2013.24033.
   Jing LH, 2012, ISPRS J PHOTOGRAMM, V70, P88, DOI 10.1016/j.isprsjprs.2012.04.003.
   Kattenborn T, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-53797-9.
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913.
   Liu T, 2015, ISPRS J PHOTOGRAMM, V110, P34, DOI 10.1016/j.isprsjprs.2015.10.002.
   Miraki M, 2021, ECOL INFORM, V61, DOI 10.1016/j.ecoinf.2020.101207.
   Morales G, 2018, FORESTS, V9, DOI 10.3390/f9120736.
   Navarro A, 2020, REMOTE SENS ENVIRON, V242, DOI 10.1016/j.rse.2020.111747.
   Plourde LC, 2007, PHOTOGRAMM ENG REM S, V73, P829, DOI 10.14358/PERS.73.7.829.
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031.
   Shao GF, 2019, LANDSCAPE ECOL, V34, P2487, DOI 10.1007/s10980-019-00916-6.
   Skabek K., 2020, COMPUT ASSIST METHOD, V26, P153.
   Su AN, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12213559.
   Tahar KN, 2021, ENG TECHNOL APPL SCI, V11, P7047, DOI 10.48084/etasr.4093.
   Thomas SC, 2007, J ENVIRON MANAGE, V85, P659, DOI 10.1016/j.jenvman.2006.04.022.
   Wagner FH, 2018, ISPRS J PHOTOGRAMM, V145, P362, DOI 10.1016/j.isprsjprs.2018.09.013.
   Wang L, 2004, PHOTOGRAMM ENG REM S, V70, P351, DOI 10.14358/PERS.70.3.351.
   {[}王媚臻 Wang Meizhen], 2019, {[}生态学报, Acta Ecologica Sinica], V39, P981.
   Waser LT, 2011, REMOTE SENS ENVIRON, V115, P76, DOI 10.1016/j.rse.2010.08.006.
   {[}杨超 Yang Chao], 2018, {[}地理与地理信息科学, Geography and Geo-information Science], V34, P24.
   Yun T, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8110942.
   Zhang B, 2020, REMOTE SENS ENVIRON, V247, DOI 10.1016/j.rse.2020.111938.
   Zhang JJ, 2014, ISPRS J PHOTOGRAMM, V98, P44, DOI 10.1016/j.isprsjprs.2014.08.007.
   Zhao Lin, 2020, Scientia Silvae Sinicae, V56, P97, DOI 10.11707/j.1001-7488.20201110.},
Number-of-Cited-References = {44},
Times-Cited = {0},
Usage-Count-Last-180-days = {8},
Usage-Count-Since-2013 = {8},
Journal-ISO = {J. Appl. Remote Sens.},
Doc-Delivery-Number = {D5ST7},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000969337300026},
DA = {2023-08-12},
}

@article{ WOS:000961992700001,
Author = {Liu, Huaipeng},
Title = {Classification of tree species using UAV-based multi-spectral and
   multi-seasonal images: a multi-feature-based approach},
Journal = {NEW FORESTS},
Year = {2023},
Month = {2023 APR 4},
Abstract = {Exploration of the effectiveness of multi-type features and
   multi-seasonal data of remote sensing images and selection of an optimal
   feature set from all extracted features are popular research topics in
   tree species classification. Eight typical image feature sets, namely,
   spectral band, digital surface model (DSM), texture (TEX), tassel cap
   transformation (TC), hue, saturation and value colour space (HSV),
   principal component analysis, minimum noise fraction (MNF) and spectral
   index (SI), were extracted in this study from images of four seasons
   acquired using the RedEdge-MX sensor, and maximum likelihood and random
   forest classifiers were used to categorise 32 typical urban tree
   species. Experimental results revealed the following: (1) the tree
   species recognition accuracy determined using the texture set (87.89\%)
   was higher than that determined using other types of feature sets; (2)
   the optimal feature set containing 20 features comprised 4 DSMs, 11
   TEXs, 2 TCs, 1 HSV (S), 1 SI and 1 MNF, and the classification accuracy
   determined using the set of features was 89.53\% and (3) the
   classification accuracy for tree species identification determined using
   multi-seasonal spectral data was higher than that determined using
   individual seasonal data. The major contribution of this study to
   relevant literature is that it proves that urban greening tree species
   can be accurately identified using multiple features and seasonal images
   acquired through UAV-based sensors. The multi-feature-based approach
   also performs substantially well in practical applications for mapping
   tree species in a general urban environment considering the effects of a
   heterogeneous environment on tree species classification and
   comprehensive image processing and classification methods.},
Publisher = {SPRINGER},
Address = {VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS},
Type = {Article; Early Access},
Language = {English},
Affiliation = {Liu, HP (Corresponding Author), Luoyang Normal Univ, Sch Land \& Tourism, Luoyang 471934, Henan, Peoples R China.
   Liu, Huaipeng, Luoyang Normal Univ, Sch Land \& Tourism, Luoyang 471934, Henan, Peoples R China.},
DOI = {10.1007/s11056-023-09974-w},
EarlyAccessDate = {APR 2023},
ISSN = {0169-4286},
EISSN = {1573-5095},
Keywords = {Tree species recognition; RedEdge-MX data; Multi-season images
   multi-type features; Maximum likelihood classification; Random forest;
   Driving factors},
Keywords-Plus = {WORLDVIEW-2 IMAGERY},
Research-Areas = {Forestry},
Web-of-Science-Categories  = {Forestry},
Author-Email = {gatestudy@163.com},
Affiliations = {Luoyang Normal University},
Funding-Acknowledgement = {Natural Science Foundation of Henan Province, China {[}202300410293];
   National Nature Science Foundation of China {[}32001250]},
Funding-Text = {AcknowledgementsThis work was supported by the Natural Science
   Foundation of Henan Province, China (Grant No. 202300410293) and the
   National Nature Science Foundation of China (Grant No. 32001250). I want
   to thank Engineer Zhenlin Xu from China Southern Surveying and Mapping
   Technology Co., Ltd for his assistance in image acquisition. I also want
   to thank Professor Ruiliang Pu from the University of South Florida for
   his help in improving the manuscript and correcting the grammatical
   errors. I also wish to express my gratitude to the editors and anonymous
   reviewers.},
Cited-References = {Adem K, 2019, EXPERT SYST APPL, V115, P557, DOI 10.1016/j.eswa.2018.08.050.
   Agarwal A, 2021, J INDIAN SOC REMOTE, V49, P491, DOI 10.1007/s12524-020-01227-z.
   Akerblom M, 2017, REMOTE SENS ENVIRON, V191, P1, DOI 10.1016/j.rse.2016.12.002.
   {[}Anonymous], 1998, J REMOTE SENS, DOI DOI 10.1088/0256-307X/15/12/025.
   Apostol B, 2020, SCI TOTAL ENVIRON, V698, DOI 10.1016/j.scitotenv.2019.134074.
   Ben LN, 2018, THESIS HENAN U SCI T.
   Chew WC., 2016, J TEKNOL, V22, P17.
   Cotrozzi L, 2022, J FORESTRY RES, V33, P21, DOI 10.1007/s11676-021-01378-w.
   Cross MD, 2019, IEEE J-STARS, V12, P2934, DOI 10.1109/JSTARS.2019.2918487.
   Dymond CC, 2002, REMOTE SENS ENVIRON, V80, P460, DOI 10.1016/S0034-4257(01)00324-8.
   Ferreira MP, 2019, ISPRS J PHOTOGRAMM, V149, P119, DOI 10.1016/j.isprsjprs.2019.01.019.
   Ghosh A, 2014, INT J APPL EARTH OBS, V26, P298, DOI 10.1016/j.jag.2013.08.011.
   Hamraz H, 2019, ISPRS J PHOTOGRAMM, V158, P219, DOI 10.1016/j.isprsjprs.2019.10.011.
   Han W., 2019, FOREST INVENTORY PLA, V44, P1.
   HUGHES GF, 1968, IEEE T INFORM THEORY, V14, P55, DOI 10.1109/TIT.1968.1054102.
   Immitzer M, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11222599.
   Immitzer M, 2012, REMOTE SENS-BASEL, V4, P2661, DOI 10.3390/rs4092661.
   Kamal M, 2015, REMOTE SENS-BASEL, V7, P4753, DOI 10.3390/rs70404753.
   Karlson M, 2016, INT J APPL EARTH OBS, V50, P80, DOI 10.1016/j.jag.2016.03.004.
   Karlson M, 2015, REMOTE SENS-BASEL, V7, P10017, DOI 10.3390/rs70810017.
   Kureel N, 2022, MODEL EARTH SYST ENV, V8, P733, DOI 10.1007/s40808-021-01113-8.
   Li D, 2015, REMOTE SENS-BASEL, V7, P16917, DOI 10.3390/rs71215861.
   Lin CS, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0125554.
   Liu H, 2016, THESIS INNER MONGOLI.
   Liu HP, 2019, J INDIAN SOC REMOTE, V47, P1959, DOI 10.1007/s12524-019-01028-z.
   Liu HuaiPeng, 2015, Journal of Beijing Forestry University, V37, P53.
   Masemola C, 2020, INT J APPL EARTH OBS, V93, DOI 10.1016/j.jag.2020.102207.
   Masemola C, 2019, IEEE T GEOSCI REMOTE, V57, P5853, DOI 10.1109/TGRS.2019.2902774.
   Modzelewska A, 2020, INT J APPL EARTH OBS, V84, DOI 10.1016/j.jag.2019.101960.
   Naidoo L, 2012, ISPRS J PHOTOGRAMM, V69, P167, DOI 10.1016/j.isprsjprs.2012.03.005.
   Niu JN, 2019, OPT EXPRESS, V27, P31741, DOI 10.1364/OE.27.031741.
   Olofsson P, 2014, REMOTE SENS ENVIRON, V148, P42, DOI 10.1016/j.rse.2014.02.015.
   Pu RL, 2020, URBAN FOR URBAN GREE, V53, DOI 10.1016/j.ufug.2020.126675.
   Pu RL, 2018, INT J APPL EARTH OBS, V71, P144, DOI 10.1016/j.jag.2018.05.005.
   Pu RL, 2012, REMOTE SENS ENVIRON, V124, P516, DOI 10.1016/j.rse.2012.06.011.
   Richards JA, 2008, IEEE GEOSCI REMOTE S, V5, P774, DOI 10.1109/LGRS.2008.2005512.
   Schonert M, 2014, PROC SPIE, V9245, DOI 10.1117/12.2066842.
   Shi WW, 2019, IEEE T NEUR NET LEAR, V30, P683, DOI 10.1109/TNNLS.2018.2852721.
   Shi YF, 2020, INT J APPL EARTH OBS, V84, DOI 10.1016/j.jag.2019.101970.
   Sona G, 2014, EARTH SCI INFORM, V7, P97, DOI 10.1007/s12145-013-0142-2.
   Tooke TR, 2009, REMOTE SENS ENVIRON, V113, P398, DOI 10.1016/j.rse.2008.10.005.
   Torabzadeh H, 2019, AGR FOREST METEOROL, V279, DOI 10.1016/j.agrformet.2019.107744.
   van der Linden S, 2015, REMOTE SENS-BASEL, V7, P11249, DOI 10.3390/rs70911249.
   Wang T, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8010024.
   Wang XF, 2021, URBAN FOR URBAN GREE, V58, DOI 10.1016/j.ufug.2020.126958.
   Yan SJ, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13030479.
   Yu XW, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9020108.
   Zhang B, 2020, REMOTE SENS ENVIRON, V247, DOI 10.1016/j.rse.2020.111938.
   Zhang HB, 2019, APPL SOFT COMPUT, V80, P57, DOI 10.1016/j.asoc.2019.03.017.
   Zhang ZY, 2016, FORESTS, V7, DOI 10.3390/f7060122.
   Zhong LH, 2019, REMOTE SENS ENVIRON, V221, P430, DOI 10.1016/j.rse.2018.11.032.
   {[}周坚华 ZHOU Jianhua], 2011, {[}遥感学报, Journal of Remote Sensing], V15, P524.},
Number-of-Cited-References = {52},
Times-Cited = {0},
Usage-Count-Last-180-days = {11},
Usage-Count-Since-2013 = {11},
Journal-ISO = {New For.},
Doc-Delivery-Number = {C4YR3},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000961992700001},
DA = {2023-08-12},
}

@inproceedings{ WOS:000849726900023,
Author = {Musa, Md and Arman, Md Shohel and Hossain, Md Ekram and Thusar, Ashraful
   Hossen and Nisat, Nahid Kawsar and Islam, Arni},
Editor = {Singh, M and Tyagi, V and Gupta, PK and Flusser, J and Oren, T and Sonawane, VR},
Title = {Classification of Immunity Booster Medicinal Plants Using CNN: A Deep
   Learning Approach},
Booktitle = {ADVANCES IN COMPUTING AND DATA SCIENCES, PT I},
Series = {Communications in Computer and Information Science},
Year = {2021},
Volume = {1440},
Pages = {244-254},
Note = {5th International Conference on Advances in Computing and Data Sciences
   (ICACDS), MVPSS Karmaveer Adv Baburao Ganpatrao Thakare Coll Engn,
   Nashik, INDIA, APR 23-24, 2021},
Organization = {Consilio Intelligence Res Lab; GISR Fdn; Print Canvas; SK Info Techies},
Abstract = {Environment has blessed us with various kinds of plants. Some of them
   uses as resources of medicines as it is called medicinal plant. In
   Bangladesh medicinal plants are also known as Ayurveda, Homeopathy and
   Unani. Experts says medicinal plants can be very useful in the fight
   with recent pandemic which is Covid-19. As we know health of a body
   depends on its immune system, so it is important to keep immunity
   stronger. Strong immune system can be influential to any infectious
   virus, bacteria and pathogens. On the other hand, inactive one can get
   easily infected with virus and other illness. There are certain
   medicinal plants which reinforce our immunity. Therefore, classification
   of these medical plants is very important. For this classification we
   have collected leaf images for six different classes which's local names
   are Darchini, Tulshi, Tejpata, Sojne, Neem, Pathorkuchi. In this article
   we introduced a famous algorithm for classification named CNN
   (Convolutional neural network). We used CNN (Convolutional neural
   network) to recognize the plant from leaf images and got 95.58\%
   accuracy. In future infectious virus can appear which can be more
   threatening than others, our research will help people to know about
   immune system and medicinal plants which reinforce our immunity, so that
   they can fight with diseases and viruses.},
Publisher = {SPRINGER INTERNATIONAL PUBLISHING AG},
Address = {GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Musa, M; Arman, MS; Hossain, ME; Thusar, AH; Nisat, NK; Islam, A (Corresponding Author), Daffodil Int Univ, Dhaka 1207, Bangladesh.
   Musa, Md; Arman, Md Shohel; Hossain, Md Ekram; Thusar, Ashraful Hossen; Nisat, Nahid Kawsar; Islam, Arni, Daffodil Int Univ, Dhaka 1207, Bangladesh.},
DOI = {10.1007/978-3-030-81462-5\_23},
ISSN = {1865-0929},
EISSN = {1865-0937},
ISBN = {978-3-030-81462-5; 978-3-030-81461-8},
Keywords = {Immunity system; Medicinal plant; Plant classification; Convolutional
   neural network},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory \& Methods},
Author-Email = {musa35-1870@diu.edu.bd
   arman.swe@diu.edu.bd
   ekram35-1936@diu.edu.bd
   ashraful35-1908@diu.edu.bd
   nahid35-1889@diu.edu.bd
   arni15-8789@diu.edu.bd},
Affiliations = {Daffodil International University},
Cited-References = {Aakif A, 2015, BIOSYST ENG, V139, P66, DOI 10.1016/j.biosystemseng.2015.08.003.
   Amuthalingeswaran C., 2019, 2019 3rd International Conference on Trends in Electronics and Informatics (ICOEI). Proceedings, P886, DOI 10.1109/ICOEI.2019.8862765.
   Ananthi C., 2014, J NANO SCI NANO TECH, V2.
   Arun C. H., 2013, INT J COMPUTER APPL, V62, P1, DOI 10.5120/10129-4920.
   Begue A, 2017, INT J ADV COMPUT SC, V8, P166.
   Bengio Y., 1997, CONVOLUTIONAL NETWOR.
   Chitra P.L., 2019, INT J ENG ADV TECHNO, V9.
   Ghazi MM, 2017, NEUROCOMPUTING, V235, P228, DOI 10.1016/j.neucom.2017.01.018.
   Jain G., 2017, J BIOMED ENG MED IMA, V4, P115, DOI {[}10.14738/jbemi.42.3053, DOI 10.14738/JBEMI.42.3053].
   Janani R., 2013, 2013 INT C ADV ELECT.
   Kingma D. P., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1412.6980.
   nytimes.com, NYTIMES COM 2010 07.
   O'Donnell K, 2018, BIOPRESERV BIOBANK, V16, P384, DOI 10.1089/bio.2018.0028.
   Poudel P., 2016, ICESMART 2016, V05.
   Tunio N., 2019, DETECTION INFECTED L.
   Venkataraman D, 2016, IEEE I C COMP INT CO, P1000.},
Number-of-Cited-References = {16},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BT7JM},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000849726900023},
DA = {2023-08-12},
}

@article{ WOS:000167901400002,
Author = {Hemming, J and Rath, T},
Title = {Computer-vision-based weed identification under field conditions using
   controlled lighting},
Journal = {JOURNAL OF AGRICULTURAL ENGINEERING RESEARCH},
Year = {2001},
Volume = {78},
Number = {3},
Pages = {233-243},
Month = {MAR},
Abstract = {The methods of digital image analysis were used to develop an
   identification system for weeds in crops. Two vegetable crops (cabbage
   and carrots) and a number of naturally occurring weed species were used
   to develop the classification algorithms. Considering the rougher
   environment, special attention was given to the open-field experiments.
   The images were obtained with a device that provided controlled lighting
   conditions. The analysis was carried out off-line. Eight different
   morphological features and three colour features were calculated for
   each single object to build a joint feature space. On the basis of
   sample data sets of each class, statistics were carried out to determine
   the features, which are suitable for discrimination. A membership
   function based on a fuzzy logic approach was formed and used for the
   classification. The experiments showed that colour features can help to
   increase the classification accuracy. Moreover, colour was used
   successfully for the segmentation procedure of plants and soil.
   Depending on growth stage, weed density and method of calculation
   between 51 and 95\% of the plants were classified correctly. Problems
   still exists by separating and allocating single plants in plant stands
   where the plants have grown together. Compared to other studies the
   plant identification system presented is an improvement, especially
   considering that the experiments were carried out under field
   conditions. (C) 2001 Silsoe Research Institute.},
Publisher = {ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD},
Address = {24-28 OVAL RD, LONDON NW1 7DX, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Hemming, J (Corresponding Author), IMAG, Inst Agr \& Environm Engn, Wageningen, Netherlands.
   IMAG, Inst Agr \& Environm Engn, Wageningen, Netherlands.
   Leibniz Univ Hannover, ITG, Inst Hort \& Agr Engn, D-30167 Hannover, Germany.},
DOI = {10.1006/jaer.2000.0639},
ISSN = {0021-8634},
Keywords-Plus = {IMAGE-ANALYSIS; SYSTEM; PLANTS},
Research-Areas = {Agriculture},
Web-of-Science-Categories  = {Agricultural Engineering},
Author-Email = {j.hemming@imag.wag-ur.nl
   rath@itg.uni-hannover.de},
Affiliations = {Leibniz University Hannover},
ResearcherID-Numbers = {Rath, Thomas/A-4708-2013},
Cited-References = {FRANZ E, 1991, T ASAE, V34, P673.
   GUYER DE, 1993, T ASAE, V36, P163.
   HEMMING J, 2000, THESIS U HANOVER GER.
   KATAYAMA T, 1998, P 3 IFAC CIGR WORKSH, P164.
   KOPP H, 1997, BILDVERARBEITUNG INT.
   LEE WS, 1997, 973093 ASAE.
   Meyer GE, 1998, T ASAE, V41, P1189, DOI 10.13031/2013.17244.
   {*}MVTEC, 1998, HALCON REF MAN C PLU.
   PETRY W, 1989, J AGRON CROP SCI, V163, P345, DOI 10.1111/j.1439-037X.1989.tb00777.x.
   Press W. H., 1992, NUMERICAL RECIPES C, V2nd ed..
   RATH T, 1997, METHODEN COMPUTERBIL.
   SACHS L, 1997, ANGEW STAT.
   SHATADAL P, 1995, T ASAE, V38, P635, DOI 10.13031/2013.27876.
   Simonton W., 1996, Applied Engineering in Agriculture, V12, P89.
   SOKEFELD M, 1996, INNOVATIVE VERFAHREN, V236, P47.
   Tian L, 1999, T ASAE, V42, P893, DOI 10.13031/2013.13269.
   Tian L., 1993, 933608 ASAE.
   Tillett ND, 1998, J AGR ENG RES, V69, P169, DOI 10.1006/jaer.1997.0245.
   TILLETT RD, 1991, J AGR ENG RES, V50, P247, DOI 10.1016/S0021-8634(05)80018-6.
   Timmermans AJM, 1996, COMPUT ELECTRON AGR, V15, P41, DOI 10.1016/0168-1699(95)00056-9.
   WHITTAKER AD, 1987, T ASAE, V30, P591.
   WOEBBECKE DM, 1995, T ASAE, V38, P271, DOI 10.13031/2013.27839.},
Number-of-Cited-References = {22},
Times-Cited = {148},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {34},
Journal-ISO = {J. Agr. Eng. Res.},
Doc-Delivery-Number = {418PW},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000167901400002},
DA = {2023-08-12},
}

@inproceedings{ WOS:000078921900036,
Author = {Meyer, GE and Hindman, T and Laksmi, K},
Editor = {Meyer, GE and DeShazer, JA},
Title = {Machine vision detection parameters for plant species identification},
Booktitle = {PRECISION AGRICULTURE AND BIOLOGICAL QUALITY},
Series = {Proceedings of SPIE},
Year = {1999},
Volume = {3543},
Pages = {327-335},
Note = {Conference on Precision Agriculture and Biological Quality, BOSTON, MA,
   NOV 03-04, 1998},
Organization = {SPIE-Int Soc Opt Engn},
Abstract = {Machine vision based on classical image processing techniques has the
   potential to be a useful tool for plant detection and identification.
   Plant identification is needed for weed detection, herbicide application
   or other efficient chemical spot spraying operations. The key to
   successful detection and identification of plants as species types is
   the segmentation of plants from background pixel regions. In particular,
   it would be beneficial to segment individual leaves from tops of
   canopies as well. The segmentation process yields an edge or binary
   image which contains shape feature information. Results indicate that
   red-green-blue (RGB) formats might provide the best segmentation
   criteria, based on models of human color perception. The binary image
   can be also used as a template to investigate textural features of the
   plant pixel region, using gray image co-occurrence matrices. Texture
   features considers leaf venation, colors, or additional canopy structure
   that might be used to identify various type of grasses or broadleaf
   plants.},
Publisher = {SPIE-INT SOC OPTICAL ENGINEERING},
Address = {1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Meyer, GE (Corresponding Author), Univ Nebraska, Lincoln, NE 68583 USA.
   Univ Nebraska, Lincoln, NE 68583 USA.},
DOI = {10.1117/12.336896},
ISSN = {0277-786X},
EISSN = {1996-756X},
ISBN = {0-8194-3155-9},
Keywords = {plants; image analysis; segmentation; shape; texture; color},
Keywords-Plus = {IMAGE-ANALYSIS; SHAPE; LEAF},
Research-Areas = {Agriculture; Life Sciences \& Biomedicine - Other Topics},
Web-of-Science-Categories  = {Agronomy; Biology},
Affiliations = {University of Nebraska System; University of Nebraska Lincoln},
Cited-References = {GERHARDS R, 1993, J AGRON CROP SCI, V171, P321, DOI 10.1111/j.1439-037X.1993.tb00147.x.
   GUYER DE, 1986, T ASAE, V29, P1500.
   GUYER DE, 1993, T ASAE, V36, P163.
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328.
   Meyer GE, 1998, T ASAE, V41, P1189, DOI 10.13031/2013.17244.
   MURCH GM, 1984, IEEE COMPUT GRAPH, V4, P49.
   {*}SAS I INC, SAS STAT US GUID, P387.
   SHEARER SA, 1990, T ASAE, V33, P2037.
   WOEBBECKE DM, 1995, T ASAE, V38, P271, DOI 10.13031/2013.27839.
   Yonekawa S, 1996, T ASAE, V39, P1525, DOI 10.13031/2013.27647.
   1997, FARM CHEM, V160, P26.
   1997, FARM IND NEWS, V30, P44.},
Number-of-Cited-References = {12},
Times-Cited = {111},
Usage-Count-Last-180-days = {4},
Usage-Count-Since-2013 = {27},
Doc-Delivery-Number = {BM50V},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000078921900036},
DA = {2023-08-12},
}

@inproceedings{ WOS:000343423200013,
Author = {Ma, Lin-Hai and Zhao, Zhong-Qiu and Wang, Jing},
Editor = {Huang, DS and Bevilacqua, V and Figueroa, JC and Premaratne, P},
Title = {ApLeafis: An Android-Based Plant Leaf Identification System},
Booktitle = {INTELLIGENT COMPUTING THEORIES},
Series = {Lecture Notes in Computer Science},
Year = {2013},
Volume = {7995},
Pages = {106-111},
Note = {9th International Conference on Intelligent Computing (ICIC), Nanning,
   PEOPLES R CHINA, JUL 28-31, 2013},
Organization = {Tongji Univ; Guangxi Univ Nationalities; IEEE Computat Intelligence Soc;
   Int Neural Network Soc; Natl Sci Fdn China},
Abstract = {To automatically identify plant species is very useful for ecologists,
   amateur botanists, educators, and so on. In this paper, an Android-based
   mobile application designed to automatically identify plant species by
   the photographs of tree leaves is described. In this application, one
   leaf image can be either a digital image from the existing leaf image
   database or a picture collected by a camera. The picture should be a
   single leaf placed on a light and untextured background without other
   clutter. The identification process consists of totally three steps:
   leaf image segmentation, feature extraction, and species identification.
   The demo system is evaluated on the ImageCLEF2012 Plant Identification
   database which contains 126 tree species from the French Mediterranean
   area. The output of the system to users is the top several species which
   match the query leaf image the best, as well as the textual descriptions
   and additional images about leaves, flowers, etc., of theirs. Our system
   works well with state-of-the-art identification performance.},
Publisher = {SPRINGER-VERLAG BERLIN},
Address = {HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Ma, LH (Corresponding Author), Hefei Univ Technol, Coll Comp Sci \& Informat Engn, Hefei 230009, Peoples R China.
   Ma, Lin-Hai; Zhao, Zhong-Qiu; Wang, Jing, Hefei Univ Technol, Coll Comp Sci \& Informat Engn, Hefei 230009, Peoples R China.},
ISSN = {0302-9743},
EISSN = {1611-3349},
ISBN = {978-3-642-39479-9; 978-3-642-39478-2},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory \& Methods},
Affiliations = {Hefei University of Technology},
Cited-References = {{[}Anonymous], 1998, INTRO WAVELETS WAVEL.
   Burger W., 2008, DIGITAL IMAGE PROCES, VThird.
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177.
   Haralick R. M., 1985, Computer Vision, Graphics, and Image Processing, V29, P100, DOI {[}10.1117/12.948400, 10.1016/S0734-189X(85)90153-7].
   Jun Chen, 2010, 2010 International Conference on Computer Application and System Modeling (ICCASM 2010), P417, DOI 10.1109/ICCASM.2010.5622334.
   Kumar N, 2012, LECT NOTES COMPUT SC, V7573, P502, DOI 10.1007/978-3-642-33709-3\_36.
   STRICKER M, 1995, P SOC PHOTO-OPT INS, V2410, P381, DOI 10.1117/12.205308.
   Wang M, 2009, IEEE T MULTIMEDIA, V11, P465, DOI 10.1109/TMM.2009.2012919.
   Zheng P., 2012, ZHAOHFUT IMAGECLEF 2.},
Number-of-Cited-References = {9},
Times-Cited = {10},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {5},
Doc-Delivery-Number = {BB4WW},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000343423200013},
DA = {2023-08-12},
}

@inproceedings{ WOS:000319334901028,
Author = {Mzoughi, Olfa and Yahiaoui, Itheri and Boujemaa, Nozha},
Book-Group-Author = {IEEE},
Title = {PETIOLE SHAPE DETECTION FOR ADVANCED LEAF IDENTIFICATION},
Booktitle = {2012 IEEE INTERNATIONAL CONFERENCE ON IMAGE PROCESSING (ICIP 2012)},
Series = {IEEE International Conference on Image Processing ICIP},
Year = {2012},
Pages = {1033-1036},
Note = {19th IEEE International Conference on Image Processing (ICIP), Lake
   Buena Vista, FL, SEP 30-OCT 03, 2012},
Organization = {Inst Elect \& Elect Engineers (IEEE); IEEE Signal Proc Soc},
Abstract = {Automatic plant identification is a relatively new research area in
   computer vision that has increasingly attracted high interest as a
   promising solution for the development of many botanical industries and
   for the success of biodiversity conservation. Most of the approaches
   proposed are based on the analysis of morphological properties of
   leaves. They have applied several well-known generic shape descriptors.
   Nevertheless, faced with the large amount of leaf species, botanical
   knowledge, especially about leaf parts (petiole, blade and their
   insertion point) is important to enhance their precision, hence, a
   crucial need to extract them from image. In this paper, we propose a
   fully automatic approach for petiole detection, based on the concept of
   local translational symmetry, which is applied to a some regions of the
   leaf. These regions are chosen w.r.t their size (small) taking into
   account the large diversity of leaf morphology (compound, oblong,
   orbicular). This method has been tested on two datasets and has provided
   more than 90\% of correct detections.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
ISSN = {1522-4880},
ISBN = {978-1-4673-2533-2; 978-1-4673-2534-9},
Keywords = {Leaf identification; contour; petiole; local translational symmetry},
Research-Areas = {Imaging Science \& Photographic Technology},
Web-of-Science-Categories  = {Imaging Science \& Photographic Technology},
ResearcherID-Numbers = {mzoughi, olfa/HMW-1127-2023},
Cited-References = {Beghin T, 2010, LECT NOTES COMPUT SC, V6475, P345, DOI 10.1007/978-3-642-17691-3\_32.
   Chaouch M, 2009, GRAPH MODELS, V71, P63, DOI 10.1016/j.gmod.2008.12.006.
   Gouveia F, 1997, ISIE `97 - PROCEEDINGS OF THE IEEE INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS, VOLS 1-3, P757, DOI 10.1109/ISIE.1997.648634.
   Hearn DJ, 2009, TAXON, V58, P934, DOI 10.1002/tax.583021.
   Kapila P., 2008, THESIS.
   Leaf Architecture Working Group, 1999, MANUAL LEAF ARCHITEC.
   Mizuno S, 2007, LECT NOTES COMPUT SC, V4418, P400.
   Wang XF, 2008, APPL MATH COMPUT, V205, P916, DOI 10.1016/j.amc.2008.05.108.
   Wang Z, 2003, IEE P-VIS IMAGE SIGN, V150, P34, DOI 10.1049/ip-vis:20030160.
   Wu SG, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, VOLS 1-3, P120.},
Number-of-Cited-References = {10},
Times-Cited = {9},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {2},
Doc-Delivery-Number = {BFE17},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000319334901028},
DA = {2023-08-12},
}

@article{ WOS:000778689500002,
Author = {Boudra, Safia and Yahiaoui, Itheri and Behloul, Ali},
Title = {Tree trunk texture classification using multi-scale statistical macro
   binary patterns and CNN},
Journal = {APPLIED SOFT COMPUTING},
Year = {2022},
Volume = {118},
Month = {MAR},
Abstract = {Automated plant classification using tree trunk has attracted increasing
   interest in the computer vision community as a contributed solution for
   the management of biodiversity. It is based on the description of the
   texture information of the bark surface. The multi-scale variants of the
   local binary patterns have achieved prominent performance in bark
   texture description. However, these approaches encode the scale levels
   of the macrostructure separately from each other. In this paper, a novel
   handcrafted texture descriptor termed multi-scale Statistical Macro
   Binary Patterns (ms-SMBP) is proposed to encode the characterizing macro
   pattern of different bark species. The proposed approach consists of
   defining a sampling scheme at high scale levels and summarizing the
   intensity distribution using statistical measures. The characterizing
   macro pattern is encoded by an in-depth gradient that describes the
   relationship between the scale levels and their adaptive statistical
   prototype. Besides this handcrafted feature descriptor, a learning-based
   description is performed with the ResNet34 model for bark
   classification. Extensive and comprehensive experiments on challenging
   and large-scale bark datasets demonstrate the effectiveness of ms-SMBP
   to identify bark species and outperforming different multi-scale LBP
   approaches. The tree trunk classification with ResNet34 shows
   interesting results on a very large-scale dataset.
   (c) 2022 Elsevier B.V. All rights reserved.},
Publisher = {ELSEVIER},
Address = {RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Boudra, S; Yahiaoui, I (Corresponding Author), Univ Reims, CReSTIC EA 3804, F-51097 Reims, France.
   Boudra, Safia; Behloul, Ali, Univ Batna 2, LaSTIC, Batna 05000, Algeria.
   Boudra, Safia; Yahiaoui, Itheri, Univ Reims, CReSTIC EA 3804, F-51097 Reims, France.},
DOI = {10.1016/j.asoc.2022.108473},
EarlyAccessDate = {FEB 2022},
Article-Number = {108473},
ISSN = {1568-4946},
EISSN = {1872-9681},
Keywords = {Tree Bark; Texture; Statistical description; Macro binary pattern;
   ResNet},
Keywords-Plus = {IMAGES},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications},
Author-Email = {safia.boudra@univ-reims.fr
   itheri.yahiaoui@univ-reims.fr
   ali.behloul@gmail.com},
Affiliations = {University of Batna 2; Universite de Reims Champagne-Ardenne},
Cited-References = {Alpaslan N, 2020, IEEE ACCESS, V8, P54415, DOI 10.1109/ACCESS.2020.2981720.
   Belhumeur PN, 2008, LECT NOTES COMPUT SC, V5305, P116, DOI 10.1007/978-3-540-88693-8\_9.
   Bertrand S., 2017, VISAPP 2017 12 INT C.
   Blaanco LJ, 2016, INT CONF CONTEMP, P248.
   Boudra S., 2018, P INT C CONT BAS MUL, P1, DOI {[}10.1109/CBMI.2018.8516536, DOI 10.1109/CBMI.2018.8516536].
   Boudra S, 2018, INT C PATT RECOG, P1530, DOI 10.1109/ICPR.2018.8545798.
   Boudra S, 2017, LECT NOTES COMPUT SC, V10617, P101, DOI 10.1007/978-3-319-70353-4\_9.
   Boudra S, 2015, LECT NOTES COMPUT SC, V9386, P764, DOI 10.1007/978-3-319-25903-1\_66.
   Carpentier M, 2018, IEEE INT C INT ROBOT, P1075, DOI 10.1109/IROS.2018.8593514.
   Cerutti G, 2013, COMPUT VIS IMAGE UND, V117, P1482, DOI 10.1016/j.cviu.2013.07.003.
   Chang C.-C., 2011, ACM T INTEL SYST TEC, V2, P1, DOI DOI 10.1145/1961189.1961199.
   Chi ZR, 2003, PROCEEDINGS OF 2003 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS \& SIGNAL PROCESSING, PROCEEDINGS, VOLS 1 AND 2, P1035.
   Cope JS, 2012, EXPERT SYST APPL, V39, P7562, DOI 10.1016/j.eswa.2012.01.073.
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848.
   Fekri-Ershad S, 2020, EXPERT SYST APPL, V158, DOI 10.1016/j.eswa.2020.113509.
   Fiel S., 2011, P 16 COMP VIS WINT W, P67.
   Goeau H., 2011, IMAGECLEF 2011, P0.
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957.
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017.
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90.
   Hu YT, 2020, SIGNAL PROCESS-IMAGE, V83, DOI 10.1016/j.image.2019.115770.
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750.
   Huang ZK, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON INFORMATION ACQUISITION, VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P946, DOI 10.1109/ICIA.2006.305863.
   Huang ZK, 2006, LECT NOTES COMPUT SC, V4233, P80.
   Huang ZK, 2006, INT J COMPUT SCI NET, V6, P100.
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386.
   Kumar N, 2012, LECT NOTES COMPUT SC, V7573, P502, DOI 10.1007/978-3-642-33709-3\_36.
   Le-Viet T., 2019, 10 INT C SIGNAL PROC, V11071.
   Liao SC, 2007, LECT NOTES COMPUT SC, V4642, P828.
   Liu LT, 2016, IEEE INT CONF ROBOT, P56, DOI 10.1109/ICRA.2016.7487115.
   Liu L, 2017, PATTERN RECOGN, V62, P135, DOI 10.1016/j.patcog.2016.08.032.
   Liu L, 2016, IEEE T IMAGE PROCESS, V25, P1368, DOI 10.1109/TIP.2016.2522378.
   Maenpaa T, 2003, LECT NOTES COMPUT SC, V2749, P885.
   Mouine S., 2013, P 3 ACM C INT C MULT, P127, DOI DOI 10.1145/2461466.2461489.
   Mouine S, 2013, P 3 ACM C INT C MULT, P309.
   Mouine S, 2013, IEEE IMAGE PROC, P1466, DOI 10.1109/ICIP.2013.6738301.
   Mzoughi O, 2016, MULTIMED TOOLS APPL, V75, P1615, DOI 10.1007/s11042-015-2603-8.
   Nanni L, 2012, EXPERT SYST APPL, V39, P3634, DOI 10.1016/j.eswa.2011.09.054.
   Nilsback M.E., 2009, IMAGE VISION COMPUT.
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623.
   RATAJCZAK R, 2019, INT C COMPUTER VISIO.
   Remes V, 2018, LECT NOTES COMPUT SC, V11004, P22, DOI 10.1007/978-3-319-97785-0\_3.
   Seeland M, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0170629.
   Sixta T., 2011, IMAGE VIDEO BASED RE.
   Song JT, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P450, DOI 10.1109/ISIMP.2004.1434097.
   Sulc M, 2017, PLANT METHODS, V13, DOI 10.1186/s13007-017-0265-4.
   Sulc M, 2013, INT CONF IMAG VIS, P82, DOI 10.1109/IVCNZ.2013.6726996.
   Svab M, 2014, COMPUTER VISION BASE.
   Nguyen TP, 2016, NEUROCOMPUTING, V173, P1565, DOI 10.1016/j.neucom.2015.09.029.
   Waldchen J, 2018, ARCH COMPUT METHOD E, V25, P507, DOI 10.1007/s11831-016-9206-z.
   Wan YY, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P482, DOI 10.1109/ISIMP.2004.1434106.
   Wang K, 2013, IEEE SIGNAL PROC LET, V20, P853, DOI 10.1109/LSP.2013.2270405.
   Wojtech M, 2011, BARK FIELD GUIDE TRE.
   Wolf L., 2008, WORKSHOP FACESREAL L.
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4.},
Number-of-Cited-References = {55},
Times-Cited = {5},
Usage-Count-Last-180-days = {4},
Usage-Count-Since-2013 = {8},
Journal-ISO = {Appl. Soft. Comput.},
Doc-Delivery-Number = {0H4FP},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000778689500002},
OA = {hybrid},
DA = {2023-08-12},
}

@inproceedings{ WOS:000492052500074,
Author = {Ozdil, Omer and Esin, Yunus Emre and Demirel, Berkan and Ozturk, Safak},
Book-Group-Author = {IEEE},
Title = {Generating Spectral Signature Library for Patterned Object in
   Hyperspectral Images},
Booktitle = {2019 9TH INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN SPACE
   TECHNOLOGIES (RAST)},
Year = {2019},
Pages = {457-460},
Note = {9th International Conference on Recent Advances in Space Technologies
   (RAST), Istanbul, TURKEY, JUN 11-14, 2019},
Abstract = {Small objects cover within a few pixels or even cover subpixels due to
   the low spatial resolution of hyperspectral cameras. This factor
   significantly reduces the detection performance for multi-pattern
   objects. For this reason, it is important to obtain signatures that can
   model the target in best way while creating spectral library signatures.
   In this study, a representative signature generation method for the
   patterned objects is proposed in order to determine the target in
   hyperspectral aerial images. The target detection performance, which was
   calculated by using the pattern signatures of the object is compared
   with the target detection performance using the Mean Signatures obtained
   by the average of the signatures from a selected area. In addition, the
   target detection performance of the average signatures obtained from
   randomly selected areas are also compared. According to the results, it
   is observed that the target detection performance of the Mean Signatures
   is higher than that of the the pattern signatures.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Ozdil, O (Corresponding Author), HAVELSAN Inc, Image \& Video Proc Grp, Ankara, Turkey.
   Ozdil, Omer; Esin, Yunus Emre; Demirel, Berkan; Ozturk, Safak, HAVELSAN Inc, Image \& Video Proc Grp, Ankara, Turkey.},
ISBN = {978-1-5386-9448-0},
Keywords = {hyperspectral image processing; plant classification; crop detection;
   spectral library},
Research-Areas = {Engineering},
Web-of-Science-Categories  = {Engineering, Aerospace},
Author-Email = {oozdil@havelsan.com.tr
   yesin@havelsan.com.tr
   bdemirel@havelsan.com.tr
   sozturk@havelsan.com.tr},
Affiliations = {Havelsan AS},
ResearcherID-Numbers = {Esin, Yunus/ABI-3881-2020
   },
ORCID-Numbers = {Esin, Yunus/0000-0002-3719-9290
   Demirel, Berkan/0000-0002-5759-6410},
Cited-References = {Ayoub TF, 2000, IEEE T AERO ELEC SYS, V36, P810, DOI 10.1109/7.869498.
   Demirel B., 2017, SIGN PROC COMM APPL, P1.
   Demirel B, 2016, 2016 24TH SIGNAL PROCESSING AND COMMUNICATION APPLICATION CONFERENCE (SIU), P1249, DOI 10.1109/SIU.2016.7495973.
   Lee ZP, 1999, APPL OPTICS, V38, P3831, DOI 10.1364/AO.38.003831.
   Lu D, 2002, INT J REMOTE SENS, V23, P2651, DOI 10.1080/01431160110109642.
   Manolakis D, 2002, IEEE SIGNAL PROC MAG, V19, P29, DOI 10.1109/79.974724.
   Ozdil O, 2018, INT GEOSCI REMOTE SE, P2709, DOI 10.1109/IGARSS.2018.8517344.},
Number-of-Cited-References = {7},
Times-Cited = {1},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BO0MC},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000492052500074},
DA = {2023-08-12},
}

@article{ WOS:000902987000001,
Author = {Patnaik, Vijaya and Mohanty, Monalisa and Subudhi, Asit Kumar},
Title = {Identification of healthy biological leafs using hybrid-feature
   classifier},
Journal = {IMAGING SCIENCE JOURNAL},
Year = {2021},
Volume = {69},
Number = {5-8},
Pages = {239-253},
Month = {NOV 17},
Abstract = {Plants are an important element of the ecosystem that helps in
   controlling carbon emissions and environmental changes. Characterization
   and identification are a need for protecting plants and for people to
   understand plant protection. Plant leaves are the main parts for
   detection. Characterizing leaves now has been a significant and
   complicated task, particularly with the features of leaves. Leaf images
   of two different types are considered here, one is healthy while the
   other is unhealthy, and divided into two distinct classes. The proposed
   method incorporates features of the leaf images that are extracted
   utilizing the Gray Level Co-occurrence Matrix (GLCM) and Gray Level Run
   Length Matrix (GLRLM) feature extraction techniques. The outcomes are
   classified using three different classifiers: Random Forest, Multilayer
   Perceptron, and Naive Bayes with an accuracy of 95.84\%, 98.33\%, and
   82.89\% respectively. The classifiers successfully classify the healthy
   and diseased leaves of various plants that were considered here. Hence
   as per the investigation, the study can be valuable for analysts for
   plant recognition, characterization, and diagnosis.},
Publisher = {TAYLOR \& FRANCIS LTD},
Address = {2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Subudhi, AK (Corresponding Author), SOA Univ, ECE, FET, ITER, Bhubaneswar 751030, Odisha, India.
   Patnaik, Vijaya; Mohanty, Monalisa; Subudhi, Asit Kumar, SOA Univ, Dept ECE, ITER, Bhubaneswar, Orissa, India.
   Subudhi, Asit Kumar, SOA Univ, ECE, FET, ITER, Bhubaneswar 751030, Odisha, India.},
DOI = {10.1080/13682199.2022.2157533},
EarlyAccessDate = {DEC 2022},
ISSN = {1368-2199},
EISSN = {1743-131X},
Keywords = {Leaf classification; GLCM; GLRLM; random forest; MLP; Naive Bayes},
Keywords-Plus = {IMAGE},
Research-Areas = {Imaging Science \& Photographic Technology},
Web-of-Science-Categories  = {Imaging Science \& Photographic Technology},
Author-Email = {vijayapatnaik99@gmail.com
   monalisamohanty@soa.ac.in
   asitsubudhi@soa.ac.in},
Affiliations = {Siksha `O' Anusandhan University; Siksha `O' Anusandhan University},
ResearcherID-Numbers = {Patnaik, Vijaya/HIR-3619-2022},
Cited-References = {Ahlin K, 2016, IFAC PAPERSONLINE, V49, P177, DOI 10.1016/j.ifacol.2016.10.033.
   Albregtsen F, 2000, INT C PATT RECOG, P738, DOI 10.1109/ICPR.2000.903650.
   Amin AHM, 2013, PROCEDIA COMPUT SCI, V24, P84, DOI 10.1016/j.procs.2013.10.030.
   Cassidy C, 2020, WORLD PAT INF, V61, DOI 10.1016/j.wpi.2020.101968.
   Chouhan SS., 2019, IEEE 2019 4 INT C IN, P700.
   Fuentes S, 2018, COMPUT ELECTRON AGR, V151, P311, DOI 10.1016/j.compag.2018.06.035.
   Geetharamani G, 2019, COMPUT ELECTR ENG, V76, P323, DOI 10.1016/j.compeleceng.2019.04.011.
   Goay CH, 2019, IEEE T COMP PACK MAN, V9, P2427, DOI 10.1109/TCPMT.2019.2938583.
   Gopal A, 2012, 2012 INTERNATIONAL CONFERENCE ON MACHINE VISION AND IMAGE PROCESSING (MVIP), P5, DOI 10.1109/MVIP.2012.6428747.
   Grand-Brochier M, 2015, IEEE T IMAGE PROCESS, V24, P1549, DOI 10.1109/TIP.2015.2400214.
   Grinblat GL, 2016, COMPUT ELECTRON AGR, V127, P418, DOI 10.1016/j.compag.2016.07.003.
   Horaisova K, 2016, BIOSYST ENG, V142, P83, DOI 10.1016/j.biosystemseng.2015.12.007.
   Jiang F, 2020, COMPUT ELECTRON AGR, V179, DOI {[}10.1016/j.compeg.2020.105824, 10.1016/j.compag.2020.105824].
   Jiang HX, 2020, IEEE ACCESS, V8, P68828, DOI 10.1109/ACCESS.2020.2986946.
   Krithika N, 2017, 2017 INTERNATIONAL CONFERENCE ON INNOVATIONS IN INFORMATION, EMBEDDED AND COMMUNICATION SYSTEMS (ICIIECS).
   Larese MG, 2014, PATTERN RECOGN, V47, P158, DOI 10.1016/j.patcog.2013.06.012.
   Lee S, 2017, 24TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2017), DOI {[}10.1016/j.patcog.2017.05.015, 10.14722/ndss.2017.23457].
   Masetic Z, 2016, COMPUT METH PROG BIO, V130, P54, DOI 10.1016/j.cmpb.2016.03.020.
   Masuzawa H, 2021, ADV ROBOTICS, V35, P359, DOI 10.1080/01691864.2021.1873846.
   Mohanaiah P, 2013, INT J SCI RES PUBL, V3.
   Mohanty A.K., 2011, INT J ENG RES APPL, V1, P687.
   Ozturk Saban, 2018, Procedia Computer Science, V132, P40, DOI 10.1016/j.procs.2018.05.057.
   Patil J. K., 2016, ENG AGR ENV FOOD, V10, P69, DOI DOI 10.1016/J.EAEF.2016.11.004.
   Romer C, 2011, COMPUT ELECTRON AGR, V79, P180, DOI 10.1016/j.compag.2011.09.011.
   Sanyal P, 2008, IMAGING SCI J, V56, P319, DOI 10.1179/174313108X319397.
   Sastry SS, 2012, ADV COND MATTER PHYS, V2012, DOI 10.1155/2012/527065.
   Sertel O, 2010, IEEE T BIO-MED ENG, V57, P2613, DOI 10.1109/TBME.2010.2055058.
   Sethy PK, 2020, COMPUT ELECTRON AGR, V175, DOI 10.1016/j.compag.2020.105527.
   Singh, 2019, ARTIF INTELL AGR.
   Singh Chouhan, 2020, MEASUREMENT.
   Singh UP., 2018, MULTILAYER CONVOLUTI, P2169.
   Sinha A, 2020, IMAGING SCI J, V68, P225, DOI 10.1080/13682199.2020.1865652.
   Sinha A, 2020, PROCEDIA COMPUT SCI, V167, P2328, DOI 10.1016/j.procs.2020.03.285.
   Subudhi A, 2020, BIOCYBERN BIOMED ENG, V40, P277, DOI 10.1016/j.bbe.2019.04.004.
   Sujatha R, 2021, MICROPROCESS MICROSY, V80, DOI 10.1016/j.micpro.2020.103615.
   Tanveer M, 2016, KNOWL-BASED SYST, V94, P70, DOI 10.1016/j.knosys.2015.11.011.
   Tavakoli H., 2020, COMPUT ELECTRON AGR, P0168.
   Treder MS, 2016, NEUROIMAGE, V129, P279, DOI 10.1016/j.neuroimage.2016.01.019.
   Vapnik V, 2017, ANN MATH ARTIF INTEL, V81, P3, DOI 10.1007/s10472-017-9538-x.
   Wan SH, 2018, IEEE ACCESS, V6, P36825, DOI 10.1109/ACCESS.2018.2851382.
   Yang, 2021, PLANT LEAF RECOGNITI, P0031.
   Zhang SW, 2020, NEUROCOMPUTING, V408, P246, DOI 10.1016/j.neucom.2019.09.113.
   Zhang SW, 2017, COMPUT ELECTRON AGR, V134, P135, DOI 10.1016/j.compag.2017.01.014.
   ZHANG YT, 2016, PR MACH LEARN RES, V48, pNI683.
   Zhao C, 2015, PATTERN RECOGN, V48, P3203, DOI 10.1016/j.patcog.2015.04.004.},
Number-of-Cited-References = {45},
Times-Cited = {0},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {2},
Journal-ISO = {Imaging Sci. J.},
Doc-Delivery-Number = {A0HQ0},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000902987000001},
DA = {2023-08-12},
}

@inproceedings{ WOS:000380567700003,
Author = {Salima, Adzkia and Herdiyeni, Yeni and Douady, Stephane},
Book-Group-Author = {IEEE},
Title = {Leaf Vein Segmentation of Medicinal Plant Using Hessian Matrix},
Booktitle = {2015 INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER SCIENCE AND
   INFORMATION SYSTEMS (ICACSIS)},
Series = {International Conference on Advanced Computer Science and Information
   Systems},
Year = {2015},
Pages = {275-279},
Note = {International Conference on Advanced Computer Science and Information
   Systems (ICACSIS), Pusat Studi Jepang Universitas Indonesia, Depok,
   INDONESIA, OCT 10-11, 2015},
Organization = {IEEE Indonesia Sect; Univ Indonesia Fac Comp Sci},
Abstract = {This paper proposes a leaf vein segmentation using Hessian matrix. Leaf
   venation pattern is a biometric feature that form the basis of leaf
   characterization and classification. It is specific in certain species
   thus it can be used as a key feature. Hessian Matrix is a method of the
   second derivative ridge detection that can be used to segment the image
   based on its group structure by analyzing eigenvalues of the pixel. We
   applied thinning to achive the better result of leaf vein. In addition,
   we performed morphological image processing to fix broken ridges or
   unconnected leaf veins. We have evaluated four veins type of 80 digital
   leaf. The experimental results show that 53.75\% of leaf image scored 2
   and 42.5\% scored 1 which means our proposed method has good performance
   to extract the primary, secondary veins and tertiary leaf vein. This
   method is promising to help botanist and taxonomist identifying
   medicinal plant species automatically.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Salima, A (Corresponding Author), Bogor Agr Univ, Dept Comp Sci, Fac Math \& Nat Sci, Java, Indonesia.
   Salima, Adzkia; Herdiyeni, Yeni, Bogor Agr Univ, Dept Comp Sci, Fac Math \& Nat Sci, Java, Indonesia.
   Douady, Stephane, Univ Paris Diderot, Lab Matiere \& Syst Complex, F-75205 Paris, France.},
ISSN = {2330-4588},
ISBN = {978-1-5090-0363-1},
Keywords = {leaf vein segmentation; eigenvalue of hessian matrix analysis; ridge
   detection; plant classification pre-process},
Keywords-Plus = {ARCHITECTURE; EVOLUTION},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Information Systems; Computer Science, Theory \&
   Methods},
Author-Email = {adzkiasalimailut@apps.ipb.ac.id
   yeniherdiyeni@ipb.ac.id
   douady@lps.ens.fr},
Affiliations = {Bogor Agricultural University; UDICE-French Research Universities;
   Universite Paris Cite},
ResearcherID-Numbers = {DOUADY, Stephane/C-4498-2018
   Herdiyeni, Yeni/GPK-6559-2022},
ORCID-Numbers = {DOUADY, Stephane/0000-0002-3416-886X
   Herdiyeni, Yeni/0000-0002-3389-1730},
Cited-References = {{[}Anonymous], 1992, PLANT BIOMECHANICS.
   dan Aviral Katyal V, 2012, INT J ADV RES COMPUT, V3, P95.
   Drechsler K., 2010, 10 IEEE INT C INF TE, P1.
   Frangi AF, 1998, LECT NOTES COMPUT SC, V1496, P130, DOI 10.1007/BFb0056195.
   Gogtay NJ, 2002, DRUG SAFETY, V25, P1005, DOI 10.2165/00002018-200225140-00003.
   Harlow WM, 1969, TXB DENDROLOGY, V5th.
   HICKEY LJ, 1973, AM J BOT, V60, P17, DOI 10.2307/2441319.
   Lindeberg T, 1996, PROC CVPR IEEE, P465, DOI 10.1109/CVPR.1996.517113.
   {[}MoF] Ministry of Forestry Republik Indonesia, 2009, LOK NAS TAN OB IND.
   Rahmadhani Herdiyeni Y., 2010, ASIAN FEDERATION INF, V3, P60.
   Roth-Nebelsick A, 2001, ANN BOT-LONDON, V87, P553, DOI 10.1006/anbo.2001.1391.
   Rudzki M., 2009, THESIS.
   Runion A, ACM T GRAPHICS, V24, P702.
   Sack L, 2013, NEW PHYTOL, V198, P983, DOI 10.1111/nph.12253.
   Salem Nancy M., 2007, 2007 15th European Signal Processing Conference (EUSIPCO), P428.
   Zhang TY, 1984, COMMUN ACM, V27, P102.},
Number-of-Cited-References = {16},
Times-Cited = {5},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {3},
Doc-Delivery-Number = {BF3QG},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000380567700003},
DA = {2023-08-12},
}

@article{ WOS:000078366600001,
Author = {Tian, LF and Slaughter, DC},
Title = {Environmentally adaptive segmentation algorithm for outdoor image
   segmentation},
Journal = {COMPUTERS AND ELECTRONICS IN AGRICULTURE},
Year = {1998},
Volume = {21},
Number = {3},
Pages = {153-168},
Month = {DEC},
Abstract = {An environmentally adaptive segmentation algorithm (EASA) was developed
   for outdoor field plant detection. Based on a partially supervised
   learning process, the algorithm can learn from environmental conditions
   in outdoor agricultural fields and build an image segmentation look-up
   table on-the-fly. Experiments showed that the algorithm can adapt to
   most daytime conditions in outdoor fields, such as changes in light
   source temperature and soil type. When compared to a static segmentation
   technique which was trained under sunny conditions, the EASA improved
   the image segmentation by correctly classifying 26.9 and 54.3\% more
   object pixels under partially cloudy and overcast conditions,
   respectively. The improved image segmentation of the EASA technique also
   allowed up to 32 times more plant cotyledons to be recognized (by leaf
   morphology) under overcast lighting conditions when compared with a
   static segmentation technique trained under sunny conditions. (C) 1998
   Elsevier Science B.V. All rights reserved.},
Publisher = {ELSEVIER SCIENCE BV},
Address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Tian, LF (Corresponding Author), Univ Illinois, Dept Agr Engn, 1304 W Pennsylvania Ave, Urbana, IL 61801 USA.
   Univ Illinois, Dept Agr Engn, Urbana, IL 61801 USA.
   Univ Calif Davis, Dept Biol \& Agr Engn, Davis, CA USA.},
DOI = {10.1016/S0168-1699(98)00037-4},
ISSN = {0168-1699},
Keywords = {computer vision; field plant; outdoor lighting; segmentation},
Keywords-Plus = {PLANT-IDENTIFICATION; MACHINE VISION; LEAVES; FRUIT},
Research-Areas = {Agriculture; Computer Science},
Web-of-Science-Categories  = {Agriculture, Multidisciplinary; Computer Science, Interdisciplinary
   Applications},
Affiliations = {University of Illinois System; University of Illinois Urbana-Champaign;
   University of California System; University of California Davis},
Cited-References = {Ballard Dana H., 1982, COMPUTER VISION.
   DESNON AG, 1987, 87037 ASAE.
   Duda RO., 1973, PATTERN CLASSIFICATI.
   FRANZ E, 1991, T ASAE, V34, P673.
   GUYER DE, 1993, T ASAE, V36, P163.
   JIA J, 1990, SPIE OPTICS AGR, V1379, P246.
   KLINKER GJ, 1993, PHYSICAL APPROACH CO.
   NADLER M, 1993, PATTERN RECOGNITION.
   OVERHEIM RD, 1982, LIGHT COLOR.
   Pao Y. H., 1989, ADAPTIVE PATTERN REC.
   PARRISH EA, 1977, T ASAE, V20, P822, DOI 10.13031/2013.35657.
   Pla F., 1993, Computers and Electronics in Agriculture, V8, P57, DOI 10.1016/0168-1699(93)90058-9.
   {*}SAS, 1990, SAS STAT US GUID.
   Shiraishi M, 1996, J MANUF SCI E-T ASME, V118, P382, DOI 10.1115/1.2831041.
   SLAUGHTER DC, 1989, T ASAE, V32, P757.
   SLAUGHTER DC, 1997, 971079 ASAE.
   Tian L, 1997, T ASAE, V40, P1761.
   Tian L., 1993, 933608 ASAE.
   Tian L, 1995, THESIS U CALIFORNIA.
   Tou J.T., 1974, PATTERN RECOGNITION, DOI DOI 10.1002/ZAMM.19770570626.
   WILLIAMSON JS, 1983, LIGHT COLOR NATURE A.
   Woebbecke D.M., 1992, SPIE OPTICS AGR FORE, V1836, p208\~{}217.
   ZHANG N, 1995, T ASAE, V38, P965, DOI 10.13031/2013.27890.},
Number-of-Cited-References = {23},
Times-Cited = {122},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {18},
Journal-ISO = {Comput. Electron. Agric.},
Doc-Delivery-Number = {162VA},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000078366600001},
DA = {2023-08-12},
}

@article{ WOS:000228504800004,
Author = {Wilson, AD and Lester, DG and Oberle, CS},
Title = {Application of conductive polymer analysis for wood and woody plant
   identifications},
Journal = {FOREST ECOLOGY AND MANAGEMENT},
Year = {2005},
Volume = {209},
Number = {3},
Pages = {207-224},
Month = {MAY 2},
Abstract = {An electronic aroma detection (EAD) technology known as conductive
   polymer analysis (CPA) was evaluated as a means of identifying and
   discriminating woody samples of angiosperms and gymnosperms using an
   analytical instrument (electronic nose) that characterizes the aroma
   profiles of volatiles released from excised wood into sampled headspace.
   The instrument measures electrical-resistance changes generated by
   adsorption of volatiles to the surface of electroactive, polymer-coated
   sensors. Unique digital electronic fingerprints of wood aromas, derived
   front multisensor-responses to distinct mixtures of wood volatiles, were
   obtained from woods of individual tree species. A reference library
   containing aroma signature patterns for 23 tree species was constructed
   for identifications of unknown samples using pattern-recognition
   algorithms. The 32-sensor array used with an Aromascan A32S instrument
   was sensitive to a wide diversity of organic compounds and produced
   outputs of distinct electronic aroma signature patterns in response to
   wood volatiles that effectively identified unknown samples from
   individual tree species included in the reference library. Some
   potential applications of CPA methods for research in ecology, forestry,
   plant taxonomy, and related disciplines were identified with some
   significant advantages and limitations. Other applications of this
   technology were discovered for the management of forested stands and
   ecosystems based on the identification of roles that wood-inhabiting
   organisms play in stand dynamics and long-term ecosystem functions.
   Results pertaining to tree systematics and phylogeny are discussed in
   the context of prevailing opinions of oak taxonomy. (c) 2005 Elsevier
   B.V. All rights reserved.},
Publisher = {ELSEVIER SCIENCE BV},
Address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Wilson, AD (Corresponding Author), USDA, Forest Serv,So Hardwoods Lab, Forest Insect \& Dis Res, So Res Stn,Ctr Bottomland Hardwoods Res, 432 Stoneville Rd, Stoneville, MS 38776 USA.
   USDA, Forest Serv,So Hardwoods Lab, Forest Insect \& Dis Res, So Res Stn,Ctr Bottomland Hardwoods Res, Stoneville, MS 38776 USA.},
DOI = {10.1016/j.foreco.2005.01.030},
ISSN = {0378-1127},
EISSN = {1872-7042},
Keywords = {artificial olfaction; electronic nose detection; forest ecology; forest
   management; plant chemotaxonomy; Quercus; woody sample identification},
Keywords-Plus = {MAMMALIAN OLFACTORY SYSTEM; PATTERN-RECOGNITION; ELECTRONIC NOSE; SENSOR
   ARRAY; OAK WILT; GAS; DISCRIMINATION; ODORS},
Research-Areas = {Forestry},
Web-of-Science-Categories  = {Forestry},
Author-Email = {dwilson02@fs.fed.us
   coberle@fs.fed.us},
Affiliations = {United States Department of Agriculture (USDA); United States Forest
   Service},
ResearcherID-Numbers = {Wilson, Alphus D./Q-2137-2015},
ORCID-Numbers = {Wilson, Alphus D./0000-0003-2352-5232},
Cited-References = {ABE H, 1988, ANAL CHIM ACTA, V215, P155, DOI 10.1016/S0003-2670(00)85275-7.
   AISHIMA T, 1991, ANAL CHIM ACTA, V243, P293, DOI 10.1016/S0003-2670(00)82573-8.
   Andrews JH, 2000, ANNU REV PHYTOPATHOL, V38, P145, DOI 10.1146/annurev.phyto.38.1.145.
   {[}Anonymous], ANN SCI FOREST.
   Bartlett PN, 1997, FOOD TECHNOL-CHICAGO, V51, P44.
   CARPENTER RD, 1989, DEFECTS HARDWOOD TIM, V678.
   DAVIDE FAM, 1995, BIOSENS BIOELECTRON, V10, P203, DOI 10.1016/0956-5663(95)96807-B.
   diNatale C, 1996, MEAS SCI TECHNOL, V7, P1103, DOI 10.1088/0957-0233/7/8/003.
   DINATALE C, 1995, SENSOR ACTUAT B-CHEM, V25, P801, DOI 10.1016/0925-4005(95)85178-X.
   EGASHIRA M, 1993, SENSOR ACTUAT B-CHEM, V13, P443, DOI 10.1016/0925-4005(93)85422-7.
   EGASHIRA M, 1997, P INT C SOL STAT SEN, P1385.
   FREUND MS, 1995, P NATL ACAD SCI USA, V92, P2652, DOI 10.1073/pnas.92.7.2652.
   GARDNER JW, 1991, SENSOR ACTUAT B-CHEM, V4, P109, DOI 10.1016/0925-4005(91)80185-M.
   GARDNER JW, 1992, SENSOR ACTUAT B-CHEM, V8, P1.
   Hanaki S, 1996, SENSOR ACTUAT A-PHYS, V57, P65, DOI 10.1016/S0924-4247(97)80096-9.
   Hansen EM, 2000, ANNU REV PHYTOPATHOL, V38, P515, DOI 10.1146/annurev.phyto.38.1.515.
   HATFIELD JV, 1994, SENSOR ACTUAT B-CHEM, V18, P221, DOI 10.1016/0925-4005(94)87086-1.
   HOBBS PJ, 1995, J AGR ENG RES, V60, P137, DOI 10.1006/jaer.1995.1007.
   KOWALSKI BR, 1972, J AM CHEM SOC, V94, P5632, DOI 10.1021/ja00771a016.
   Lonergan MC, 1996, CHEM MATER, V8, P2298, DOI 10.1021/cm960036j.
   NANTO H, 1993, SENSOR ACTUAT B-CHEM, V14, P715, DOI 10.1016/0925-4005(93)85156-5.
   Pelosi P., 1988, SENSORS SENSORY SYST, P361.
   PERSAUD K, 1982, NATURE, V299, P352, DOI 10.1038/299352a0.
   Persaud K.C., 1993, ROBOTS BIOLOGICAL SY, P579.
   Persaud K.C., 1994, OLFACTION TASTE, P708, DOI DOI 10.1007/978-4-431-68355-1\_282.
   PERSAUD KC, 1992, TRAC-TREND ANAL CHEM, V11, P61, DOI 10.1016/0165-9936(92)80079-L.
   PERSAUD KC, 1996, P INT C AIR POLL AGR, P249.
   PISANELLI AM, 1994, LIFE CHEM REPORTS, V11, P303.
   QUELLETTE J, 1999, IND PHYS, V5, P26.
   Shirley S.G., 1990, Seminars in the Neurosciences, V2, P59.
   SHURMER HV, 1990, IEE PROC-G, V137, P197, DOI 10.1049/ip-g-2.1990.0030.
   SHURMER HV, 1989, SENSOR ACTUATOR, V18, P359.
   VERKASALO E, 1993, FPLRP516 USDA.
   Whipps JM, 2001, J EXP BOT, V52, P487, DOI 10.1093/jexbot/52.suppl\_1.487.
   White J, 1996, ANAL CHEM, V68, P2191, DOI 10.1021/ac9511197.
   WILSON, 1999, P MISS ASS PLANT PAT, V17, P13.
   Wilson AD, 2004, PHYTOPATHOLOGY, V94, P419, DOI 10.1094/PHYTO.2004.94.5.419.
   Wilson AD, 2002, PLANT DIS, V86, P1067, DOI 10.1094/PDIS.2002.86.10.1067.
   Wilson AD, 2001, J FOREST, V99, P4.
   YEA B, 1994, SENSOR ACTUAT A-PHYS, V45, P159, DOI 10.1016/0924-4247(94)00831-0.
   YIM HS, 1993, BIOSENS BIOELECTRON, V8, P1, DOI 10.1016/0956-5663(93)80041-M.},
Number-of-Cited-References = {41},
Times-Cited = {19},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {9},
Journal-ISO = {For. Ecol. Manage.},
Doc-Delivery-Number = {917YH},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000228504800004},
DA = {2023-08-12},
}

@article{ WOS:000496605900010,
Author = {Madsen, Simon L. and Dyrmann, Mads and Jorgensen, Rasmus N. and
   Karstoft, Henrik},
Title = {Generating artificial images of plant seedlings using generative
   adversarial networks},
Journal = {BIOSYSTEMS ENGINEERING},
Year = {2019},
Volume = {187},
Pages = {147-159},
Month = {NOV},
Abstract = {Plants seedlings are a part of a domain with low inter-class and
   relatively high intra-class variance with respect to visual appearance.
   This paper presents an approach for generating artificial image samples
   of plant seedlings using generative adversarial networks (GAN) to
   alleviate for the lack of training data for deep learning systems in
   this domain. We show that it is possible to use GAN to produce samples
   that are visually distinct across nine different plants species and
   maintain a high amount variance within each species. The generated
   samples resemble the intended species with an average recognition
   accuracy of 58.9 +/- 9.2\%, evaluated using a state-of-the-art
   classification model. The observed errors are related to samples
   representing species which are relatively anonymous at the
   dicotyledonous growth stage and to the model's incapability to reproduce
   small shape details. The artificial plant samples are also used for
   pretraining a classification model, which is fine-tuned using real data.
   The pretrained model achieves 62.0 +/- 5.3\% accuracy on classifying
   real plant seedlings prior to any finetuning, thus providing a strong
   basis for further training. However, finetuning the pretrained models
   show no performance increase compared to models trained without
   finetuning, as both approaches are capable of achieving near perfect
   classification on the dataset applied in this work. (C) 2019 IAgrE.
   Published by Elsevier Ltd. All rights reserved.},
Publisher = {ACADEMIC PRESS INC ELSEVIER SCIENCE},
Address = {525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA},
Type = {Article},
Language = {English},
Affiliation = {Madsen, SL (Corresponding Author), Aarhus Univ, Dept Engn, Finlandsgade 22, DK-8200 Aarhus N, Denmark.
   Madsen, Simon L.; Dyrmann, Mads; Jorgensen, Rasmus N.; Karstoft, Henrik, Aarhus Univ, Dept Engn, Finlandsgade 22, DK-8200 Aarhus N, Denmark.},
DOI = {10.1016/j.biosystemseng.2019.09.005},
ISSN = {1537-5110},
EISSN = {1537-5129},
Keywords = {Image synthesis; Plant seedlings; GAN; Low inter-class and high
   intra-class variance; Plant classification},
Research-Areas = {Agriculture},
Web-of-Science-Categories  = {Agricultural Engineering; Agriculture, Multidisciplinary},
Author-Email = {slm@eng.au.dk
   madsdyrmann@eng.au.dk
   rnj@eng.au.dk
   hka@eng.au.dk},
Affiliations = {Aarhus University},
ORCID-Numbers = {Dyrmann, Mads/0000-0002-6510-1609
   Leminen Madsen, Simon/0000-0002-0121-8824},
Funding-Acknowledgement = {Innovation Foundation Denmark as part of the RoboWeedMaPS project
   {[}6150-00027B]},
Funding-Text = {This work is founded by Innovation Foundation Denmark as part of the
   RoboWeedMaPS project {[}J. nr.6150-00027B].},
Cited-References = {{[}Anonymous], 2018, ARXIV180305573.
   Arjovsky M., 2017, ARXIV170107875.
   Bishop C.M., 2006, PATTERN RECOGN.
   Celisse A, 2008, COMPUT STAT DATA AN, V52, P2350, DOI 10.1016/j.csda.2007.10.002.
   Chen X., 2016, ADV NEURAL INFORM PR, P2172.
   Christiansen P, 2014, AUTOMATED CLASSIFICA.
   Denton E.L., 2015, ADV NEURAL INFORM PR, P1486, DOI DOI 10.5555/2969239.2969405.
   Dyrmann M., 2016, CIGR-AgEng Conference, 26-29 June 2016, Aarhus, Denmark. Abstracts and Full papers, P1.
   Dyrmann M., 2017, ARXIV171105458.
   Frid-Adar M, 2018, I S BIOMED IMAGING, P289, DOI 10.1109/ISBI.2018.8363576.
   Giuffrida MV, 2017, IEEE INT CONF COMP V, P2064, DOI 10.1109/ICCVW.2017.242.
   Goodfellow I., 2016, ARXIV170100160, DOI DOI 10.1038/NATURE14539.
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622.
   Gulrajani I., 2017, ADV NEURAL INF PROCE, P5767, DOI {[}10.48550/arXiv.1704.00028, DOI 10.5555/3295222.3295327].
   Halevy A, 2009, IEEE INTELL SYST, V24, P8, DOI 10.1109/MIS.2009.36.
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90.
   Karras T, 2017, ARXIV.
   Minervini M, 2017, PLANT J, V90, P204, DOI 10.1111/tpj.13472.
   Mundermann L, 2005, PLANT PHYSIOL, V139, P960, DOI 10.1104/pp.105.060483.
   Odena A, 2017, PR MACH LEARN RES, V70.
   Radford A, 2015, ARXIV.
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054.
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y.
   Salimans T, 2016, ADV NEUR IN, V29.
   Scharr H, 2016, MACH VISION APPL, V27, P585, DOI 10.1007/s00138-015-0737-3.
   Sogaard HT, 2005, BIOSYST ENG, V91, P271, DOI 10.1016/j.biosystemseng.2005.04.011.
   Sun C, 2017, IEEE I CONF COMP VIS, P843, DOI 10.1109/ICCV.2017.97.
   Szegedy C., 2015, P IEEE C COMP VIS PA.
   Tsaftaris SA, 2016, TRENDS PLANT SCI, V21, P989, DOI 10.1016/j.tplants.2016.10.002.
   Ubbens J, 2018, PLANT METHODS, V14, DOI 10.1186/s13007-018-0273-z.
   Ward D., 2018, ARXIV180710931.
   Xinyue Zhu, 2018, Advances in Knowledge Discovery and Data Mining. 22nd Pacific-Asia Conference, PAKDD 2018. Proceedings: LNAI 10939, P349, DOI 10.1007/978-3-319-93040-4\_28.
   Yosinski J., 2014, ADV NEURAL INFORM PR, P3320, DOI DOI 10.5555/2969033.2969197.
   Zhang H., 2017, ARXIV171010916.
   Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629.
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405.
   Zhu Y., 2018, P BMVC, P324.},
Number-of-Cited-References = {37},
Times-Cited = {15},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {19},
Journal-ISO = {Biosyst. Eng.},
Doc-Delivery-Number = {JN0PG},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000496605900010},
DA = {2023-08-12},
}

@article{ WOS:000480625700128,
Author = {Turkoglu, Muammer and Hanbay, Davut},
Title = {Leaf-based plant species recognition based on improved local binary
   pattern and extreme learning machine},
Journal = {PHYSICA A-STATISTICAL MECHANICS AND ITS APPLICATIONS},
Year = {2019},
Volume = {527},
Month = {AUG 1},
Abstract = {Over the past 15 years, many feature extraction methods have been used
   and developed for the recognition of plant species. These methods have
   mostly been performed using separation operations from the background
   based on a pre-processing stage. However, the Local Binary Patterns
   (LBP) method, which provides high performance in object recognition, is
   used to obtain textural features from images without need for a
   pre-processing stage. In this paper, we propose different approaches
   based on LBP for the recognition of plant leaves using extracted texture
   features from plant leaves. While the original LBP converts color images
   to gray tones, the proposed methods are applied by using the R and G
   color channel of images. In addition, we evaluate the robustness of the
   proposed methods against noise such as salt \& pepper and Gaussian.
   Later, the obtained features from the proposed methods were classified
   and tested using the Extreme Learning Machine (ELM) method. The
   experimental works were performed using various plant leaf datasets such
   as Flavia, Swedish, ICL, and Foliage. According to the obtained
   performance results, the calculated accuracy values for Flavia, Swedish,
   ICL and Foliage datasets were 98.94\%, 99.46\%, 83.71\%, and 92.92\%,
   respectively. The results demonstrate that the proposed method was more
   successful when compared to the original LBP, improved LBP methods, and
   other image descriptors for both noisy and noiseless images. (C) 2019
   Elsevier B.V. All rights reserved},
Publisher = {ELSEVIER},
Address = {RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Turkoglu, M (Corresponding Author), Bingol Univ, Engn Fac, Comp Engn Dept, TR-12000 Bingol, Turkey.
   Turkoglu, Muammer, Bingol Univ, Engn Fac, Comp Engn Dept, TR-12000 Bingol, Turkey.
   Hanbay, Davut, Inonu Univ, Engn Fac, Comp Engn Dept, TR-44280 Malatya, Turkey.},
DOI = {10.1016/j.physa.2019.121297},
Article-Number = {121297},
ISSN = {0378-4371},
EISSN = {1873-2119},
Keywords = {Plant classification; Local binary pattern; Image descriptors;
   Region-overall LBP; Extreme learning machine},
Keywords-Plus = {FEATURE-EXTRACTION; FACE RECOGNITION; CLASSIFICATION; DESCRIPTORS},
Research-Areas = {Physics},
Web-of-Science-Categories  = {Physics, Multidisciplinary},
Author-Email = {mturkoglu@bingol.edu.tr},
Affiliations = {Bingol University; Inonu University},
ResearcherID-Numbers = {Hanbay, Davut/AAG-8511-2019},
ORCID-Numbers = {Hanbay, Davut/0000-0003-2271-7865},
Cited-References = {Abdullah MFA, 2014, EXPERT SYST APPL, V41, P6131, DOI 10.1016/j.eswa.2014.04.006.
   Abusham EEA, 2011, LECT NOTES COMPUT SC, V6762, P169.
   Ahmed FM, 2011, IEEE RAD CONF, P320.
   Alcin OF, 2015, J INTELL SYST, V24, P135, DOI 10.1515/jisys-2014-0095.
   {[}Anonymous], TURKIYE BILISIM VAKF.
   Chaki J, 2015, 2015 IEEE 2ND INTERNATIONAL CONFERENCE ON RECENT TRENDS IN INFORMATION SYSTEMS (RETIS), P189, DOI 10.1109/ReTIS.2015.7232876.
   Chakraborty S, 2017, COMPUT ELECTR ENG, V62, P92, DOI 10.1016/j.compeleceng.2017.06.013.
   Oliveira MWD, 2015, PHYSICA A, V439, P160, DOI 10.1016/j.physa.2015.06.046.
   Florindo JB, 2018, PHYSICA A, V493, P189, DOI 10.1016/j.physa.2017.10.012.
   Hasim A., 2016, IOP C SERIES EARTH E.
   HE DC, 1990, IEEE T GEOSCI REMOTE, V28, P509.
   Herdiyeni Y, 2012, 2012 INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER SCIENCE AND INFORMATION SYSTEMS, P255.
   Huang GB, 2004, IEEE IJCNN, P985.
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126.
   Iwata T, 2013, PROC SICE ANN CONF, P2489.
   Kadir Abdul, 2012, Journal of Theoretical and Applied Information Technology, V41, P82.
   Kadir A., 2015, GATE COMPUTER VISION, V1, P3, DOI DOI 10.15579/GTCVPR.0101.003007.
   Kadir A., 2011, INT J COMPUT APPL, V29, P15, DOI DOI 10.5120/3592-4981.
   Kalyoncu C, 2015, COMPUT VIS IMAGE UND, V133, P102, DOI 10.1016/j.cviu.2014.11.001.
   Kaynar O., 2017, 2017 INT ART INT DAT, P1.
   Kulkarni A. H., 2013, INT J ADV RES COMPUT, V2, P984.
   Lee K.-B., 2013, INT J BIOSCI BIOTECH, V5, P57, DOI {[}10.14257/ijbsbt.2013.5.5.06, DOI 10.14257/IJBSBT.2013.5.5.06, 10.3724/sp.j.1087.2009.01707, DOI 10.1007/978-94-007-5857-5\_12].
   Lukic M, 2017, 2017 IEEE 15TH INTERNATIONAL SYMPOSIUM ON APPLIED MACHINE INTELLIGENCE AND INFORMATICS (SAMI), P485, DOI 10.1109/SAMI.2017.7880358.
   Machicao J, 2018, PHYSICA A, V497, P109, DOI 10.1016/j.physa.2017.12.072.
   Mahdikhanlou K, 2014, IRAN CONF ELECTR ENG, P1690, DOI 10.1109/IranianCEE.2014.6999810.
   Milacic L, 2017, PHYSICA A, V465, P285, DOI 10.1016/j.physa.2016.08.040.
   Muthevi A, 2017, IEEE INT ADV COMPUT, P870, DOI {[}10.1109/IACC.2017.169, 10.1109/IACC.2017.0178].
   Naresh YG, 2016, NEUROCOMPUTING, V173, P1789, DOI 10.1016/j.neucom.2015.08.090.
   Nijalingappa P, 2015, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON APPLIED AND THEORETICAL COMPUTING AND COMMUNICATION TECHNOLOGY (ICATCCT), P338, DOI 10.1109/ICATCCT.2015.7456906.
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS \& IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47.
   Pushpa BR, 2016, INT J APPL ENG RES, V11, P5142.
   Rakic G, 2019, PHYSICA A, V513, P418, DOI 10.1016/j.physa.2018.09.010.
   Rakshit RD, 2018, EXPERT SYST APPL, V92, P82, DOI 10.1016/j.eswa.2017.09.038.
   Rojanamontien M, 2016, INT CONF KNOWL SMART, P234, DOI 10.1109/KST.2016.7440521.
   Shabanzade M., 2011, SIGNAL IMAGE PROCESS, V2, P23, DOI DOI 10.5121/sipij.2011.2303.
   Sigirci IO, 2015, SIG PROCESS COMMUN, P1078, DOI 10.1109/SIU.2015.7130020.
   Silva PFB, 2013, LECT NOTES COMPUT SC, V7950, P197, DOI 10.1007/978-3-642-39094-4\_23.
   Soderkvist O., 2001, THESIS.
   Tiwari D, 2016, COMPUT VIS IMAGE UND, V150, P58, DOI 10.1016/j.cviu.2016.04.010.
   Tuncer T., 2018, 2018 26 SIGN PROC CO, P1.
   Vi Nguyen Thanh Le, 2019, Information Processing in Agriculture, V6, P116, DOI 10.1016/j.inpa.2018.08.002.
   Wang XF, 2008, APPL MATH COMPUT, V205, P916, DOI 10.1016/j.amc.2008.05.108.
   Wang X, 2014, DIGIT SIGNAL PROCESS, V34, P101, DOI 10.1016/j.dsp.2014.08.005.
   Wang ZB, 2014, IEEE IJCNN, P975, DOI 10.1109/IJCNN.2014.6889656.
   Wu SG, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, VOLS 1-3, P120.
   Xia Q, 2014, LECT NOTES ARTIF INT, V8589, P369, DOI 10.1007/978-3-319-09339-0\_38.
   Xiao XY, 2010, LECT NOTES ARTIF INT, V6216, P149, DOI 10.1007/978-3-642-14932-0\_19.
   Zhang H., 2015, J COMPUTIONAL SYSTEM, V11, P141.
   Zhu C, 2013, PATTERN RECOGN, V46, P1949, DOI 10.1016/j.patcog.2013.01.003.},
Number-of-Cited-References = {49},
Times-Cited = {24},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {20},
Journal-ISO = {Physica A},
Doc-Delivery-Number = {IQ3BO},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000480625700128},
DA = {2023-08-12},
}

@article{ WOS:000829611700003,
Author = {Lu, Zhiguo and Zheng, Yuhong and Zhang, Pengchong and Fan, Boyuan and
   Yu, Aimin and Fu, Li},
Title = {Electrochemical Identification of Yulania spp. by Fingerprinting of
   Leaves Using Glassy Carbon Electrode},
Journal = {PHYTON-INTERNATIONAL JOURNAL OF EXPERIMENTAL BOTANY},
Year = {2022},
Volume = {91},
Number = {11},
Pages = {2549-2558},
Abstract = {In this communication, we used electrochemical sensor for recording the
   electrochemical profiles of eleven species of Yulania spp. from leaf
   extract. Two solvents and two buffer conditions were used for
   electrochemical fingerprints collection. Their electrochemical
   fingerprints can be converted to different patterns and consequently for
   species recognition. The results indicate the pattern recognition is
   much convenient than that of the recognition of species directly using
   voltammetric signal. The current information in electrochemical
   fingerprinting represents the type and amount of electrochemically
   active molecules, which linked to the genetic differences among the
   plants. Therefore, the electrochemical fingerprints were applied for
   further phylogenetic study. The phylogenetic tree deduced from
   voltametric curves is divided into three main groups. The first clade
   contains Y. denudate, kobus, and Y. amoena. The third clade contains Y.
   ?? soulangeana, Manglietia fordiana and Y. sinostellata. In addition, Y.
   salicifolia is not in these main clades. The results demonstrate that
   electrochemical fingerprinting can be used as a com-plementary tool in
   the study of phylogenetics.},
Publisher = {TECH SCIENCE PRESS},
Address = {871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA},
Type = {Article},
Language = {English},
Affiliation = {Zheng, YH (Corresponding Author), Inst Bot, Nanjing 210014, Jiangsu, Peoples R China.
   Zheng, YH (Corresponding Author), Chinese Acad Sci, Nanjing Bot Garden, Mem Sun Yat Sen, Nanjing 210014, Peoples R China.
   Fu, L (Corresponding Author), Hangzhou Dianzi Univ, Coll Mat \& Environm Engn, Hangzhou 310018, Peoples R China.
   Lu, Zhiguo; Zheng, Yuhong, Inst Bot, Nanjing 210014, Jiangsu, Peoples R China.
   Lu, Zhiguo; Zheng, Yuhong, Chinese Acad Sci, Nanjing Bot Garden, Mem Sun Yat Sen, Nanjing 210014, Peoples R China.
   Zhang, Pengchong, Hangzhou West Lake Acad Landscape Sci, Hangzhou Bot Garden, Hangzhou 310013, Peoples R China.
   Fan, Boyuan; Fu, Li, Hangzhou Dianzi Univ, Coll Mat \& Environm Engn, Hangzhou 310018, Peoples R China.
   Yu, Aimin, Swinburne Univ Technol, Fac Sci Engn \& Technol, Dept Chem \& Biotechnol, Hawthorn, Vic 3122, Australia.},
DOI = {10.32604/phyton.2022.021288},
ISSN = {0031-9457},
EISSN = {1851-5657},
Keywords = {Phylogenetic; Yulania spp; plant identification; fingerprints;
   chemotaxonomy},
Keywords-Plus = {COMPLETE CHLOROPLAST GENOME},
Research-Areas = {Plant Sciences},
Web-of-Science-Categories  = {Plant Sciences},
Author-Email = {zhengyuhong@cnbg.net
   fuli@hdu.edu.cn},
Affiliations = {Chinese Academy of Sciences; Hangzhou Dianzi University; Swinburne
   University of Technology},
ResearcherID-Numbers = {Zheng, Yu/GRJ-5808-2022},
Funding-Acknowledgement = {Jiangsu Agriculture Science and Technology Innovation Fund (JASTIF)
   {[}CX (21)3044]; National Natural Science Foundation of China
   {[}22004026]},
Funding-Text = {This research was supported by the Jiangsu Agriculture Science and
   Technology Innovation Fund (JASTIF, No. CX (21)3044) and National
   Natural Science Foundation of China (22004026).},
Cited-References = {Almerekova S, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0240121.
   Arogundade O. O., 2020, Notulae Scientia Biologicae, V12, P318, DOI 10.15835/nsb12210537.
   Azuma H, 2011, THAI FOREST B BOT, V39, P148.
   Vundac VB, 2019, PLANTS-BASEL, V8, DOI 10.3390/plants8020032.
   Bonini SA, 2018, J ETHNOPHARMACOL, V227, P300, DOI 10.1016/j.jep.2018.09.004.
   Ortiz AC, 2021, FORESTS, V12, DOI 10.3390/f12060703.
   Domenech-Carbo A, 2015, NEW J CHEM, V39, P7421, DOI 10.1039/c5nj01233c.
   Du XiWu, 2019, Journal of West China Forestry Science, V48, P132.
   Fan BY, 2021, BIOSENSORS-BASEL, V11, DOI 10.3390/bios11050155.
   Fu D. L., 2019, AM J AGR FORESTRY, V7, P200, DOI {[}10.11648/j.ajaf.20190705.16, DOI 10.11648/J.AJAF.20190705.16].
   Fu D. L., 2019, AM J AGR FORESTRY, V7, P229, DOI {[}10.11648/j.ajaf.20190705.19, DOI 10.11648/J.AJAF.20190705.19].
   Fu DL, 2001, J WUHAN BOT RES, V19, P191.
   Fu L, 2022, CHEMOSPHERE, V297, DOI 10.1016/j.chemosphere.2022.134127.
   Fu L, 2021, J HERB MED, V30, DOI 10.1016/j.hermed.2021.100512.
   Fu L, 2021, BIOELECTROCHEMISTRY, V140, DOI 10.1016/j.bioelechem.2021.107829.
   Fu L, 2020, BIOSENS BIOELECTRON, V159, DOI 10.1016/j.bios.2020.112212.
   Fu L, 2019, BIOELECTROCHEMISTRY, V129, P199, DOI 10.1016/j.bioelechem.2019.06.001.
   Fu L, 2018, BIOSENS BIOELECTRON, V120, P102, DOI 10.1016/j.bios.2018.08.052.
   Koch MA, 2018, TRENDS PLANT SCI, V23, P4, DOI 10.1016/j.tplants.2017.10.005.
   Kuang DY, 2011, GENOME, V54, P663, DOI {[}10.1139/G11-026, 10.1139/g11-026].
   Leff JW, 2018, ISME J, V12, P1794, DOI 10.1038/s41396-018-0089-x.
   Lei GM, 2016, J CHEM TECHNOL BIOT, V91, P1896, DOI 10.1002/jctb.4785.
   Mannaa M, 2019, INT J MOL SCI, V20, DOI 10.3390/ijms20010121.
   Roma-Marzio F, 2017, PHYTOCHEMISTRY, V141, P48, DOI 10.1016/j.phytochem.2017.05.008.
   Shi S, 2000, THEOR APPL GENET, V101, P925, DOI 10.1007/s001220051563.
   Si HongMin, 2019, Journal of West China Forestry Science, V48, P7.
   Sun Li-Yong, 2018, Plant Science Journal, V36, P804, DOI 10.11913/PSJ.2095-0837.2018.60804.
   Sun LY, 2020, GENE, V736, DOI 10.1016/j.gene.2020.144410.
   Wang YL, 2016, CYTOLOGIA, V81, P194, DOI 10.1508/cytologia.81.195.
   Wang YaLing, 2003, Acta Horticulturae Sinica, V30, P299.
   Wang YL, 2006, ACTA PHYTOTAXON SIN, V44, P135, DOI 10.1360/aps040013.
   Xie HH, 2019, MITOCHONDRIAL DNA B, V4, P830, DOI 10.1080/23802359.2019.1567286.
   Xu YT, 2020, BIOELECTROCHEMISTRY, V133, DOI 10.1016/j.bioelechem.2020.107455.
   Yahyaabadi Y., 2020, J PLANT RES IRANIAN, V33, P843.
   Zhang MJ, 2020, CHEMISTRYSELECT, V5, P5035, DOI 10.1002/slct.202001100.
   Zhao D. X., 2008, J ANHUI AGR SCI, V35, P11811.
   Zhou JT, 2020, ANAL LETT, V53, P2517, DOI 10.1080/00032719.2020.1746327.
   Zhu B., 2021, J BIOL UDAYANA, V1, P1, DOI {[}10.1007/s12374-013-0111-9, DOI 10.1007/S12374-013-0111-9].},
Number-of-Cited-References = {38},
Times-Cited = {1},
Usage-Count-Last-180-days = {4},
Usage-Count-Since-2013 = {13},
Journal-ISO = {Phyton-Int. J. Exp. Bot.},
Doc-Delivery-Number = {3D9KC},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000829611700003},
OA = {gold},
DA = {2023-08-12},
}

@article{ WOS:000371944900015,
Author = {Moghaddam, Parviz Ahmadi and Arasteh, Amir Sheykhi and Komarizadeh,
   Mohammad Hasan and Babazadeh, Saeedeh},
Title = {Developing a selective thinning algorithm in sugar beet fields using
   machine vision system},
Journal = {COMPUTERS AND ELECTRONICS IN AGRICULTURE},
Year = {2016},
Volume = {122},
Pages = {133-138},
Month = {MAR},
Abstract = {Row crops thinning is an effective operation in the production of most
   agricultural crops. However, it is costly, exhausting and harmful for
   the health of workers. The main purpose of this research is developing a
   high accuracy algorithm to recognize sugar beet plants and eliminate
   excessive plants. Images were captured with a CCD digital camera when
   all plants had 4-6 leaves. In this study, two methods were used to
   recognize sugar beet plants, the mass center algorithm (MC) and the
   average width algorithm (AW). Images revealed that overlapping between
   plants is the main problem in plants recognition. The average width
   method is appeared to be more accurate than the other method, especially
   in high overlapping conditions. Moreover, the mean of accuracies in
   removal of plants, which should be removed, are significantly different
   (alpha = 0.05) by T-test. Device testing in vitro conditions indicated
   that accuracy of average width algorithm in detection of excessive
   plants is reached to 88\%. The results showed that three sequential
   images should be checked simultaneously in order to reduce errors in
   recognition of excessive plants. (C) 2016 Elsevier B.V. All rights
   reserved.},
Publisher = {ELSEVIER SCI LTD},
Address = {THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Moghaddam, PA (Corresponding Author), Urmia Univ, Dept Biosyst Engn, Fac Agr, Orumiyeh, Iran.
   Moghaddam, Parviz Ahmadi; Arasteh, Amir Sheykhi; Komarizadeh, Mohammad Hasan; Babazadeh, Saeedeh, Urmia Univ, Dept Biosyst Engn, Fac Agr, Orumiyeh, Iran.},
DOI = {10.1016/j.compag.2016.01.025},
ISSN = {0168-1699},
EISSN = {1872-7107},
Keywords = {Machine vision; Thinning; Overlapping; Sugar beet; Image processing;
   T-test},
Keywords-Plus = {MECHANICAL WEED-CONTROL},
Research-Areas = {Agriculture; Computer Science},
Web-of-Science-Categories  = {Agriculture, Multidisciplinary; Computer Science, Interdisciplinary
   Applications},
Author-Email = {p.ahmadi@urmia.ac.ir},
Affiliations = {Urmia University},
Cited-References = {Astrand B, 2002, AUTON ROBOT, V13, P21, DOI 10.1023/A:1015674004201.
   Bakker T, 2008, COMPUT ELECTRON AGR, V60, P87, DOI 10.1016/j.compag.2007.07.006.
   Liu J, 2000, T ASAE, V43, P757, DOI 10.13031/2013.2759.
   Siemens MC, 2012, 121338169 ASABE, P14.
   Slaughter DC, 2008, COMPUT ELECTRON AGR, V61, P63, DOI 10.1016/j.compag.2007.05.008.
   Sun XC, 2016, AGR FOREST METEOROL, V216, P48, DOI 10.1016/j.agrformet.2015.10.006.
   Symonds P, 2015, COMPUT ELECTRON AGR, V117, P57, DOI 10.1016/j.compag.2015.07.011.
   Tian L., 1995, KNOWLEDGE BASED MACH, V9, P10.
   Tillett ND, 2008, BIOSYST ENG, V99, P171, DOI 10.1016/j.biosystemseng.2007.09.026.
   van der Weide RY, 2008, WEED RES, V48, P215, DOI 10.1111/j.1365-3180.2008.00629.x.},
Number-of-Cited-References = {10},
Times-Cited = {4},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {18},
Journal-ISO = {Comput. Electron. Agric.},
Doc-Delivery-Number = {DG3BQ},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000371944900015},
DA = {2023-08-12},
}

@article{ WOS:000395520700017,
Author = {Rueda Plata, Diego and Ramos-Pollan, Raul and Gonzalez, Fabio A.},
Title = {Effective training of convolutional neural networks with small,
   specialized datasets},
Journal = {JOURNAL OF INTELLIGENT \& FUZZY SYSTEMS},
Year = {2017},
Volume = {32},
Number = {2},
Pages = {1333-1342},
Abstract = {This work proposes a supervised layer-wise strategy to train deep
   convolutional neural networks (DCNs) particularly suited for small,
   specialized image datasets. DCNs are increasingly being used with
   considerable success in image classification tasks and trained over
   large datasets (with more than 1M images and 10K classes). Pre-trained
   successful DCNs can then be used for new smaller datasets (10K to 100K
   images) through a transfer learning process which cannot guarantee
   competitive a-priori performance if the new data is of different or
   specialized nature (medical imaging, plant recognition, etc.). We
   therefore seek out to find competitive techniques to train DCNs for such
   small datasets, and hereby describe a supervised greedy layer-wise
   method analogous to that used in unsupervised deep networks. Our method
   consistently outperforms the traditional methods that train a full DCN
   architecture in a single stage, yielding an average of over 20\%
   increase in classification performance across all DCN architectures and
   datasets used in this work. Furthermore, we obtain more interpretable
   and cleaner visual features. Our method is better suited for small,
   specialized datasets since we require a training cycle for each DCN
   layer and this increases its computing time almost linearly with the
   number of layers. Nevertheless, it still remains as a fraction of the
   computing time required to generate pre-trained models with large
   generic datasets, and poses no additional requirements on hardware. This
   constitutes a solid alternative for training DCNs when transfer learning
   is not possible and, furthermore, suggests that state of the art DCN
   performance with large datasets might yet be improved at the expense of
   a higher computing time.},
Publisher = {IOS PRESS},
Address = {NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Ramos-Pollan, R (Corresponding Author), Univ Ind Santander, Cra 27 Calle 9, Bucaramanga, Colombia.
   Rueda Plata, Diego; Ramos-Pollan, Raul, Univ Ind Santander, Cra 27 Calle 9, Bucaramanga, Colombia.
   Gonzalez, Fabio A., Univ Nacl Colombia, MindLab Res Grp, Bogota, Colombia.},
DOI = {10.3233/JIFS-169131},
ISSN = {1064-1246},
EISSN = {1875-8967},
Keywords = {Convolutional networks; deep learning; greedy layer-wise training},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence},
Author-Email = {rramosp@uis.edu.co},
Affiliations = {Universidad Industrial de Santander; Universidad Nacional de Colombia},
ORCID-Numbers = {Rueda, Diego/0000-0003-2818-3323},
Funding-Acknowledgement = {VIE at Universidad Industrial de Santander (UIS) {[}1905]; project
   ``Desarrollo de un Sistema Informatico para la Busqueda Sistematica de
   Fuentes Naturales para la Elaboracion de Bioproductos{''} through
   Colciencias {[}FP44842-576-2014];  {[}P50 AG05681];  {[}P01 AG03991]; 
   {[}R01 AG021910];  {[}P50 MH071616];  {[}U24 RR021382];  {[}R01 MH56584]},
Funding-Text = {This work was partially funded by project titled ``Plataforma de
   deteccion de gradientes ionosfericos para sistemas de posicionamiento
   global con aumentacion terrestre{''} number 1905 from VIE at Universidad
   Industrial de Santander (UIS); and, also partially, by project
   ``Desarrollo de un Sistema Informatico para la Busqueda Sistematica de
   Fuentes Naturales para la Elaboracion de Bioproductos{''} number
   FP44842-576-2014 through Colciencias. Experiments were run on the High
   Performance and Scientific Computing Centre at UIS
   (http://www.sc3.uis.edu.co). OASIS data is accessible through the
   following grant numbers: P50 AG05681, P01 AG03991, R01 AG021910, P50
   MH071616, U24 RR021382, R01 MH56584.},
Cited-References = {Bengio Y, 2007, P ADV NEUR INF PROC, V19, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024.
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50.
   Bossard L, 2014, LECT NOTES COMPUT SC, V8694, P446, DOI 10.1007/978-3-319-10599-4\_29.
   Erhan D, 2010, J MACH LEARN RES, V11, P625.
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251.
   He K, 2015, C COMPUTER VISION PA.
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527.
   Hinton Geoffrey E., 2012, NEURAL NETWORKS TRIC, P599, DOI 10.1007/978-3-642-35289-8\_32.
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI {[}10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2].
   Jacobsen J.-H., 2016, ARXIV160502971.
   Jia Y., 2014, ACM INT C MULT, DOI {[}DOI 10.1145/2647868.2654889, 10.1145/2647868.2654889].
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386.
   Larochelle H, 2009, J MACH LEARN RES, V10, P1.
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791.
   LeCun Y., 1995, CONVOLUTIONAL NETWOR, P255, DOI {[}10.5555/303568.303704, DOI 10.5555/303568.303704].
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS \& IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47.
   Penatti Otavio A. B., 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P44, DOI 10.1109/CVPRW.2015.7301382.
   Rueda-Plata D, 2015, LECT NOTES ARTIF INT, V9329, P275, DOI 10.1007/978-3-319-24069-5\_26.
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003.
   Vincent P, 2010, J MACH LEARN RES, V11, P3371.
   Yang Y, 2010, P 18 SIGSPATIAL INT, DOI {[}10.1145/1869790.1869829, DOI 10.1145/1869790.1869829].},
Number-of-Cited-References = {21},
Times-Cited = {3},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {8},
Journal-ISO = {J. Intell. Fuzzy Syst.},
Doc-Delivery-Number = {EM7VP},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000395520700017},
DA = {2023-08-12},
}

@article{ WOS:000780307600001,
Author = {Kim, Tae Kyung and Hong, Jeonghyun and Ryu, Daun and Kim, Sukyung and
   Byeon, Si Yeon and Huh, Woojin and Kim, Kunhyo and Baek, Gyu Heon and
   Kim, Hyun Seok},
Title = {Identifying and extracting bark key features of 42 tree species using
   convolutional neural networks and class activation mapping},
Journal = {SCIENTIFIC REPORTS},
Year = {2022},
Volume = {12},
Number = {1},
Month = {MAR 19},
Abstract = {The significance of automatic plant identification has already been
   recognized by academia and industry. There were several attempts to
   utilize leaves and flowers for identification; however, bark also could
   be beneficial, especially for trees, due to its consistency throughout
   the seasons and its easy accessibility, even in high crown conditions.
   Previous studies regarding bark identification have mostly contributed
   quantitatively to increasing classification accuracy. However, ever
   since computer vision algorithms surpassed the identification ability of
   humans, an open question arises as to how machines successfully
   interpret and unravel the complicated patterns of barks. Here, we
   trained two convolutional neural networks (CNNs) with distinct
   architectures using a large-scale bark image dataset and applied class
   activation mapping (CAM) aggregation to investigate diagnostic keys for
   identifying each species. CNNs could identify the barks of 42 species
   with > 90\% accuracy, and the overall accuracies showed a small
   difference between the two models. Diagnostic keys matched with salient
   shapes, which were also easily recognized by human eyes, and were
   typified as blisters, horizontal and vertical stripes, lenticels of
   various shapes, and vertical crevices and clefts. The two models
   exhibited disparate quality in the diagnostic features: the old and less
   complex model showed more general and well-matching patterns, while the
   better-performing model with much deeper layers indicated local patterns
   less relevant to barks. CNNs were also capable of predicting untrained
   species by 41.98\% and 48.67\% within the correct genus and family,
   respectively. Our methodologies and findings are potentially applicable
   to identify and visualize crucial traits of other plant organs.},
Publisher = {NATURE PORTFOLIO},
Address = {HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY},
Type = {Article},
Language = {English},
Affiliation = {Kim, HS (Corresponding Author), Seoul Natl Univ, Dept Agr Forestry \& Bioresources, Seoul 08826, South Korea.
   Kim, HS (Corresponding Author), Seoul Natl Univ, Dept Forest Sci, Seoul 08826, South Korea.
   Kim, HS (Corresponding Author), Seoul Natl Univ, Interdisciplinary Program Agr \& Forest Meteorol, Seoul 08826, South Korea.
   Kim, HS (Corresponding Author), Natl Ctr Agrometeorol, Seoul 08826, South Korea.
   Kim, HS (Corresponding Author), Seoul Natl Univ, Res Inst Agr \& Life Sci, Seoul 08826, South Korea.
   Kim, Tae Kyung; Hong, Jeonghyun; Kim, Sukyung; Byeon, Si Yeon; Huh, Woojin; Kim, Kunhyo; Kim, Hyun Seok, Seoul Natl Univ, Dept Agr Forestry \& Bioresources, Seoul 08826, South Korea.
   Baek, Gyu Heon; Kim, Hyun Seok, Seoul Natl Univ, Dept Forest Sci, Seoul 08826, South Korea.
   Ryu, Daun; Kim, Hyun Seok, Seoul Natl Univ, Interdisciplinary Program Agr \& Forest Meteorol, Seoul 08826, South Korea.
   Kim, Hyun Seok, Natl Ctr Agrometeorol, Seoul 08826, South Korea.
   Kim, Hyun Seok, Seoul Natl Univ, Res Inst Agr \& Life Sci, Seoul 08826, South Korea.},
DOI = {10.1038/s41598-022-08571-9},
Article-Number = {4772},
ISSN = {2045-2322},
Research-Areas = {Science \& Technology - Other Topics},
Web-of-Science-Categories  = {Multidisciplinary Sciences},
Author-Email = {cameroncrazies@snu.ac.kr},
Affiliations = {Seoul National University (SNU); Seoul National University (SNU); Seoul
   National University (SNU); Seoul National University (SNU)},
Funding-Acknowledgement = {Korea Forest Service (Korea Forestry Promotion Institute); National
   Research Foundation of Korea (NRF) {[}2018113B10-2020-BB01,
   2020185D10-2222-AA02, 2021R1A4A1025553]; Korea Forestry Promotion
   Institute (KOFPI) {[}2020185D10-2222-AA02, 2018113B10-2020-BB01] Funding
   Source: Korea Institute of Science \& Technology Information (KISTI),
   National Science \& Technology Information Service (NTIS); National
   Research Foundation of Korea {[}2021R1A4A1025553] Funding Source: Korea
   Institute of Science \& Technology Information (KISTI), National Science
   \& Technology Information Service (NTIS)},
Funding-Text = {This work was supported by Korea Forest Service (Korea Forestry
   Promotion Institute), and National Research Foundation of Korea (NRF),
   project No. 2018113B10-2020-BB01, No. 2020185D10-2222-AA02, and No.
   2021R1A4A1025553.},
Cited-References = {Azlah MAF, 2019, COMPUTERS, V8, DOI 10.3390/computers8040077.
   Baek Y, 2019, PROC CVPR IEEE, P9357, DOI 10.1109/CVPR.2019.00959.
   Ben-David S, 2020, ARXIV PREPRINT ARXIV.
   Bieker VC, 2018, BOT LETT, V165, P409, DOI 10.1080/23818107.2018.1458651.
   Boudra S, 2015, LECT NOTES COMPUT SC, V9386, P764, DOI 10.1007/978-3-319-25903-1\_66.
   Lima MCF, 2020, AGRICULTURE-BASEL, V10, DOI 10.3390/agriculture10050161.
   Carpentier M, 2018, IEEE INT C INT ROBOT, P1075, DOI 10.1109/IROS.2018.8593514.
   Chattopadhay A., 2018 IEEE WINT C APP, P839.
   Chi Z., INT C NEUR NETW SIGN, P1035.
   Cope JS, 2012, EXPERT SYST APPL, V39, P7562, DOI 10.1016/j.eswa.2012.01.073.
   Cubuk ED, 2020, IEEE COMPUT SOC CONF, P3008, DOI 10.1109/CVPRW50498.2020.00359.
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848.
   Fekri-Ershad S, 2020, EXPERT SYST APPL, V158, DOI 10.1016/j.eswa.2020.113509.
   Fiel S., 2010, 16 COMP VIS WINT WOR, P67.
   Gogul I, 2017, 2017 FOURTH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMMUNICATION AND NETWORKING (ICSCN).
   Hadlich HL, 2018, FOREST ECOL MANAG, V427, P296, DOI 10.1016/j.foreco.2018.06.002.
   Pham H, 2021, PROC CVPR IEEE, P11552, DOI 10.1109/CVPR46437.2021.01139.
   Hopkins GW, 2002, ANIM CONSERV, V5, P245, DOI 10.1017/S1367943002002299.
   JUNIKKA L, 1994, IAWA J, V15, P3, DOI 10.1163/22941932-90001338.
   Kim T. K., 2021, {*}{*}DATA OBJECT{*}{*}, DOI 10.5281/zenodo.4749062.
   Kim TK, 2021, ECOL MODEL, V440, DOI 10.1016/j.ecolmodel.2020.109419.
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386.
   Kumar N, 2012, LECT NOTES COMPUT SC, V7573, P502, DOI 10.1007/978-3-642-33709-3\_36.
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539.
   Lee SH, 2015, IEEE IMAGE PROC, P452, DOI 10.1109/ICIP.2015.7350839.
   Liang Y-Q., 2008, FOR STUD CHINA, V10, P179, DOI 10.1007/s11632-008-0036-4.
   MacLeod N, 2010, NATURE, V467, P154, DOI 10.1038/467154a.
   Majeed Y, 2020, COMPUT ELECTRON AGR, V171, DOI 10.1016/j.compag.2020.105308.
   Mizoguchi T, 2017, PROC SPIE, V10332, DOI 10.1117/12.2270123.
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS \& IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47.
   Norouzzadeh MS, 2018, P NATL ACAD SCI USA, V115, pE5716, DOI 10.1073/pnas.1719367115.
   Pearson DL, 2011, BIOSCIENCE, V61, P58, DOI 10.1525/bio.2011.61.1.11.
   Qizhe Xie, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10684, DOI 10.1109/CVPR42600.2020.01070.
   Rangarajan AK, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-59108-x.
   Ratajczak R, 2019, VISAPP: PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 4, P240, DOI 10.5220/0007361902400248.
   Rathi D, 2017, 2017 NINTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION (ICAPR), P344.
   Rosell JA, 2014, NEW PHYTOL, V201, P486, DOI 10.1111/nph.12541.
   Rzanny M, 2019, PLANT METHODS, V15, DOI 10.1186/s13007-019-0462-4.
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI {[}10.1109/ICCV.2017.74, 10.1007/s11263-019-01228-7].
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556.
   Sokolova M, 2009, INFORM PROCESS MANAG, V45, P427, DOI 10.1016/j.ipm.2009.03.002.
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594.
   Tan MX, 2019, PR MACH LEARN RES, V97.
   WHITMORE T. C., 1962, NEW PHYTOL, V61, P191, DOI 10.1111/j.1469-8137.1962.tb06288.x.
   Wilf P, 2016, P NATL ACAD SCI USA, V113, P3305, DOI 10.1073/pnas.1524473113.
   YUNUS M, 1990, BOT J LINN SOC, V103, P367, DOI 10.1111/j.1095-8339.1990.tb00196.x.
   Zhang YS, 2020, IEEE WINT CONF APPL, P173, DOI 10.1109/WACVW50321.2020.9096945.
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319.},
Number-of-Cited-References = {48},
Times-Cited = {0},
Usage-Count-Last-180-days = {4},
Usage-Count-Since-2013 = {6},
Journal-ISO = {Sci Rep},
Doc-Delivery-Number = {0J7UT},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000780307600001},
OA = {gold, Green Published},
DA = {2023-08-12},
}

@article{ WOS:000402880700029,
Author = {Zhang, Shanwen and Wu, Xiaowei and You, Zhuhong},
Title = {Jaccard distance based weighted sparse representation for coarse-to-fine
   plant species recognition},
Journal = {PLOS ONE},
Year = {2017},
Volume = {12},
Number = {6},
Month = {JUN 7},
Abstract = {Leaf based plant species recognition plays an important role in
   ecological protection, however its application to large and modern leaf
   databases has been a long-standing obstacle due to the computational
   cost and feasibility. Recognizing such limitations, we propose a Jaccard
   distance based sparse representation (JDSR) method which adopts a
   two-stage, coarse to fine strategy for plant species recognition. In the
   first stage, we use the Jaccard distance between the test sample and
   each training sample to coarsely determine the candidate classes of the
   test sample. The second stage includes a Jaccard distance based weighted
   sparse representation based classification(WSRC), which aims to
   approximately represent the test sample in the training space, and
   classify it by the approximation residuals. Since the training model of
   our JDSR method involves much fewer but more informative
   representatives, this method is expected to overcome the limitation of
   high computational and memory costs in traditional sparse representation
   based classification. Comparative experimental results on a public leaf
   image database demonstrate that the proposed method outperforms other
   existing feature extraction and SRC based plant recognition methods in
   terms of both accuracy and computational speed.},
Publisher = {PUBLIC LIBRARY SCIENCE},
Address = {1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA},
Type = {Article},
Language = {English},
Affiliation = {You, ZH (Corresponding Author), Xijing Univ, Dept Informat Engn, Xian, Peoples R China.
   Zhang, Shanwen; You, Zhuhong, Xijing Univ, Dept Informat Engn, Xian, Peoples R China.
   Zhang, Shanwen; Wu, Xiaowei, Virginia Tech, Dept Stat, Blacksburg, VA USA.},
DOI = {10.1371/journal.pone.0178317},
Article-Number = {e0178317},
ISSN = {1932-6203},
Keywords-Plus = {DICTIONARY; ALGORITHM},
Research-Areas = {Science \& Technology - Other Topics},
Web-of-Science-Categories  = {Multidisciplinary Sciences},
Author-Email = {zhuhongyou@163.com},
Affiliations = {Xijing University; Virginia Polytechnic Institute \& State University},
ResearcherID-Numbers = {You, Zhu-Hong/AAI-6862-2020
   You, Zhu-Hong/A-4056-2011},
ORCID-Numbers = {You, Zhu-Hong/0000-0003-1266-2696},
Cited-References = {Chaki J, 2015, PATTERN RECOGN LETT, V58, P61, DOI 10.1016/j.patrec.2015.02.010.
   Du JX, 2007, APPL MATH COMPUT, V185, P883, DOI 10.1016/j.amc.2006.07.072.
   Du JX, 2016, NEUROCOMPUTING, V188, P131, DOI 10.1016/j.neucom.2014.10.113.
   Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57.
   Fan ZZ, 2015, NEUROCOMPUTING, V151, P304, DOI 10.1016/j.neucom.2014.09.035.
   Grinblat GL, 2016, COMPUT ELECTRON AGR, V127, P418, DOI 10.1016/j.compag.2016.07.003.
   Guo S, 2012, INT C PATT RECOG, P1241.
   Hati S, 2013, INT J COMPUTER APPL, V62, P15, DOI {[}10.5120/10172-4897, DOI 10.5120/10172-4897].
   Hu RX, 2012, IEEE T IMAGE PROCESS, V21, P4667, DOI 10.1109/TIP.2012.2207391.
   Jou-Ken Hsiao, 2014, 2014 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-TW), P209, DOI 10.1109/ICCE-TW.2014.6904061.
   Kadir A, 2011, INT J COMPUTER TREND, V2231-2803, P224.
   Kumar S., 2012, INDIAN J COMPUTER SC, V3, P436.
   Li LY, 2014, IMAGE VISION COMPUT, V32, P814, DOI 10.1016/j.imavis.2014.02.007.
   Li S, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2155.
   Liu NA, 2016, NEUROCOMPUTING, V216, P460, DOI 10.1016/j.neucom.2016.08.005.
   Lu CY, 2013, J VIS COMMUN IMAGE R, V24, P111, DOI 10.1016/j.jvcir.2012.05.003.
   Mokrzycki W, 2012, LECT NOTES COMPUT SC, V7594, P533, DOI 10.1007/978-3-642-33564-8\_64.
   Salleh SS, 2012, IJCSI INT J COMPUTER, V9, P124.
   Trishen M, 2015, PROCEDIA COMPUTER SC, V58, P740.
   Xu Y, 2013, INFORM SCIENCES, V238, P138, DOI 10.1016/j.ins.2013.02.051.
   Yang S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0116500.
   Zhang SW, 2013, PATTERN RECOGN, V46, P1891, DOI 10.1016/j.patcog.2013.01.015.
   Zhang Z, 2017, IEEE T IND INFORM, V13, P644, DOI 10.1109/TII.2017.2653184.
   Zhao ZQ, 2016, PATTERN RECOGN, V56, P77, DOI 10.1016/j.patcog.2016.02.016.
   Zhao ZQ, 2015, NEUROCOMPUTING, V151, P1112, DOI 10.1016/j.neucom.2014.02.077.
   Zhao ZQ, 2012, IEEE T IMAGE PROCESS, V21, P4218, DOI 10.1109/TIP.2012.2197631.},
Number-of-Cited-References = {26},
Times-Cited = {2},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {10},
Journal-ISO = {PLoS One},
Doc-Delivery-Number = {EX0AO},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000402880700029},
OA = {Green Published, gold, Green Submitted},
DA = {2023-08-12},
}

@article{ WOS:000436456300008,
Author = {Lottes, Philipp and Behley, Jens and Milioto, Andres and Stachniss,
   Cyrill},
Title = {Fully Convolutional Networks With Sequential Information for Robust Crop
   and Weed Detection in Precision Farming},
Journal = {IEEE ROBOTICS AND AUTOMATION LETTERS},
Year = {2018},
Volume = {3},
Number = {4},
Pages = {2870-2877},
Month = {OCT},
Abstract = {Reducing the use of agrochemicals is an important component toward
   sustainable agriculture. Robots that can perform targeted weed control
   offer the potential to contribute to this goal, for example, through
   specialized weeding actions such as selective spraying or mechanical
   weed removal. A prerequisite of such systems is a reliable and robust
   plant classification system that is able to distinguish crop and weed in
   the field. A major challenge in this context is the fact that different
   fields show a large variability. Thus, classification systems have to
   robustly cope with substantial environmental changes with respect to
   weed pressure and weed types, growth stages of the crop, visual
   appearance, and soil conditions. In this letter, we propose a novel
   crop-weed classification system that relies on a fully convolutional
   network with an encoder-decoder structure and incorporates spatial
   information by considering image sequences. Exploiting the crop
   arrangement information that is observable from the image sequences
   enables our system to robustly estimate a pixel-wise labeling of the
   images into crop and weed, i.e., a semantic segmentation. We provide a
   thorough experimental evaluation, which shows that our system
   generalizes well to previously unseen fields under varying environmental
   conditions-a key capability to actually use such systems in precision
   framing. We provide comparisons to other state-of-the-art approaches and
   show that our system substantially improves the accuracy of crop-weed
   classification without requiring a retraining of the model.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Lottes, P (Corresponding Author), Univ Bonn, Inst Geodesy \& Geoinformat, D-53113 Bonn, Germany.
   Lottes, Philipp; Behley, Jens; Milioto, Andres; Stachniss, Cyrill, Univ Bonn, Inst Geodesy \& Geoinformat, D-53113 Bonn, Germany.},
DOI = {10.1109/LRA.2018.2846289},
ISSN = {2377-3766},
Keywords = {Deep learning in robotics and automation; robotics in agriculture and
   forestry},
Keywords-Plus = {NEURAL-NETWORKS; CLASSIFICATION},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {philipp.lottes@igg.uni-bonn.de
   jens.behley@igg.uni-bonn.de
   andres.milioto@igg.uni-bonn.de
   cyrill.@stachnissigg.uni-bonn.de},
Affiliations = {University of Bonn},
ResearcherID-Numbers = {Stachniss, Cyrill/AAH-3034-2019
   },
ORCID-Numbers = {Behley, Jens/0000-0001-6483-0319
   Milioto, Andres/0000-0002-5716-3279
   Stachniss, Cyrill/0000-0003-1173-6972},
Funding-Acknowledgement = {EC {[}H2020-ICT-644227-Flourish]},
Funding-Text = {This work was supported in part by the EC under Grant
   H2020-ICT-644227-Flourish.},
Cited-References = {{[}Anonymous], 2018, GUIDE CONVOLUTION AR.
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615.
   Chebrolu N, 2017, INT J ROBOT RES, V36, P1045, DOI 10.1177/0278364917720510.
   Di Cicco M, 2017, IEEE INT C INT ROBOT, P5188, DOI 10.1109/IROS.2017.8206408.
   Hall D., 2017, P IEEE INT C ROB AUT, P5174.
   Hall D, 2017, IEEE INT C INT ROBOT, P5174, DOI 10.1109/IROS.2017.8206406.
   Haug S, 2014, IEEE WINT CONF APPL, P1142, DOI 10.1109/WACV.2014.6835733.
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123.
   Huang G., 2017, P 2017 IEEE C COMP V, P4700, DOI {[}DOI 10.1109/CVPR.2017.243, 10.1109/CVPR.2017.243].
   Jegou S, 2017, IEEE COMPUT SOC CONF, P1175, DOI 10.1109/CVPRW.2017.156.
   Langsenkamp F., 2014, P INT C AGR ENG, P16.
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965.
   Lottes P., 2017, 2017 IEEE INT C ROB, P3024, DOI DOI 10.1109/ICRA.2017.7989347.
   Lottes P, 2017, IEEE INT C INT ROBOT, P5155, DOI 10.1109/IROS.2017.8206403.
   Lottes P, 2017, J FIELD ROBOT, V34, P1160, DOI 10.1002/rob.21675.
   McCool C, 2017, IEEE ROBOT AUTOM LET, V2, P1344, DOI 10.1109/LRA.2017.2667039.
   Milioto A, 2018, IEEE INT CONF ROBOT, P2229.
   Milioto A, 2017, ISPRS ANN PHOTO REM, V4-2, P41, DOI 10.5194/isprs-annals-IV-2-W3-41-2017.
   Mortensen A. K., 2016, P INT C AGR ENG.
   Muter M., 2013, P INT C AGR ENG.
   Nieuwenhuizen A.T, 2009, THESIS.
   Paszke A., 2016, ARXIV160602147.
   Potena C, 2017, ADV INTELL SYST COMP, V531, P105, DOI 10.1007/978-3-319-48036-7\_9.
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4\_28.
   Sa I, 2018, IEEE ROBOT AUTOM LET, V3, P588, DOI 10.1109/LRA.2017.2774979.
   Slaughter DC, 2008, COMPUT ELECTRON AGR, V61, P63, DOI 10.1016/j.compag.2007.05.008.
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929.
   Szegedy C., 2015, P IEEE C COMP VIS PA.
   Wendel A, 2016, IEEE INT CONF ROBOT, P5128, DOI 10.1109/ICRA.2016.7487717.},
Number-of-Cited-References = {29},
Times-Cited = {108},
Usage-Count-Last-180-days = {10},
Usage-Count-Since-2013 = {86},
Journal-ISO = {IEEE Robot. Autom. Lett.},
Doc-Delivery-Number = {GK8GI},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000436456300008},
OA = {Green Submitted},
DA = {2023-08-12},
}

@article{ WOS:000445199900009,
Author = {Leibman-Markus, Meirav and Pizarro, Lorena and Schuster, Silvia and Lin,
   Z. J. Daniel and Gershony, Ofir and Bar, Maya and Coaker, Gitta and
   Avni, Adi},
Title = {The intracellular nucleotide-binding leucine-rich repeat receptor
   (SlNRC4a) enhances immune signalling elicited by extracellular
   perception},
Journal = {PLANT CELL AND ENVIRONMENT},
Year = {2018},
Volume = {41},
Number = {10},
Pages = {2313-2327},
Month = {OCT},
Abstract = {Plant recognition and defence against pathogens employs a two-tiered
   perception system. Surface-localized pattern recognition receptors
   (PRRs) act to recognize microbial features, whereas intracellular
   nucleotide-binding leucine-rich repeat receptors (NLRs) directly or
   indirectly recognize pathogen effectors inside host cells. Employing the
   tomato PRR LeEIX2/EIX model system, we explored the molecular mechanism
   of signalling pathways. We identified an NLR that can associate with
   LeEIX2, termed SlNRC4a (NB-LRR required for hypersensitive
   response-associated cell death-4). Co-immunoprecipitation demonstrates
   that SlNRC4a is able to associate with different PRRs. Physiological
   assays with specific elicitors revealed that SlNRC4a generally alters
   PRR-mediated responses. SlNRC4a overexpression enhances defence
   responses, whereas silencing SlNRC4 reduces plant immunity. Moreover,
   the coiled-coil domain of SlNRC4a is able to associate with LeEIX2 and
   is sufficient to enhance responses upon EIX perception. On the basis of
   these findings, we propose that SlNRC4a acts as a noncanonical positive
   regulator of immunity mediated by diverse PRRs. Thus, SlNRC4a could link
   both intracellular and extracellular immune perceptions.},
Publisher = {WILEY},
Address = {111 RIVER ST, HOBOKEN 07030-5774, NJ USA},
Type = {Article},
Language = {English},
Affiliation = {Avni, A (Corresponding Author), Tel Aviv Univ, Sch Plant Sci \& Food Secur, Tel Aviv, Israel.
   Leibman-Markus, Meirav; Pizarro, Lorena; Schuster, Silvia; Avni, Adi, Tel Aviv Univ, Sch Plant Sci \& Food Secur, Tel Aviv, Israel.
   Lin, Z. J. Daniel; Coaker, Gitta, Univ Calif Davis, Dept Plant Pathol, Davis, CA 95616 USA.
   Gershony, Ofir; Bar, Maya, ARO, Volcani Ctr, Dept Plant Pathol \& Weed Res, Rishon Leziyyon, Israel.
   Avni, Adi, Donald Danforth Plant Sci Ctr, St Louis, MO USA.},
DOI = {10.1111/pce.13347},
ISSN = {0140-7791},
EISSN = {1365-3040},
Keywords = {EIX; endocytosis; immune receptors; LeEIX2; NB-LRR; NLR; pattern
   triggered immunity; SlNRC4},
Keywords-Plus = {INTROGRESSION LINE POPULATION; ETHYLENE-INDUCING XYLANASE; NB-LRR
   PROTEIN; CELL-DEATH; DISEASE RESISTANCE; NICOTIANA-TABACUM; PLANT
   IMMUNITY; NLR PROTEINS; ARABIDOPSIS-THALIANA; FLAGELLIN PERCEPTION},
Research-Areas = {Plant Sciences},
Web-of-Science-Categories  = {Plant Sciences},
Author-Email = {lpavni@post.tau.ac.il},
Affiliations = {Tel Aviv University; University of California System; University of
   California Davis; VOLCANI INSTITUTE OF AGRICULTURAL RESEARCH; Donald
   Danforth Plant Science Center},
ResearcherID-Numbers = {Avni, Adi/GQP-2781-2022
   Pizarro, Lorena/ADY-9319-2022
   Avni, Adi/R-9048-2017
   },
ORCID-Numbers = {Bar, Maya/0000-0002-7823-9121
   Avni, Adi/0000-0003-2092-9768
   Pizarro, Lorena/0000-0001-5954-5839},
Funding-Acknowledgement = {Israel Ministry of Agriculture and Rural Development {[}13-37-0001];
   United States-Israel Binational Science Foundation {[}2013227]; United
   States-Israel Binational Agriculture Research and Development Fund
   {[}IS-4842-15 R]},
Funding-Text = {Chief Scientist of the Israel Ministry of Agriculture and Rural
   Development, Grant/Award Number: 13-37-0001; United States-Israel
   Binational Science Foundation, Grant/Award Number: 2013227; United
   States-Israel Binational Agriculture Research and Development Fund,
   Grant/Award Number: IS-4842-15 R},
Cited-References = {Andolfo G, 2014, BMC PLANT BIOL, V14, DOI 10.1186/1471-2229-14-120.
   {[}Anonymous], 2012, COLD SPRING HARB SYM.
   AVNI A, 1994, PLANT PHYSIOL, V106, P1049, DOI 10.1104/pp.106.3.1049.
   BAILEY BA, 1990, PLANT PHYSIOL, V94, P1849, DOI 10.1104/pp.94.4.1849.
   Bar M, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0007973.
   Bar M, 2009, PLANT J, V59, P600, DOI 10.1111/j.1365-313X.2009.03897.x.
   Bernoux M, 2011, CELL HOST MICROBE, V9, P200, DOI 10.1016/j.chom.2011.02.009.
   Bohm H, 2014, CURR OPIN PLANT BIOL, V20, P47, DOI 10.1016/j.pbi.2014.04.007.
   Bonardi V, 2012, FRONT PLANT SCI, V3, DOI 10.3389/fpls.2012.00237.
   Bonardi V, 2012, CURR OPIN IMMUNOL, V24, P41, DOI 10.1016/j.coi.2011.12.006.
   Caplan J, 2008, CELL HOST MICROBE, V3, P126, DOI 10.1016/j.chom.2008.02.010.
   Casteel CL, 2006, ENTOMOL EXP APPL, V121, P67, DOI 10.1111/j.1570-8703.2006.00458.x.
   Cesari S, 2016, P NATL ACAD SCI USA, V113, P10204, DOI 10.1073/pnas.1605483113.
   Cesari S, 2014, FRONT PLANT SCI, V5, DOI 10.3389/fpls.2014.00606.
   Chinchilla D, 2006, PLANT CELL, V18, P465, DOI 10.1105/tpc.105.036574.
   Chou KC, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0011335.
   Collier SM, 2011, MOL PLANT MICROBE IN, V24, P918, DOI 10.1094/MPMI-03-11-0050.
   Couto D, 2016, NAT REV IMMUNOL, V16, P537, DOI 10.1038/nri.2016.77.
   Cui HT, 2015, ANNU REV PLANT BIOL, V66, P487, DOI 10.1146/annurev-arplant-050213-040012.
   DeMeyer G, 1997, PHYTOPATHOLOGY, V87, P588, DOI 10.1094/PHYTO.1997.87.6.588.
   Dereeper A, 2008, NUCLEIC ACIDS RES, V36, pW465, DOI 10.1093/nar/gkn180.
   Dodds PN, 2010, NAT REV GENET, V11, P539, DOI 10.1038/nrg2812.
   ELAD Y, 1993, PHYTOPARASITICA, V21, P257, DOI 10.1007/BF02980947.
   ESHED Y, 1995, GENETICS, V141, P1147.
   Fernandez-Pozo N, 2015, NUCLEIC ACIDS RES, V43, pD1036, DOI 10.1093/nar/gku1195.
   Gabriels SHEJ, 2007, PLANT J, V50, P14, DOI 10.1111/j.1365-313X.2007.03027.x.
   Gomez-Gomez L, 2000, MOL CELL, V5, P1003, DOI 10.1016/S1097-2765(00)80265-8.
   Gust AA, 2014, CURR OPIN PLANT BIOL, V21, P104, DOI 10.1016/j.pbi.2014.07.007.
   Hanania U, 1997, PLANT J, V12, P113, DOI 10.1046/j.1365-313X.1997.12010113.x.
   Hao W, 2013, J BIOL CHEM, V288, P35868, DOI 10.1074/jbc.M113.517417.
   Henry E, 2013, NEW PHYTOL, V199, P908, DOI 10.1111/nph.12214.
   Kawchuk LM, 2001, P NATL ACAD SCI USA, V98, P6511, DOI 10.1073/pnas.091114198.
   Lapidot M, 2015, PLOS GENET, V11, DOI 10.1371/journal.pgen.1005538.
   Leibman-Markus M, 2017, METHODS MOL BIOL, V1578, P167, DOI 10.1007/978-1-4939-6859-6\_13.
   Liebrand TWH, 2013, P NATL ACAD SCI USA, V110, P10010, DOI 10.1073/pnas.1220015110.
   Liu J, 2011, CELL HOST MICROBE, V9, P137, DOI 10.1016/j.chom.2011.01.010.
   Liu YL, 2002, PLANT J, V31, P777, DOI 10.1046/j.1365-313X.2002.01394.x.
   Macho AP, 2014, MOL CELL, V54, P263, DOI 10.1016/j.molcel.2014.03.028.
   Maekawa T, 2011, CELL HOST MICROBE, V9, P187, DOI 10.1016/j.chom.2011.02.008.
   Mantelin S, 2011, PLANT J, V67, P459, DOI 10.1111/j.1365-313X.2011.04609.x.
   Marchler-Bauer A, 2017, NUCLEIC ACIDS RES, V45, pD200, DOI 10.1093/nar/gkw1129.
   Marone D, 2013, INT J MOL SCI, V14, P7302, DOI 10.3390/ijms14047302.
   MCCORMICK S, 1986, PLANT CELL REP, V5, P81, DOI 10.1007/BF00269239.
   Mcdowell JM, 2006, MOL PLANT PATHOL, V7, P437, DOI 10.1111/j.1364-3703.2006.00342.x.
   Milligan SB, 1998, PLANT CELL, V10, P1307, DOI 10.1105/tpc.10.8.1307.
   Nandety RS, 2013, PLANT PHYSIOL, V162, P1459, DOI 10.1104/pp.113.219162.
   Nishimura MT, 2017, P NATL ACAD SCI USA, V114, pE2053, DOI 10.1073/pnas.1620973114.
   NITSCH JP, 1969, SCIENCE, V163, P85, DOI 10.1126/science.163.3862.85.
   Nombela G, 2003, MOL PLANT MICROBE IN, V16, P645, DOI 10.1094/MPMI.2003.16.7.645.
   Rairdan GJ, 2008, PLANT CELL, V20, P739, DOI 10.1105/tpc.107.056036.
   Ron M, 2004, PLANT CELL, V16, P1604, DOI 10.1105/tpc.022475.
   Ron M., 2004, TOMATO LEEIX GENES I.
   Schindelin J, 2012, NAT METHODS, V9, P676, DOI {[}10.1038/NMETH.2019, 10.1038/nmeth.2019].
   Schlecht I, 1999, EUR J RADIOL, V32, P208, DOI 10.1016/S0720-048X(99)00036-4.
   Sharfman M, 2011, PLANT J, V68, P413, DOI 10.1111/j.1365-313X.2011.04696.x.
   Steinhauser MC, 2011, PLANT PHYSIOL, V157, P998, DOI 10.1104/pp.111.181594.
   Strange RN, 2005, ANNU REV PHYTOPATHOL, V43, P83, DOI 10.1146/annurev.phyto.43.113004.133839.
   Takken FLW, 1999, PLANT J, V20, P279, DOI 10.1046/j.1365-313X.1999.t01-1-00601.x.
   Thomma BPHJ, 2016, CURR OPIN MICROBIOL, V32, pV, DOI 10.1016/j.mib.2016.07.001.
   Thomma BPHJ, 2011, PLANT CELL, V23, P4, DOI 10.1105/tpc.110.082602.
   Tor M, 2009, J EXP BOT, V60, P3645, DOI 10.1093/jxb/erp233.
   Toruno TY, 2016, ANNU REV PHYTOPATHOL, V54, P419, DOI 10.1146/annurev-phyto-080615-100204.
   van der Hoorn RAL, 2005, PLANT CELL, V17, P1000, DOI 10.1105/tpc.104.028118.
   van Ooijen G, 2007, ANNU REV PHYTOPATHOL, V45, P43, DOI 10.1146/annurev.phyto.45.062806.094430.
   VANENGELEN FA, 1995, TRANSGENIC RES, V4, P288, DOI 10.1007/BF01969123.
   Wang GF, 2015, PLOS PATHOG, V11, DOI 10.1371/journal.ppat.1004674.
   Wang WM, 2007, MOL PLANT MICROBE IN, V20, P966, DOI 10.1094/MPMI-20-8-0966.
   Wu CH, 2017, P NATL ACAD SCI USA, V114, P8113, DOI 10.1073/pnas.1702041114.
   Wu CH, 2016, NEW PHYTOL, V209, P1344, DOI 10.1111/nph.13764.
   Xiao SY, 2001, SCIENCE, V291, P118, DOI 10.1126/science.291.5501.118.
   Xie KB, 2015, P NATL ACAD SCI USA, V112, P3570, DOI 10.1073/pnas.1420294112.
   Yachdav G, 2014, NUCLEIC ACIDS RES, V42, pW337, DOI 10.1093/nar/gku366.
   Yu JY, 2014, BMC GENOMICS, V15, DOI {[}10.1186/1471-2164-15-3, 10.1186/1471-2199-15-20].
   Zhang XX, 2017, ANNU REV PHYTOPATHOL, V55, P205, DOI 10.1146/annurev-phyto-080516-035250.
   Zipfel C, 2004, NATURE, V428, P764, DOI 10.1038/nature02485.
   Zipfel C, 2014, TRENDS IMMUNOL, V35, P345, DOI 10.1016/j.it.2014.05.004.},
Number-of-Cited-References = {76},
Times-Cited = {26},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {32},
Journal-ISO = {Plant Cell Environ.},
Doc-Delivery-Number = {GU3SL},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000445199900009},
OA = {Green Accepted},
DA = {2023-08-12},
}

@article{ WOS:000326767300004,
Author = {Pant, Paras and Heikkinen, Ville and Hovi, Aarne and Korpela, Ilkka and
   Hauta-Kasari, Markku and Tokola, Timo},
Title = {Evaluation of simulated bands in airborne optical sensors for tree
   species identification},
Journal = {REMOTE SENSING OF ENVIRONMENT},
Year = {2013},
Volume = {138},
Pages = {27-37},
Month = {NOV},
Abstract = {Airborne multispectral remote sensing devices have been used in
   automatic identification of tree species, and the spatial and spectral
   properties of the sensors affect the remote sensing measurement results.
   Previous work based on a simulation model with ground-level measured
   reflectance data of pine (Pinus sylvestris L.), spruce (Picea abies (L.)
   H. Karst.), and birch (Betula pubescens Ehrh. and Betula pendula Roth)
   tree species and idealized Leica ADS80 sensitivities suggested that the
   addition of a fifth sensitivity band in the red edge wavelength region
   to the existing Leica ADS80 system significantly improves the
   classification performance. In this paper, we extend this analysis using
   a simulated model with accurate spectral sensitivity information and
   airborne AisaEAGLE II hyperspectral data for these three tree species.
   We simulated multispectral responses using spectral sensitivity
   characteristics of the Leica ADS40, the Vexcel UltraCam-D, the
   Intergraph-Z/I Digital mapping camera and the Leica ADS40 system with an
   added band in the 691-785 nm region. We evaluated the tree species
   classification performance of these simulated responses using
   Discriminant Analysis and Support Vector Machine classifiers. The
   classification experiment result showed that the simulated responses of
   the 5-band multispectral system yielded the most robust classification
   performance with approximately 98\% accuracy. This result was similar to
   the accuracy obtained with the hyperspectral data. Although differences
   were observed in the sensitivity functions of the 4-band systems, there
   were no large differences observed in the classification performances
   between them. With the simulated 5-band system, there was an increase of
   5-13\% points in classification accuracy when compared to the accuracies
   of the 4-band systems. The results obtained via proposed 5-band system
   support results from previous studies suggesting that there is a need
   for a sensitivity band in the red edge wavelength region for
   applications in tree species classification. (C) 2013 Elsevier Inc. All
   rights reserved.},
Publisher = {ELSEVIER SCIENCE INC},
Address = {STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA},
Type = {Article},
Language = {English},
Affiliation = {Pant, P (Corresponding Author), Univ Eastern Finland, Sch Comp, Joensuu Campus,POB 111, Joensuu 80101, Finland.
   Pant, Paras; Heikkinen, Ville; Hauta-Kasari, Markku, Univ Eastern Finland, Sch Comp, Joensuu 80101, Finland.
   Hovi, Aarne; Korpela, Ilkka, Univ Helsinki, Dept Forest Sci, FIN-00014 Helsinki, Finland.
   Tokola, Timo, Univ Eastern Finland, Sch Forest Sci, Joensuu 80101, Finland.},
DOI = {10.1016/j.rse.2013.07.016},
ISSN = {0034-4257},
EISSN = {1879-0704},
Keywords = {Airborne multispectral sensors; Sensor sensitivity; Feature extraction;
   Pattern classification; Tree classification},
Keywords-Plus = {IMAGING SPECTROMETER; CLASSIFICATION; LIDAR; REFLECTANCE; NORMALIZATION;
   IMAGERY; FUSION; CASI; LEAF},
Research-Areas = {Environmental Sciences \& Ecology; Remote Sensing; Imaging Science \&
   Photographic Technology},
Web-of-Science-Categories  = {Environmental Sciences; Remote Sensing; Imaging Science \& Photographic
   Technology},
Author-Email = {paras.pant@uef.fi},
Affiliations = {University of Eastern Finland; University of Helsinki; University of
   Eastern Finland},
ResearcherID-Numbers = {Tokola, Timo E/D-2096-2010
   },
ORCID-Numbers = {Tokola, Timo/0000-0001-5269-5308
   Hovi, Aarne/0000-0002-4384-5279},
Funding-Acknowledgement = {University of Eastern Finland {[}931043]; Academy of Finland {[}256155];
   University of Helsinki; Academy of Finland (AKA) {[}256155, 256155]
   Funding Source: Academy of Finland (AKA)},
Funding-Text = {This work was supported by the University of Eastern Finland (project
   no. 931043 Multi-scale Geospatial Analysis), the Academy of Finland
   (project no. 256155) and the University of Helsinki. The authors thank
   the project leader of Multi-scale Geospatial Analysis project, Prof.
   MattiMaltamo, School of Forest Sciences, University of Eastern Finland,
   Joensuu. The authors thank TuureTakala of the Dept. of Geography,
   University of Helsinki, for providing the measurement details. The
   authors also thank Susanne Scholz (Microsoft Photogrammetry,
   Anzengrubergasse 8/4, A-8010 Graz) for providing the sensitivity
   information for the Vexcel UltraCam-D.},
Cited-References = {Anger C.D., 1994, P 1 INT AIRB REM SEN, VII, P205.
   {[}Anonymous], 2002, LEARNING KERNELS SUP.
   Becker BL, 2007, REMOTE SENS ENVIRON, V108, P111, DOI 10.1016/j.rse.2006.11.005.
   Beisl U., 2006, P C ISPRS COMM TECHN, P14.
   Bishop C.M., 2006, PATTERN RECOGN, V128.
   Bunting P, 2006, REMOTE SENS ENVIRON, V101, P230, DOI 10.1016/j.rse.2005.12.015.
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199.
   Chang CI, 2003, HYPERSPECTRAL IMAGIN.
   Clark ML, 2005, REMOTE SENS ENVIRON, V96, P375, DOI 10.1016/j.rse.2005.03.009.
   Cocks T, 1998, 1ST EARSEL WORKSHOP ON IMAGING SPECTROSCOPY, P37.
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104.
   Cramer M., 2011, GEOMETRY PERFECT RAD, P65.
   CRIPPEN RE, 1990, REMOTE SENS ENVIRON, V34, P71, DOI 10.1016/0034-4257(90)90085-Z.
   Dalponte M, 2008, IEEE T GEOSCI REMOTE, V46, P1416, DOI 10.1109/TGRS.2008.916480.
   Dalponte M, 2012, REMOTE SENS ENVIRON, V123, P258, DOI 10.1016/j.rse.2012.03.013.
   Dalponte M, 2009, REMOTE SENS ENVIRON, V113, P2345, DOI 10.1016/j.rse.2009.06.013.
   FILELLA I, 1994, INT J REMOTE SENS, V15, P1459, DOI 10.1080/01431169408954177.
   Green K, 2011, PHOTOGRAMM ENG REM S, V77, P589, DOI 10.14358/PERS.77.6.589.
   Green RO, 1998, REMOTE SENS ENVIRON, V65, P227, DOI 10.1016/S0034-4257(98)00064-9.
   Hamada Y, 2007, REMOTE SENS ENVIRON, V109, P237, DOI 10.1016/j.rse.2007.01.003.
   Heikkinen V, 2011, IEEE T GEOSCI REMOTE, V49, P4539, DOI 10.1109/TGRS.2011.2141143.
   Heikkinen V, 2010, IEEE T GEOSCI REMOTE, V48, P1355, DOI 10.1109/TGRS.2009.2032239.
   Hill RA, 2010, APPL VEG SCI, V13, P86, DOI 10.1111/j.1654-109X.2009.01053.x.
   Holmgren J, 2008, INT J REMOTE SENS, V29, P1537, DOI 10.1080/01431160701736471.
   Honkavaara E., 2011, RADIOMETRIC ASPECTS.
   Honkavaara E., 2007, PHOTOGRAMMETRIC WEEK, P117.
   JAASKELAINEN T, 1994, APPL OPTICS, V33, P2356, DOI 10.1364/AO.33.002356.
   Korpela I., 2004, MONOGRAPHS FINNISH S, V3.
   Korpela I., 2010, P ISPRS TC 7 S 100 Y, P342.
   Korpela I, 2011, REMOTE SENS ENVIRON, V115, P2062, DOI 10.1016/j.rse.2011.04.008.
   Korpela I, 2010, SILVA FENN, V44, P319, DOI 10.14214/sf.156.
   Kropfl M., 2006, TECHNICAL REPORT.
   Latifi H, 2012, REMOTE SENS ENVIRON, V121, P10, DOI 10.1016/j.rse.2012.01.015.
   Lucas R, 2008, REMOTE SENS ENVIRON, V112, P2088, DOI 10.1016/j.rse.2007.10.011.
   MAKISARA K, 1993, INT GEOSCI REMOTE SE, P479, DOI 10.1109/IGARSS.1993.322291.
   Markelin L, 2010, INT ARCH PHOTOGRAMM, V38, P145.
   Packalen P, 2009, PHOTOGRAMM ENG REM S, V75, P1451, DOI 10.14358/PERS.75.12.1451.
   Rayn R., 2009, P PHOT WEEK, P81.
   Richardson AD, 2002, NEW PHYTOL, V153, P185, DOI 10.1046/j.0028-646X.2001.00289.x.
   Schlapfer D, 1998, P SOC PHOTO-OPT INS, V3438, P334, DOI 10.1117/12.328114.
   Schowengerdt RA, 2007, REMOTE SENSING: MODELS AND METHODS FOR IMAGE PROCESSING, 3RD EDITION, P1.
   Sims DA, 2002, REMOTE SENS ENVIRON, V81, P337, DOI 10.1016/S0034-4257(02)00010-X.
   SPECIM, 2012, TECHNICAL REPORT.
   Tsai F, 2002, IEEE T GEOSCI REMOTE, V40, P416, DOI 10.1109/36.992805.
   Waser LT, 2010, PHOTOGRAMM FERNERKUN, P141, DOI 10.1127/1432-8364/2010/0046.
   Yuan D, 1996, ISPRS J PHOTOGRAMM, V51, P117, DOI 10.1016/0924-2716(96)00018-4.},
Number-of-Cited-References = {46},
Times-Cited = {21},
Usage-Count-Last-180-days = {3},
Usage-Count-Since-2013 = {67},
Journal-ISO = {Remote Sens. Environ.},
Doc-Delivery-Number = {249HC},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000326767300004},
DA = {2023-08-12},
}

@inproceedings{ WOS:000226030400150,
Author = {Qi, HN and Yang, JG and Lin, J},
Editor = {Arabnia, HR and Mun, Y},
Title = {Sawtooth identification and counting of leaf edge based on SVM},
Booktitle = {IC-AI `04 \& MLMTA'04 , VOL 1 AND 2, PROCEEDINGS},
Year = {2004},
Pages = {990-995},
Note = {International Conference on Artificial Intelligence/International
   Conference on Machine Learning, Models, Technologies and Applications,
   Las Vegas, NV, JUN 21-24, 2004},
Organization = {Comp Sci Res, Educ, \& Applicat Press; Int Technol Inst; Korean Soc
   Internet Informat; World Acad Sci Informat Technol},
Abstract = {The focus of Computer-Aided Plant-Identification (CAPI) is the stable
   features extraction of plant. Sawtooth number of leaf edge is such an
   important feature for some species of plants. It is difficult to depict
   sawteeth shapes in rigid mathematic methods. However, a trained support
   vector machine (SVM) with good adaptability can be applied to classify
   sawtooth and nonsawtooth samples. According to the principle of SVM and
   the characteristics of the samples, a linear kernel is chosen here for
   the SVM. The samples can be obtained by a circular sample window sliding
   along the edge of the leaf and then be rotated to a standard pose for
   decreasing the complexity of identification. By avoiding repeated
   sampling and counting of the same sawtooth, the algorithm presented in
   the paper accomplishes automatic counting of the sawtooth number. The
   results of the experiment show that the SVM-based method works well. For
   the equivalent of SVM and the three-layer feedforward neural network
   three-layer BP net can also be used for the task of sawtooth
   identification. In addition the elementary experiment shows that
   skeletonization method is another good scheme for counting the number of
   sawtooth.},
Publisher = {C S R E A PRESS},
Address = {115 AVALON DR, ATHENS, GA 30606 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Qi, HN (Corresponding Author), Zhejiang Univ, Inst Artificial Intelligence, Hangzhou, Peoples R China.
   Zhejiang Univ, Inst Artificial Intelligence, Hangzhou, Peoples R China.},
ISBN = {1-932415-33-5},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence},
Author-Email = {qihengnian@zju.edu.cn
   yangjg@zju.edu.cn
   auberlin@hotmail.com},
Affiliations = {Zhejiang University},
Cited-References = {Byun H, 2002, LECT NOTES COMPUT SC, V2388, P213.
   Hu RenYong, 2001, Journal of Zhejiang University (Agriculture and Life Sciences), V27, P419.
   HYERAN B, 2002, LNCS, V2388, P213.
   {[}祁亨年 Qi Hengnian], 2003, {[}浙江林学院学报, Journal of Zhejiang Forestry College], V20, P281.
   Scholkopf B., 2000, STAT LEARNING KERNEL.
   Sebe N, 2002, LECT NOTES COMPUT SC, V2383, P17.
   Vellido A, 1999, EXPERT SYST APPL, V17, P51, DOI 10.1016/S0957-4174(99)00016-0.
   XIAO JH, 2002, J WUYI U NATURE SCI, V16, P6.
   {[}余学军 Yu Xuejun], 2002, {[}中国图象图形学报. A, Journal of image and graphics], V7, P272.
   Zhang L, 2002, J COMPUT SCI TECH-CH, V17, P549, DOI 10.1007/BF02948823.
   Zhang XX, 2002, ADV WATER RESOUR, V25, P1, DOI 10.1016/S0309-1708(01)00047-1.
   ZHUANG YT, 2002, WEBBASED MULTIMEDIA, P38.},
Number-of-Cited-References = {12},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BBL81},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000226030400150},
DA = {2023-08-12},
}

@article{ WOS:000305863300084,
Author = {Guerrero, J. M. and Pajares, G. and Montalvo, M. and Romeo, J. and
   Guijarro, M.},
Title = {Support Vector Machines for crop/weeds identification in maize fields},
Journal = {EXPERT SYSTEMS WITH APPLICATIONS},
Year = {2012},
Volume = {39},
Number = {12},
Pages = {11149-11155},
Month = {SEP 15},
Abstract = {In Precision Agriculture (PA) automatic image segmentation for plant
   identification is an important issue to be addressed. Emerging
   technologies in optical imaging sensors play an important role in PA. In
   maize fields, site-specific treatments, with chemical products or
   mechanical manipulations, are applied for weeds elimination. Maize is an
   irrigated crop, also unprotected from rainfall. After a strong rain,
   soil materials (particularly clays) mixed with water impregnate the
   vegetative cover. The green spectral component associated to the plants
   is masked by the dominant red spectral component coming from soil
   materials. This makes methods based on the greenness identification fail
   under such situations. We propose a new method based on Support Vector
   Machines for identifying plants with green spectral components masked
   and unmasked. The method is also valid for post-treatment evaluation,
   where loss of greenness in weeds is identified with the effectiveness of
   the treatment and in crops with damage or masking. The performance of
   the method allows to verify its viability for automatic tasks in
   agriculture based on image processing. (C) 2012 Elsevier Ltd. All rights
   reserved.},
Publisher = {PERGAMON-ELSEVIER SCIENCE LTD},
Address = {THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Guerrero, JM (Corresponding Author), Univ Complutense Madrid, Fac Informat, Dpto Ingn Software \& Inteligencia Artificial, E-28040 Madrid, Spain.
   Guerrero, J. M.; Pajares, G.; Romeo, J.; Guijarro, M., Univ Complutense Madrid, Fac Informat, Dpto Ingn Software \& Inteligencia Artificial, E-28040 Madrid, Spain.
   Montalvo, M., Univ Complutense Madrid, Fac Informat, Dpt Arquitectura Computadores \& Automat, E-28040 Madrid, Spain.},
DOI = {10.1016/j.eswa.2012.03.040},
ISSN = {0957-4174},
EISSN = {1873-6793},
Keywords = {Support Vector Machines; Image segmentation; Weeds/crop discrimination;
   Precision Agriculture},
Keywords-Plus = {ENVIRONMENTALLY ADAPTIVE SEGMENTATION; DIGITAL IMAGES; COLOR; ALGORITHM;
   FEATURES; PLANT},
Research-Areas = {Computer Science; Engineering; Operations Research \& Management Science},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic; Operations Research \& Management Science},
Author-Email = {jmguerre@fdi.ucm.es
   pajares@fdi.ucm.es},
Affiliations = {Complutense University of Madrid; Complutense University of Madrid},
ResearcherID-Numbers = {Guerrero, Josep M./D-5519-2014
   Guijarro, Maria/K-5026-2014
   Pajares, Gonzalo/C-1404-2017
   Guerrero, Josep M./Y-2929-2019
   Guerrero, José Miguel/U-3621-2017
   },
ORCID-Numbers = {Guerrero, Josep M./0000-0001-5236-4592
   Guijarro, Maria/0000-0002-2966-9512
   Pajares, Gonzalo/0000-0003-0915-6282
   Guerrero, José Miguel/0000-0003-2521-514X
   Montalvo Martinez, Martin/0000-0003-2801-2372},
Funding-Acknowledgement = {European Union {[}245986, NMP-2009-3.4-1]; Ministerio de Economia y
   Competitividad of Spain {[}AGL2011-30442-C02-02]},
Funding-Text = {The research leading to these results has been funded by the European
   Union's Seventh Framework Programme {[}FP7/2007-2013] under Grant
   Agreement no 245986 in the Theme NMP-2009-3.4-1 (Automation and robotics
   for sustainable crop and forestry management). The authors wish also to
   acknowledge to the project AGL2011-30442-C02-02, supported by the
   Ministerio de Economia y Competitividad of Spain within the Plan
   Nacional de I+D+i.},
Cited-References = {{[}Anonymous], 1998, LEARNING DATA CONCEP.
   Burgos-Artizzu XP, 2011, COMPUT ELECTRON AGR, V75, P337, DOI 10.1016/j.compag.2010.12.011.
   Burgos-Artizzu XP, 2009, COMPUT ELECTRON AGR, V65, P176, DOI 10.1016/j.compag.2008.09.001.
   Davies G., 1998, PRECISION AGR INTRO.
   Gebhardt S, 2007, PRECIS AGRIC, V8, P1, DOI 10.1007/s11119-006-9024-7.
   Gebhardt S, 2006, PRECIS AGRIC, V7, P165, DOI 10.1007/s11119-006-9006-9.
   Gee C, 2008, COMPUT ELECTRON AGR, V60, P49, DOI 10.1016/j.compag.2007.06.003.
   Guijarro M, 2011, COMPUT ELECTRON AGR, V75, P75, DOI 10.1016/j.compag.2010.09.013.
   Hague T, 2006, PRECIS AGRIC, V7, P21, DOI 10.1007/s11119-005-6787-1.
   Kataoka T., 2003, 2003 IEEE ASME INT C.
   Kirk K, 2009, BIOSYST ENG, V104, P308, DOI 10.1016/j.biosystemseng.2009.07.001.
   Ling PP, 1996, J AGR ENG RES, V65, P85, DOI 10.1006/jaer.1996.0082.
   Luscier JD, 2006, FRONT ECOL ENVIRON, V4, P408, DOI 10.1890/1540-9295(2006)4{[}408:UDPAOI]2.0.CO;2.
   Meyer G.E., 1998, MACHINE VISION DETEC.
   Meyer GE, 2004, COMPUT ELECTRON AGR, V42, P161, DOI 10.1016/j.compag.2003.08.002.
   Meyer GE, 2008, COMPUT ELECTRON AGR, V63, P282, DOI 10.1016/j.compag.2008.03.009.
   Neto J.C., 2004, COMBINED STAT SOFT C, DOI DOI 10.1016/J.JACI.2012.05.050.
   Onyango CM, 2003, COMPUT ELECTRON AGR, V39, P141, DOI 10.1016/S0168-1699(03)00023-1.
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076.
   Reid J. F., 1987, IEEE Control Systems Magazine, V7, P39, DOI 10.1109/MCS.1987.1105271.
   Ribeiro A., 2005, P 5 EUR C PREC AGR 5, P169.
   Ruiz-Ruiz G, 2009, COMPUT ELECTRON AGR, V68, P88, DOI 10.1016/j.compag.2009.04.009.
   Shrestha DS, 2004, BIOSYST ENG, V89, P119, DOI 10.1016/j.biosystemseng.2004.06.007.
   Tellaeche A, 2008, COMPUT ELECTRON AGR, V60, P144, DOI 10.1016/j.compag.2007.07.008.
   Tellaeche A, 2008, PATTERN RECOGN, V41, P521, DOI 10.1016/j.patcog.2007.07.007.
   Tian LF, 1998, COMPUT ELECTRON AGR, V21, P153, DOI 10.1016/S0168-1699(98)00037-4.
   Vapnik V., 1999, NATURE STAT LEARNING.
   WOEBBECKE DM, 1995, T ASAE, V38, P271, DOI 10.13031/2013.27839.
   Zheng LY, 2010, PATTERN RECOGN LETT, V31, P920, DOI 10.1016/j.patrec.2010.01.016.
   Zheng LY, 2009, COMPUT ELECTRON AGR, V65, P93, DOI 10.1016/j.compag.2008.08.002.},
Number-of-Cited-References = {30},
Times-Cited = {149},
Usage-Count-Last-180-days = {9},
Usage-Count-Since-2013 = {78},
Journal-ISO = {Expert Syst. Appl.},
Doc-Delivery-Number = {966UQ},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000305863300084},
DA = {2023-08-12},
}

@article{ WOS:000485298000046,
Author = {Goyal, Neha and Gupta, Kapil and Kumar, Nitin},
Title = {Multiclass Twin Support Vector Machine for plant species identification},
Journal = {MULTIMEDIA TOOLS AND APPLICATIONS},
Year = {2019},
Volume = {78},
Number = {19},
Pages = {27785-27808},
Month = {OCT},
Abstract = {Automatic plant species identification is one of the recent and
   fascinating research area as plants are crucial element of ecosystem.
   Several plant species exist with significant importance but most of us
   are unaware of the diversity of plant species available on earth. Their
   utility to humans starts as oxygen provider, food source, and medicinal
   compounds essential for medicines that are difficult to develop in right
   proportions. Being the first living habitants of earth, they have roots
   far deeper in the ecosystem than any living being. Hence, it is utmost
   important to develop automatic plant species identification system in
   which the digital image of the plant is given as input and the label of
   the plant is determined by the system. In this paper, we have focused on
   three different aspects (i) Significance of threshold (ii) Feature
   descriptor that can best describe the leaf images and (iii) Proposed a
   novel classification method called Multi class Twin Support Vector
   Machine which in an extension of widely used Twin Support Vector Machine
   classifier. The performance of the proposed method is compared with SVM,
   Multi Birth SVM and Probabilistic Neural Network. It is observed that
   the proposed classifier outperforms all the aforementioned classifiers
   on publicly available datasets.},
Publisher = {SPRINGER},
Address = {VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Goyal, N (Corresponding Author), NIT, Kurukshetra, Haryana, India.
   Goyal, Neha; Gupta, Kapil, NIT, Kurukshetra, Haryana, India.
   Kumar, Nitin, NIT, Dept Comp Sci \& Engn, Srinagar, Uttarakhand, India.},
DOI = {10.1007/s11042-019-7588-2},
ISSN = {1380-7501},
EISSN = {1573-7721},
Keywords = {Plant recognition; Image segmentation; Feature extraction; Multiclass
   classification; TWSVM},
Keywords-Plus = {FEATURES},
Research-Areas = {Computer Science; Engineering},
Web-of-Science-Categories  = {Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory \& Methods; Engineering,
   Electrical \& Electronic},
Author-Email = {neha.goya12309@gmail.com
   navkapil@gmail.com
   nitin@nituk.ac.in},
Affiliations = {National Institute of Technology (NIT System); National Institute of
   Technology Kurukshetra; National Institute of Technology (NIT System);
   National Institute of Technology Uttarakhand},
ResearcherID-Numbers = {Gupta, Kapil/AAN-8584-2020
   Kumar, Nitin/AAT-9454-2020
   Goyal, Neha/AFH-8800-2022
   Goyal, Neha/AAF-3497-2022
   },
ORCID-Numbers = {Gupta, Kapil/0000-0003-0264-948X
   Goyal, Neha/0000-0002-7016-4663},
Funding-Acknowledgement = {University Grant Commission, India},
Funding-Text = {We acknowledge University Grant Commission, India for supporting this
   research by providing fellowship to one of the author, Ms. Neha Goyal.
   We are also thankful to the reviewers for their valuable and
   constructive comments and suggestions for the paper. Their inputs have
   helped us in strengthening the overall quality of the paper.},
Cited-References = {Aakif A, 2015, BIOSYST ENG, V139, P66, DOI 10.1016/j.biosystemseng.2015.08.003.
   Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101.
   Arun Priya C., 2012, Proceedings of the 2012 International Conference on Pattern Recognition, Informatics and Medical Engineering (PRIME), P428, DOI 10.1109/ICPRIME.2012.6208384.
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199.
   Chen S, 2012, CROSS DISCIPLINARY B, P183.
   Chen S, 2015, IMAGE VISION COMPUT, V33, P68, DOI 10.1016/j.imavis.2014.10.007.
   Chen S, 2014, IEEE T IMAGE PROCESS, V23, P1629, DOI 10.1109/TIP.2013.2294548.
   Cope JS, 2012, EXPERT SYST APPL, V39, P7562, DOI 10.1016/j.eswa.2012.01.073.
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411.
   Dalal N, EUR C COMP VIS, P428.
   Dallimer M, 2012, BIOSCIENCE, V62, P47, DOI 10.1525/bio.2012.62.1.9.
   Du JX, 2007, APPL MATH COMPUT, V185, P883, DOI 10.1016/j.amc.2006.07.072.
   Hsiao JK, 2014, 2014 SCIENCE AND INFORMATION CONFERENCE (SAI), P389, DOI 10.1109/SAI.2014.6918216.
   Jayadeva, 2007, IEEE T PATTERN ANAL, V29, P905, DOI 10.1109/TPAMI.2007.1068.
   Kalyoncu C, 2015, COMPUT VIS IMAGE UND, V133, P102, DOI 10.1016/j.cviu.2014.11.001.
   Kumar N, 2012, LECT NOTES COMPUT SC, V7573, P502, DOI 10.1007/978-3-642-33709-3\_36.
   Pham NH, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTING, MANAGEMENT AND TELECOMMUNICATIONS (COMMANTEL), P134, DOI 10.1109/ComManTel.2013.6482379.
   Pilgrim SE, 2008, ECOLOGICAL KNOWLEDGE.
   Punyasena SW, 2014, APPL PLANT SCI, V2, DOI 10.3732/apps.1400071.
   Robinson BS, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0156572.
   ROSENFELD A, 1983, IEEE T SYST MAN CYB, V13, P231, DOI 10.1109/TSMC.1983.6313118.
   Rzanny M, 2017, PLANT METHODS, V13, DOI 10.1186/s13007-017-0245-8.
   Saleem G, 2019, COMPUT ELECTRON AGR, V157, P270, DOI 10.1016/j.compag.2018.12.038.
   SEZAN MI, 1990, COMPUT VISION GRAPH, V49, P36, DOI 10.1016/0734-189X(90)90161-N.
   Sourceforge, 2017, FLAV LEAF REC ALG PL.
   Sun Y, 2017, COMPUT INTELL NEUROS, V2017.
   Tomar D, 2015, KNOWL-BASED SYST, V81, P131, DOI 10.1016/j.knosys.2015.02.009.
   Trias-Blasi A, 2015, NATURE, V521, P161, DOI 10.1038/521161c.
   Waldchen J, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1005993.
   Waldchen J, 2018, ARCH COMPUT METHOD E, V25, P507, DOI 10.1007/s11831-016-9206-z.
   Wu SG, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, VOLS 1-3, P120.
   Yang ZX, 2013, NEURAL COMPUT APPL, V22, pS153, DOI 10.1007/s00521-012-1108-x.
   Yanikoglu B, 2014, MACH VISION APPL, V25, P1369, DOI 10.1007/s00138-014-0612-7.},
Number-of-Cited-References = {33},
Times-Cited = {6},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {12},
Journal-ISO = {Multimed. Tools Appl.},
Doc-Delivery-Number = {IW9FD},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000485298000046},
DA = {2023-08-12},
}

@article{ WOS:000540851700041,
Author = {Li, Yang and Chao, Xuewei},
Title = {ANN-Based Continual Classification in Agriculture},
Journal = {AGRICULTURE-BASEL},
Year = {2020},
Volume = {10},
Number = {5},
Month = {MAY},
Abstract = {In the area of plant protection and precision farming, timely detection
   and classification of plant diseases and crop pests play crucial roles
   in the management and decision-making. Recently, there have been many
   artificial neural network (ANN) methods used in agricultural
   classification tasks, which are task specific and require big datasets.
   These two characteristics are quite different from how humans learn
   intelligently. Undoubtedly, it would be exciting if the models can
   accumulate knowledge to handle continual tasks. Towards this goal, we
   propose an ANN-based continual classification method via memory storage
   and retrieval, with two clear advantages: Few data and high flexibility.
   This proposed ANN-based model combines a convolutional neural network
   (CNN) and generative adversarial network (GAN). Through learning of the
   similarity between input paired data, the CNN part only requires few raw
   data to achieve a good performance, suitable for a classification task.
   The GAN part is used to extract important information from old tasks and
   generate abstracted images as memory for the future task. Experimental
   results show that the regular CNN model performs poorly on the continual
   tasks (pest and plant classification), due to the forgetting problem.
   However, our proposed method can distinguish all the categories from new
   and old tasks with good performance, owing to its ability of
   accumulating knowledge and alleviating forgetting. There are so many
   possible applications of this proposed approach in the agricultural
   field, for instance, the intelligent fruit picking robots, which can
   recognize and pick different kinds of fruits; the plant protection is
   achieved by automatic identification of diseases and pests, which can
   continuously improve the detection range. Thus, this work also provides
   a reference for other studies towards more intelligent and flexible
   applications in agriculture.},
Publisher = {MDPI},
Address = {ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND},
Type = {Article},
Language = {English},
Affiliation = {Li, Y (Corresponding Author), Shihezi Univ, Coll Mech \& Elect Engn, Xinjiang 832003, Peoples R China.
   Li, Y (Corresponding Author), Tianjin Univ, Sch Elect \& Informat Engn, Tianjin 300072, Peoples R China.
   Li, Yang; Chao, Xuewei, Shihezi Univ, Coll Mech \& Elect Engn, Xinjiang 832003, Peoples R China.
   Li, Yang, Tianjin Univ, Sch Elect \& Informat Engn, Tianjin 300072, Peoples R China.},
DOI = {10.3390/agriculture10050178},
Article-Number = {178},
EISSN = {2077-0472},
Keywords = {similarity; metric; memory; deep learning},
Keywords-Plus = {STABILITY},
Research-Areas = {Agriculture},
Web-of-Science-Categories  = {Agronomy},
Author-Email = {liyang328@shzu.edu.cn
   psicnhpu@163.com},
Affiliations = {Shihezi University; Tianjin University},
ResearcherID-Numbers = {Li, Yang/ABC-9731-2020},
ORCID-Numbers = {Li, Yang/0000-0002-4268-4004},
Funding-Acknowledgement = {Natural Science Program of Shihezi University {[}KX01230101]; Shihezi
   University},
Funding-Text = {This research was funded by Natural Science Program of Shihezi
   University, grant number KX01230101. The APC was funded by Shihezi
   University.},
Cited-References = {Abdalla A, 2019, COMPUT ELECTRON AGR, V167, DOI 10.1016/j.compag.2019.105091.
   Abraham WC, 2005, TRENDS NEUROSCI, V28, P73, DOI 10.1016/j.tins.2004.12.003.
   Abu Jwade S, 2019, COMPUT ELECTRON AGR, V167, DOI 10.1016/j.compag.2019.105055.
   Berlemont S, 2018, NEUROCOMPUTING, V273, P47, DOI 10.1016/j.neucom.2017.07.060.
   Lima MCF, 2020, AGRICULTURE-BASEL, V10, DOI 10.3390/agriculture10050161.
   Carpenter GA, 2019, NEURAL NETWORKS, V120, P5, DOI 10.1016/j.neunet.2019.09.018.
   Fagott J, 2006, P NATL ACAD SCI USA, V103, P17564, DOI 10.1073/pnas.0605184103.
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009.
   Ghazi MM, 2017, NEUROCOMPUTING, V235, P228, DOI 10.1016/j.neucom.2017.01.018.
   Grutzendler J, 2002, NATURE, V420, P812, DOI 10.1038/nature01276.
   Kamilaris A, 2018, COMPUT ELECTRON AGR, V147, P70, DOI 10.1016/j.compag.2018.02.016.
   Kaya M, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11091066.
   Knoll FJ, 2019, COMPUT ELECTRON AGR, V167, DOI 10.1016/j.compag.2019.105097.
   Koirala A, 2020, AGRONOMY-BASEL, V10, DOI 10.3390/agronomy10010143.
   Li Y., 2020, ZENODO, DOI {[}10.5281/zenodo.3824050, DOI 10.5281/ZENODO.3824050].
   Li YF, 2020, COMPUT ELECTRON AGR, V169, DOI 10.1016/j.compag.2019.105174.
   Li Y, 2020, COMPUT ELECTRON AGR, V169, DOI 10.1016/j.compag.2020.105240.
   Liu ZY, 2016, SCI REP-UK, V6, DOI 10.1038/srep20410.
   Lu Y, 2017, NEUROCOMPUTING, V267, P378, DOI 10.1016/j.neucom.2017.06.023.
   Martineau M, 2017, PATTERN RECOGN, V65, P273, DOI 10.1016/j.patcog.2016.12.020.
   Parisi GI, 2019, NEURAL NETWORKS, V113, P54, DOI 10.1016/j.neunet.2019.01.012.
   Pourdarbani R, 2019, AGRONOMY-BASEL, V9, DOI 10.3390/agronomy9110672.
   Przybylak A, 2020, AGRICULTURE-BASEL, V10, DOI 10.3390/agriculture10040112.
   Thenmozhi K, 2019, COMPUT ELECTRON AGR, V164, DOI 10.1016/j.compag.2019.104906.
   Too EC, 2019, COMPUT ELECTRON AGR, V161, P272, DOI 10.1016/j.compag.2018.03.032.
   Wang JN, 2012, KNOWL-BASED SYST, V33, P102, DOI 10.1016/j.knosys.2012.03.014.
   Wu Y, 2019, AGRONOMY-BASEL, V9, DOI 10.3390/agronomy9110737.
   Xie CJ, 2018, COMPUT ELECTRON AGR, V152, P233, DOI 10.1016/j.compag.2018.07.014.},
Number-of-Cited-References = {28},
Times-Cited = {44},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {39},
Journal-ISO = {Agriculture-Basel},
Doc-Delivery-Number = {LY9MH},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000540851700041},
OA = {gold, Green Published},
DA = {2023-08-12},
}

@article{ WOS:000979962100007,
Author = {Weyler, Jan and Laebe, Thomas and Magistri, Federico and Behley, Jens
   and Stachniss, Cyrill},
Title = {Towards Domain Generalization in Crop and Weed Segmentation for
   Precision Farming Robots},
Journal = {IEEE ROBOTICS AND AUTOMATION LETTERS},
Year = {2023},
Volume = {8},
Number = {6},
Pages = {3310-3317},
Month = {JUN},
Abstract = {Precision farming robots offer the potential to reduce the amount of
   used agrochemicals through targeted interventions and thus are a
   promising step towards sustainable agriculture. A prerequisite for such
   systems is a robust plant classification system that can identify crops
   and weeds in various agricultural fields. Most vision-based systems
   train convolutional neural networks (CNNs) on a given dataset, i.e., the
   source domain, to perform semantic segmentation of images. However,
   deploying these models on unseen fields, i.e., in the target domain,
   often shows a low generalization capability. Enhancing the
   generalization capability of CNNs is critical to increasing their
   performance on target domains with different operational conditions. In
   this letter, we present a domain generalized semantic segmentation
   approach for robust crop and weed detection by effectively extending and
   diversifying the source domain to achieve high performance across
   different agricultural field conditions. We propose to leverage
   unlabeled images captured from various agricultural fields during
   training in a two-step framework. First, we suggest a method to
   automatically compute sparse annotations and use them to present the
   model more plant varieties and growth stages to enhance its
   generalization capability. Among others, we exploit unlabeled images
   from fields containing crops sown in rows. Second, we propose a style
   transfer method that renders the source domain images in the style of
   images from various fields to achieve increased diversification. We
   conduct extensive experiments and show that we achieve superior
   performance in crop-weed segmentation across various fields compared to
   state-of-the-art methods.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Weyler, J (Corresponding Author), Univ Bonn, D-53115 Bonn, Germany.
   Weyler, Jan; Laebe, Thomas; Magistri, Federico; Behley, Jens; Stachniss, Cyrill, Univ Bonn, D-53115 Bonn, Germany.
   Stachniss, Cyrill, Univ Oxford, Dept Engn Sci, Oxford OX1 4BH, England.
   Stachniss, Cyrill, Lamarr Inst Machine Learning \& Artificial Intellig, D-53115 Bonn, Germany.},
DOI = {10.1109/LRA.2023.3262417},
ISSN = {2377-3766},
Keywords = {Crops; Semantic segmentation; Soil; Annotations; Training; Vegetation
   mapping; Farming; Robotics and automation in agriculture and forestry;
   semantic scene understanding; deep learning for visual perception},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {jan.weyler@igg.uni-bonn.de
   laebe@ipb.uni-bonn.de
   federico.magistri@igg.uni-bonn.de
   jens.behley@igg.uni-bonn.de
   cyrill.stachniss@igg.uni-bonn.de},
Affiliations = {University of Bonn; University of Oxford},
ORCID-Numbers = {Weyler, Jan/0000-0002-8944-8949
   Laebe, Thomas/0000-0003-4873-513X
   Magistri, Federico/0000-0003-2815-5760
   Stachniss, Cyrill/0000-0003-1173-6972},
Funding-Acknowledgement = {Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)
   {[}EXC-2070 - 390732324, STA 1051/5-1, FOR 5351]},
Funding-Text = {H. I. Son and Editor H.Moon upon evaluation of the reviewers' comments.
   This work supported bythe Deutsche Forschungsgemeinschaft (DFG, German
   Research Foundation)through Germany's Excellence Strategy, EXC-2070 -
   390732324 - PhenoRoband through STA 1051/5-1 within the FOR 5351 -
   AID4Crops.},
Cited-References = {Chebrolu N, 2018, IEEE ROBOT AUTOM LET, V3, P3090, DOI 10.1109/LRA.2018.2849603.
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2\_49.
   Cherian A, 2019, IEEE WINT CONF APPL, P1797, DOI 10.1109/WACV.2019.00196.
   Chiu TY, 2019, IEEE I CONF COMP VIS, P4451, DOI 10.1109/ICCV.2019.00455.
   Choi S, 2021, PROC CVPR IEEE, P11575, DOI 10.1109/CVPR46437.2021.01141.
   Garcia-Garcia A, 2017, Arxiv, DOI {[}arXiv:1704.06857, 10.48550/arXiv.1704.06857, DOI 10.48550/ARXIV.1704.06857].
   Gogoll D, 2020, IEEE INT C INT ROBOT, P2636, DOI 10.1109/IROS45743.2020.9341277.
   Haug S, 2014, IEEE WINT CONF APPL, P1142, DOI 10.1109/WACV.2014.6835733.
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90.
   Hendrycks D., 2019, PROC INT C LEARN REP.
   Kingma DP., 2015, 3 INT C LEARN REPR I.
   Lee S, 2022, PROC CVPR IEEE, P9926, DOI 10.1109/CVPR52688.2022.00970.
   Lottes P, 2020, J FIELD ROBOT, V37, P20, DOI 10.1002/rob.21901.
   Lottes P, 2018, IEEE INT C INT ROBOT, P8233, DOI 10.1109/IROS.2018.8593678.
   Lottes P, 2018, IEEE ROBOT AUTOM LET, V3, P2870, DOI 10.1109/LRA.2018.2846289.
   Lottes P, 2017, J FIELD ROBOT, V34, P1160, DOI 10.1002/rob.21675.
   McCool C, 2017, IEEE ROBOT AUTOM LET, V2, P1344, DOI 10.1109/LRA.2017.2667039.
   Milioto A, 2017, ISPRS ANN PHOTO REM, V4-2, P41, DOI 10.5194/isprs-annals-IV-2-W3-41-2017.
   Muter M., 2013, PROC AGR ENG C.
   Owens P., 2005, MORPHOLOGY ENCY SOIL.
   Park T., 2020, EUR C COMP VIS, P319, DOI DOI 10.1007/978-3-030-58545-7\_19.
   Romera E, 2018, IEEE T INTELL TRANSP, V19, P263, DOI 10.1109/TITS.2017.2750080.
   Slaughter DC, 2008, COMPUT ELECTRON AGR, V61, P63, DOI 10.1016/j.compag.2007.05.008.
   Wenzhu Yang, 2015, Information Processing in Agriculture, V2, P149, DOI 10.1016/j.inpa.2015.07.003.},
Number-of-Cited-References = {24},
Times-Cited = {0},
Usage-Count-Last-180-days = {10},
Usage-Count-Since-2013 = {10},
Journal-ISO = {IEEE Robot. Autom. Lett.},
Doc-Delivery-Number = {F1IV9},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000979962100007},
DA = {2023-08-12},
}

@article{ WOS:000438070100001,
Author = {Bosilj, Petra and Duckett, Tom and Cielniak, Grzegorz},
Title = {Analysis of Morphology-Based Features for Classification of Crop and
   Weeds in Precision Agriculture},
Journal = {IEEE ROBOTICS AND AUTOMATION LETTERS},
Year = {2018},
Volume = {3},
Number = {4},
Pages = {2950-2956},
Month = {OCT},
Abstract = {Determining the types of vegetation present in an image is a core step
   in many precision agriculture tasks. In this letter, we focus on
   pixel-based approaches for classification of crops versus weeds,
   especially for complex cases involving overlapping plants and partial
   occlusion. We examine the benefits of multiscale and content-driven
   morphology-based descriptors called attribute profiles. These are
   compared to the state-of-the-art keypoint descriptors with a fixed
   neighborhood previously used in precision agriculture, namely histograms
   of oriented gradients and local binary patterns. The proposed
   classification technique is especially advantageous when coupled with
   morphology-based segmentation on a max-tree structure, as the same
   representation can be reused for feature extraction. The robustness of
   the approach is demonstrated by an experimental evaluation on two
   datasets with different crop types, while being able to provide
   descriptors at a higher resolution. The proposed approach compared
   favorably to the state-of-the-art approaches without an increase in
   computational complexity, while being able to provide descriptors at a
   higher resolution.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Bosilj, P (Corresponding Author), Univ Lincoln, Sch Comp Sci, Lincoln Ctr Autonomous Syst, Lincoln LN6 7TS, England.
   Bosilj, Petra; Duckett, Tom; Cielniak, Grzegorz, Univ Lincoln, Sch Comp Sci, Lincoln Ctr Autonomous Syst, Lincoln LN6 7TS, England.},
DOI = {10.1109/LRA.2018.2848305},
ISSN = {2377-3766},
Keywords = {Object detection; segmentation and categorization; agricultural
   automation; field robots},
Keywords-Plus = {PLANT CLASSIFICATION; ATTRIBUTE PROFILES; IMAGE; IDENTIFICATION;
   SEGMENTATION},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {pbosilj@lincoln.ac.uk
   tduckett@lincoln.ac.uk
   gcielniak@lincoln.ac.uk},
Affiliations = {University of Lincoln},
ResearcherID-Numbers = {Cielniak, Grzegorz/AAS-5387-2020
   },
ORCID-Numbers = {Cielniak, Grzegorz/0000-0002-6299-8465
   Bosilj, Petra/0000-0001-9640-9828},
Funding-Acknowledgement = {BBSRC {[}BB/P004911/1]; BBSRC {[}BB/P004911/1] Funding Source: UKRI},
Funding-Text = {This work was supported by BBSRC Grant BB/P004911/1.},
Cited-References = {{[}Anonymous], 1999, MORPHOLOGICAL IMAGE.
   {[}Anonymous], 2001, BAYESIAN THEORY.
   {[}Anonymous], 2014, IEEE WINTER C APPL C.
   Aptoula E, 2014, IEEE T GEOSCI REMOTE, V52, P3023, DOI 10.1109/TGRS.2013.2268736.
   Binch A, 2017, COMPUT ELECTRON AGR, V140, P123, DOI 10.1016/j.compag.2017.05.018.
   Bosilj P, 2018, COMPUT IND, V98, P226, DOI 10.1016/j.compind.2018.02.003.
   Bosilj P, 2018, J IMAGING, V4, DOI 10.3390/jimaging4020033.
   Bosilj P, 2016, ISPRS INT J GEO-INF, V5, DOI 10.3390/ijgi5120228.
   Breen EJ, 1996, COMPUT VIS IMAGE UND, V64, P377, DOI 10.1006/cviu.1996.0066.
   Breiman L., 1984, BIOMETRICS.
   Burgos-Artizzu XP, 2011, COMPUT ELECTRON AGR, V75, P337, DOI 10.1016/j.compag.2010.12.011.
   Cavallaro G, 2017, IEEE T IMAGE PROCESS, V26, P1859, DOI 10.1109/TIP.2017.2664667.
   Cavallaro G, 2015, IEEE GEOSCI REMOTE S, V12, P1690, DOI 10.1109/LGRS.2015.2419629.
   Chebrolu N, 2017, INT J ROBOT RES, V36, P1045, DOI 10.1177/0278364917720510.
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104.
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177.
   Dalla Mura M, 2010, IEEE T GEOSCI REMOTE, V48, P3747, DOI 10.1109/TGRS.2010.2048116.
   Guerrero JM, 2012, EXPERT SYST APPL, V39, P11149, DOI 10.1016/j.eswa.2012.03.040.
   Hamuda E, 2016, COMPUT ELECTRON AGR, V125, P184, DOI 10.1016/j.compag.2016.04.024.
   HE DC, 1990, IEEE T GEOSCI REMOTE, V28, P509.
   Hemming J, 2001, J AGR ENG RES, V78, P233, DOI 10.1006/jaer.2000.0639.
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692.
   Lemire D, 2007, PROCEEDINGS OF THE SEVENTH SIAM INTERNATIONAL CONFERENCE ON DATA MINING, P545.
   Lottes P, 2017, J FIELD ROBOT, V34, P1160, DOI 10.1002/rob.21675.
   Milioto A, 2018, IEEE INT CONF ROBOT, P2229.
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623.
   Rouse J.W., 1974, NASA SPECIAL PUBLICA, P301.
   SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458.
   Salembier P, 1998, IEEE T IMAGE PROCESS, V7, P555, DOI 10.1109/83.663500.
   Song BQ, 2014, IEEE T GEOSCI REMOTE, V52, P5122, DOI 10.1109/TGRS.2013.2286953.
   Tsolakidis DG, 2014, LECT NOTES ARTIF INT, V8445, P406, DOI 10.1007/978-3-319-07064-3\_33.
   WOEBBECKE DM, 1995, T ASAE, V38, P259, DOI 10.13031/2013.27838.
   Xiao XY, 2010, LECT NOTES ARTIF INT, V6216, P149, DOI 10.1007/978-3-642-14932-0\_19.},
Number-of-Cited-References = {33},
Times-Cited = {16},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {22},
Journal-ISO = {IEEE Robot. Autom. Lett.},
Doc-Delivery-Number = {GM4FE},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000438070100001},
OA = {Green Accepted},
DA = {2023-08-12},
}

@inproceedings{ WOS:000623016600032,
Author = {Liu, Peng and Zhang, Jingcheng and Wang, Bin and Zhang, Xuexue and Wu,
   Kaihua},
Editor = {Li, D and Zhao, C},
Title = {Study on Vegetation Classification Based on Spectral Knowledge Base},
Booktitle = {COMPUTER AND COMPUTING TECHNOLOGIES IN AGRICULTURE XI, CCTA 2017, PT II},
Series = {IFIP Advances in Information and Communication Technology},
Year = {2019},
Volume = {546},
Pages = {310-320},
Note = {11th IFIP WG 5.14 International Conference on Computer and Computing
   Technologies in Agriculture (CCTA), China Agr Univ, Natl Engn Res Ctr
   Informat Technol Agr, Jilin, OMAN, AUG 12-15, 2017},
Organization = {Int Federat Informat Proc, Tech Comm 5 14 Branch Agr Informat Proc;
   China Natl Engn Res Ctr Informat Technol Agr; China Natl Engn Res Ctr
   Intelligent Equipment Agr; Chinese Assoc Artificial Intelligence;
   Chinese Soc Agr Engn; Chinese Soc Agr Machinery; China Agr Mechanizat
   Assoc, Informatizat Branch; China Agro Technol Extens Asso, Comm
   Informat Technol; Technol Innovat Strateg Alliance Ag Internet Things
   Ind; Beijing Soc Informat Technol Agr; Minist Agr, Key Lab Informat
   Technol Agr; Sino US Cooperat Technol Ctr Agr Aviat; Beijing Key Lab
   Digital Plant; Minist Agr, Dept Sci, Technol \& Educ; Minist Agr, Dept
   Market \& Econ Informat; Minist Sci \& Technol, Dept Int Cooperat; Jilin
   Prov Agr Commiss; Jilin Prov Dept Sci \& Technol; Changchun Municipal
   Govt; Beijing Assoc Sci \& Technol; Beijing Acad Agr \& Forestry Sci},
Abstract = {A framework about spectral based vegetation classification was proposed,
   which serves as a core methodology of the vegetation spectral knowledge
   base. The hyperspectral reflectances of 13 types of plants were measured
   by an ASD FieldSpec 4 spectroradiometer. Two forms of spectral features
   were used for representing the key spectral characteristics of plants,
   including Vegetation index (VI) and spectral shape features. Based on
   these spectral features, a sensitivity analysis was performed to
   identify the most important features for establishing the classifier.
   The analysis of variance (ANOVA) and the cross-correlation analysis were
   applied to derive the sensitivity of features and remove features that
   have high correlations. Then, a classification method for
   differentiating plants was established by coupling some spectral
   similarity measures (e.g., ED) with some classification methods (e.g.,
   BPANN and SVM). The results of discrimination analysis showed that a
   highest accuracy was produced by SVM with the OAA over 99\% when using 7
   sensitive VIs. The results suggested the framework about spectral based
   vegetation classification can form a basis for spectral knowledge base
   and application technology and further achieve a wide range of plant
   classification based on remote sensing.},
Publisher = {SPRINGER INTERNATIONAL PUBLISHING AG},
Address = {GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Zhang, JC (Corresponding Author), Hangzhou Dianzi Univ, Coll Life Informat Sci \& Instrument Engn, Hangzhou 310018, Zhejiang, Peoples R China.
   Liu, Peng; Zhang, Jingcheng; Wang, Bin; Zhang, Xuexue; Wu, Kaihua, Hangzhou Dianzi Univ, Coll Life Informat Sci \& Instrument Engn, Hangzhou 310018, Zhejiang, Peoples R China.},
DOI = {10.1007/978-3-030-06179-1\_32},
ISSN = {1868-4238},
EISSN = {1868-422X},
ISBN = {978-3-030-06179-1; 978-3-030-06178-4},
Keywords = {Vegetation classification; Hyperspectral; Feature extraction;
   Classification algorithm},
Keywords-Plus = {SPECIES DISCRIMINATION; INDEX; RECOGNITION; IMAGERY; IKONOS; RATIO;
   MODIS},
Research-Areas = {Agriculture; Computer Science},
Web-of-Science-Categories  = {Agricultural Engineering; Computer Science, Information Systems;
   Computer Science, Interdisciplinary Applications},
Author-Email = {zzwliupeng@163.com
   zhangjc\_rs@163.com
   wangb\_rs@163.com
   zhangxx\_rs@163.com
   wukaihua@hdu.edu.cn},
Affiliations = {Hangzhou Dianzi University},
Funding-Acknowledgement = {Zhejiang public welfare programme of agriculture technology
   {[}2016C32087]; National Natural Science Foundation of China
   {[}41671415, 41601461]; Graduate Scientific Research Foundation of
   Hangzhou Dianzi University {[}CXJJ2017068]},
Funding-Text = {This work was supported by Zhejiang public welfare programme of
   agriculture technology (2016C32087), National Natural Science Foundation
   of China (41671415; 41601461) and Graduate Scientific Research
   Foundation of Hangzhou Dianzi University (CXJJ2017068).},
Cited-References = {Abdel-Rahman EM, 2010, INT J APPL EARTH OBS, V12, pS52, DOI 10.1016/j.jag.2009.11.003.
   Allard D, 2011, EUR J SOIL SCI, V62, P381, DOI 10.1111/j.1365-2389.2011.01362.x.
   BARNES JD, 1992, ENVIRON EXP BOT, V32, P85, DOI 10.1016/0098-8472(92)90034-Y.
   Bue BD, 2015, ISPRS J PHOTOGRAMM, V108, P33, DOI 10.1016/j.isprsjprs.2015.06.001.
   CONGALTON RG, 1983, PHOTOGRAMM ENG REM S, V49, P69.
   Delalieux S, 2008, REMOTE SENS ENVIRON, V112, P3762, DOI 10.1016/j.rse.2008.05.003.
   DEMETRIADESSHAH TH, 1990, REMOTE SENS ENVIRON, V33, P55, DOI 10.1016/0034-4257(90)90055-Q.
   Fensholt R, 2003, REMOTE SENS ENVIRON, V87, P111, DOI 10.1016/j.rse.2003.07.002.
   Galvao LS, 2005, REMOTE SENS ENVIRON, V94, P523, DOI 10.1016/j.rse.2004.11.012.
   GAMON JA, 1992, REMOTE SENS ENVIRON, V41, P35, DOI 10.1016/0034-4257(92)90059-S.
   Gong P, 1997, REMOTE SENS ENVIRON, V62, P189, DOI 10.1016/S0034-4257(97)00094-1.
   Huete A, 2002, REMOTE SENS ENVIRON, V83, P195, DOI 10.1016/S0034-4257(02)00096-2.
   Koppe W., PHOTOGRAMM FERNERKUN, V3, P167.
   Merton R., 1999, 8 JPL AIRB EARTH SCI, P9.
   Penuelas J, 1997, INT J REMOTE SENS, V18, P2869, DOI 10.1080/014311697217396.
   PENUELAS J, 1995, INT J REMOTE SENS, V16, P2727, DOI 10.1080/01431169508954588.
   PENUELAS J, 1995, PHOTOSYNTHETICA, V31, P221.
   Prospere K, 2014, REMOTE SENS-BASEL, V6, P8494, DOI 10.3390/rs6098494.
   Pu RL, 2012, REMOTE SENS ENVIRON, V124, P516, DOI 10.1016/j.rse.2012.06.011.
   Pu RL, 2011, ENVIRON MONIT ASSESS, V172, P199, DOI 10.1007/s10661-010-1327-5.
   Pu RL, 2009, INT J REMOTE SENS, V30, P2759, DOI 10.1080/01431160802555820.
   Rouse J.W., 1973, P 3 ERTS S, V1, P48.
   Schlerf M, 2005, REMOTE SENS ENVIRON, V95, P177, DOI 10.1016/j.rse.2004.12.016.
   Schmidt KS, 2003, REMOTE SENS ENVIRON, V85, P92, DOI 10.1016/S0034-4257(02)00196-7.
   STORY M, 1986, PHOTOGRAMM ENG REM S, V52, P397.
   Tsai F, 1998, REMOTE SENS ENVIRON, V66, P41, DOI 10.1016/S0034-4257(98)00032-7.
   van den Berg AK, 2005, HORTSCIENCE, V40, P685, DOI 10.21273/HORTSCI.40.3.685.
   Xiangbing Kong, 2010, Proceedings of the 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P2269, DOI 10.1109/CISP.2010.5647885.
   Yu J., 2017, JIANGSU AGR SCI, V45, P240.
   {[}曾帅 Zeng Shuai], 2017, {[}遥感信息, Remote Sensing Information], V32, P75.},
Number-of-Cited-References = {30},
Times-Cited = {0},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {7},
Doc-Delivery-Number = {BQ8WM},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000623016600032},
OA = {Green Submitted},
DA = {2023-08-12},
}

@article{ WOS:000861438200006,
Author = {Esquivel-Barboza, Esteban A. and Carranza-Rojas, Jose},
Title = {Senescence Reversion in Plant Images Using Perception and Unpaired Data},
Journal = {IEEE LATIN AMERICA TRANSACTIONS},
Year = {2022},
Volume = {20},
Number = {11},
Pages = {2346-2353},
Month = {NOV},
Abstract = {Recent work on using herbarium images for automatic plant
   identification, and in particular to do domain adaptation to field
   images, has been promising. A potential way to address such domain
   adaptation problem is generative: Hallucinate how a herbarium image
   would have looked like when it was in the field, and use such synthetic,
   fresh and green image for plant identification purposes. Such generative
   task, called senescence reversion, has been poorly explored. To our
   knowledge, it has been studied only in terms of paired data, meaning,
   with pairs of dry and fresh images of the same specimen. Such paired
   data is hard to produce, curate and find. In this work we explore
   herbarium senescence reversion via unpaired data. The lack of pairs at
   specimen level presents its own challenges, as capturing the intricacies
   of each species depends on images of different specimens from different
   domains. We explore learning a mapping from a herbarium image to leaf
   plant images and vice-versa, aligning two models, one for each herbarium
   and leaf domain. We experiment against the state-of-the-art paired
   baseline Pix2Pix which yields a SSIM of 0.8986, compared to our unpaired
   approach that yields 0.8865, showing very similar results on
   reconstruction metrics regardless of our approach not having the luxury
   of pairs by specimen. Additionally, we apply perceptual loss in order to
   improve the natural look of the synthetic images. The balance of how
   much perception is good to avoid reconstruction problems is also
   studied. Lastly, using a new unpaired dataset built by ourselves, our
   results show that using a low lambda value from 0.025 to 0.05 for
   perceptual loss, helps getting lower Frachet Inception Distances and
   higher Inception Scores. To our knowledge, no other work has focused on
   reverting senescence of herbarium sheet images based on unpaired data.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Esquivel-Barboza, EA (Corresponding Author), Costa Rica Inst Technol, Comp Engn Dept, Cartago, Costa Rica.
   Esquivel-Barboza, Esteban A., Costa Rica Inst Technol, Comp Engn Dept, Cartago, Costa Rica.
   Carranza-Rojas, Jose, Costa Rica Inst Technol, Microsoft Res \& Comp Engn Dept, Cartago, Costa Rica.},
DOI = {10.1109/TLA.2022.9904759},
ISSN = {1548-0992},
Keywords = {Task analysis; Image reconstruction; Generators; Training; Loss
   measurement; Feature extraction; Indexes; Image-to-image translation;
   Unpaired data; CycleGAN; Herbaria; Senescence reversion},
Research-Areas = {Computer Science; Engineering},
Web-of-Science-Categories  = {Computer Science, Information Systems; Engineering, Electrical \&
   Electronic},
Author-Email = {eesquivel@estudiantec.cr
   jose.m.carranza@microsoft.com},
Affiliations = {Instituto Tecnologico de Costa Rica; Instituto Tecnologico de Costa Rica},
ORCID-Numbers = {Carranza-Rojas, Jose/0000-0002-9177-9173
   Esquivel-Barboza, Esteban A./0000-0002-2100-9712},
Cited-References = {Affouard A., PL NTNET APP ERA DEE, P7.
   Amodio M, 2019, PROC CVPR IEEE, P8975, DOI 10.1109/CVPR.2019.00919.
   Blau Y, 2018, PROC CVPR IEEE, P6228, DOI 10.1109/CVPR.2018.00652.
   Carranza-Rojas J, 2017, BMC EVOL BIOL, V17, P1, DOI 10.1186/s12862-017-1014-z.
   Chen T, 2020, PR MACH LEARN RES, V119.
   Chen YS, 2018, PROC CVPR IEEE, P6306, DOI 10.1109/CVPR.2018.00660.
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848.
   Goeau H., OVERVIEW LIFECLEF PL, P15.
   Goodfellow I., GENERATIVE ADVERSARI.
   Hensel M, 2017, ADV NEUR IN, V30.
   Herve G., 2020, LIFECLEF 2020 PLANT, P2.
   Huang X., MULTIMODAL UNSUPERVI.
   Hussein B. R., RECONSTRUCTION DAMAG, V61.
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632.
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6\_43.
   Liu MY, 2017, ADV NEUR IN, V30.
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304.
   Mata-Montero E, 2015, PROC LAT AM COMPUT C, P41.
   Ounsworth M., ANTICIPATORY MOVEMEN.
   Park T., CONTRASTIVE LEARNING.
   Ronneberger O., U NET CONVOLUTIONAL.
   Salimans T., IMPROVED TECHNIQUES.
   Simonyan K., 2014, 14091556V6 ARXIV, P1, DOI DOI 10.48550/ARXIV.1409.1556.
   Talebi H, 2018, IEEE T IMAGE PROCESS, V27, P3998, DOI 10.1109/TIP.2018.2831899.
   Villacis-llobet J., 2019, COMMUN COMPUT PHYS, P438.
   Wang T., CYCLEGAN BETTER CYCL, P8.
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861.
   Yerman M., HERBARIUM EXPLORATIO.
   Zhang R., UNREASONABLE EFFECTI.
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244.},
Number-of-Cited-References = {30},
Times-Cited = {0},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {2},
Journal-ISO = {IEEE Latin Am. Trans.},
Doc-Delivery-Number = {4Y3OS},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000861438200006},
DA = {2023-08-12},
}

@article{ WOS:000459358400027,
Author = {Saleem, G. and Akhtar, M. and Ahmed, N. and Qureshi, W. S.},
Title = {Automated analysis of visual leaf shape features for plant
   classification},
Journal = {COMPUTERS AND ELECTRONICS IN AGRICULTURE},
Year = {2019},
Volume = {157},
Pages = {270-280},
Month = {FEB},
Abstract = {A large number of studies have been performed during the past few years
   to automatically identify the plant type in a given image. Besides
   common object recognition difficulties arising mainly due to light, pose
   and orientation variations, the plant type identification problem is
   further complicated by the differences in leaf shape overage and
   changing leaf color under different weather conditions. The limited
   accuracy of existing approaches can be improved using an appropriate
   selection of representative leaf based features. This study evaluates
   different handcrafted visual leaf features, their extraction techniques,
   and classification methods. Towards this end, a new five-step algorithm
   is presented (comprising image pre-processing, segmentation, feature
   extraction, dimensionality reduction, and classification steps) for
   recognition of plant type through leaf images. The proposed algorithm is
   evaluated on a publicly available standard dataset `Flavia' of 1600 leaf
   images and on a self-collected dataset of 625 leaf images. With the
   proposed algorithm, different classifiers such as k-nearest neighbor
   (KNN), decision tree, naive Bayes, and multi-support vector machines
   (SVM) are tested. The best performing KNN, claimed for the final
   results, reveals that the proposed algorithm gives precision and recall
   values of 97.6\% and 98.8\% respectively when tested on Plavia' dataset.
   The proposed technique is also tested on our self-collected dataset,
   giving respectively 96.1\% and 97.3\% precision and recall measure
   results. Results confirm that our approach, when augmented with
   efficient segmentation techniques on raw leaf images, can be a
   significantly accurate plant type recognition method in practical
   situations. AlexNet, a Convolutional Neural Network (CNN) based approach
   is also compared for classification on the datasets as oppose to
   handcrafted feature-based approach and it is found that the later
   outperforms the former in robustness when the training dataset is small.},
Publisher = {ELSEVIER SCI LTD},
Address = {THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Qureshi, WS (Corresponding Author), Natl Univ Sci \& Technol, Dept Mechatron Engn, H-12, Islamabad, Pakistan.
   Saleem, G., Natl Univ Sci \& Technol, Dept Comp \& Software Engn, H-12, Islamabad, Pakistan.
   Akhtar, M., Univ New South Wales, Sch Civil \& Environm Engn, Res Ctr Integrated Transport Innovat, Sydney, NSW 2052, Australia.
   Ahmed, N., Univ Engn \& Technol, Dept Comp Sci \& Engn, Lahore, Pakistan.
   Qureshi, W. S., Natl Univ Sci \& Technol, Dept Mechatron Engn, H-12, Islamabad, Pakistan.},
DOI = {10.1016/j.compag.2018.12.038},
ISSN = {0168-1699},
EISSN = {1872-7107},
Keywords = {Segmentation; Feature extraction; Dimensionality reduction; K-nearest
   neighbours; Naive Bayes},
Research-Areas = {Agriculture; Computer Science},
Web-of-Science-Categories  = {Agriculture, Multidisciplinary; Computer Science, Interdisciplinary
   Applications},
Author-Email = {gulshan.saleem14@ce.ceme.edu.pk
   m.akhtar@unsw.edu.au
   waqar.shahid@alumni.ait.asia},
Affiliations = {National University of Sciences \& Technology - Pakistan; University of
   New South Wales Sydney; University of Engineering \& Technology Lahore;
   National University of Sciences \& Technology - Pakistan},
ResearcherID-Numbers = {Ahmed, Nisar/AAX-5519-2020
   Qureshi, Waqar Shahid/ABG-1744-2020
   Ahmad, Nisar/IAQ-3092-2023},
ORCID-Numbers = {Ahmed, Nisar/0000-0002-6397-4860
   Qureshi, Waqar Shahid/0000-0003-0176-8145
   },
Cited-References = {Aakif A, 2015, BIOSYST ENG, V139, P66, DOI 10.1016/j.biosystemseng.2015.08.003.
   {[}Anonymous], 2012, PATT REC INF MED ENG.
   {[}Anonymous], 2007, LEAF RECOGNITION ALG.
   {[}Anonymous], 1999, ESANN.
   {[}Anonymous], OAC HERBARIUM.
   {[}Anonymous], 2012, LEAFSNAP COMPUTER VI.
   {[}Anonymous], 2013, ARXIV14014447.
   {[}Anonymous], 2014, ARXIV14100969.
   {[}Anonymous], 2013, INT J ENG SCI TECHNO.
   {[}Anonymous], 2013, SIGNAL PROCESSING PA.
   {[}Anonymous], EVALUATION FEATURES.
   {[}Anonymous], INT J SIGNAL PROCESS.
   {[}Anonymous], 2013, P 7 INT C BIOINSP CO.
   {[}Anonymous], 2007, SIGN PROC INF TECHN.
   {[}Anonymous], 2014, LEAF RECOGNITION USI.
   {[}Anonymous], SCI INF C SAI.
   {[}Anonymous], P 2 INT C COMP COMM.
   {[}Anonymous], 2014, P INT C ADV COMP COM.
   {[}Anonymous], 1979, IEEE T SYST MAN CYBE, DOI DOI 10.1109/TSMC.1979.4310076.
   FAYYAD UM, 1992, MACH LEARN, V8, P87, DOI 10.1023/A:1022638503176.
   Gwo CY, 2013, APPL PLANT SCI, V1, DOI 10.3732/apps.1200005.
   Joly A, 2014, ECOL INFORM, V23, P22, DOI 10.1016/j.ecoinf.2013.07.006.
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386.
   Lewis D. D., 1998, Machine Learning: ECML-98. 10th European Conference on Machine Learning. Proceedings, P4, DOI 10.1007/BFb0026666.
   Liu Nian, 2016, Journal of Beijing Forestry University, V38, P110.
   Munisami T, 2015, PROCEDIA COMPUT SCI, V58, P740, DOI 10.1016/j.procs.2015.08.095.
   Prasad S, 2017, MULTIMED TOOLS APPL, V76, P6915, DOI 10.1007/s11042-016-3309-2.
   Shlens J., 2005, TUTORIAL PRINCIPAL C.
   Tsolakidis DG, 2014, LECT NOTES ARTIF INT, V8445, P406, DOI 10.1007/978-3-319-07064-3\_33.
   Tyystjarvi E, 2011, PRECIS AGRIC, V12, P546, DOI 10.1007/s11119-010-9201-6.
   Vapnik V., 2013, NATURE STAT LEARNING.
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207.
   Zeng QM, 2017, MULTIMED TOOLS APPL, V76, P17873, DOI 10.1007/s11042-015-3178-0.},
Number-of-Cited-References = {33},
Times-Cited = {57},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {34},
Journal-ISO = {Comput. Electron. Agric.},
Doc-Delivery-Number = {HM3FF},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000459358400027},
DA = {2023-08-12},
}

@article{ WOS:000799279300103,
Author = {Goyal, Neha and Gupta, Kapil and Kumar, Nitin},
Title = {Clustering-Based Hierarchical Framework for Multiclass Classification of
   Leaf Images},
Journal = {IEEE TRANSACTIONS ON INDUSTRY APPLICATIONS},
Year = {2022},
Volume = {58},
Number = {3},
Pages = {4076-4085},
Month = {MAY-JUN},
Note = {IEEE International Conference on Computing, Power and Communication
   Technologies (GUCON), Greater Noida, INDIA, OCT 02-04, 2020},
Organization = {IEEE},
Abstract = {This article introduces a multiclass classification approach accustoming
   the benefits of partitioning-based strategies and hierarchical
   techniques. The proposed hierarchical framework creates a hierarchy with
   the notion of grouping classes with similar traits as one group. It
   overcomes the deficiency of the existing multiclass extension
   approaches, viz., nonlinearity, imbalanced class classification, and
   increasing classification cost with increasing number of classes. The
   hierarchical framework presents the idea of decomposing several classes
   hierarchically, where every cluster contains a set of classes having
   similar traits. The approach aims to maximize the intercluster distance
   and minimize the intracluster distribution. The effectiveness of the
   proposed method is evaluated on real-world and complex problems of plant
   recognition. Three leaf image datasets are considered for performance
   evaluation using a support vector machine. The results signify that the
   proposed approach for multiclass classification is an efficient approach
   with significantly improved recognition accuracy. It is a robust and
   effective approach with the least computational cost. The speedup factor
   of the proposed approach in the binary structure is 16, 6.5, and 5.5 as
   compared to a one-versus-one traditional support vector machine for
   Flavia, Swedish, and self-collected leaf datasets, respectively.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article; Proceedings Paper},
Language = {English},
Affiliation = {Goyal, N (Corresponding Author), Natl Inst Technol Kurukshetra, Kurukshetra 136119, Haryana, India.
   Goyal, Neha; Gupta, Kapil, Natl Inst Technol Kurukshetra, Kurukshetra 136119, Haryana, India.
   Kumar, Nitin, Natl Inst Technol Uttarakhand, Srinagar 246174, India.},
DOI = {10.1109/TIA.2022.3153757},
ISSN = {0093-9994},
EISSN = {1939-9367},
Keywords = {Support vector machines; Feature extraction; Training; Indexes; Task
   analysis; Partitioning algorithms; Clustering algorithms; Dunn index
   (DI); hierarchical approach; multiclass classification; separability
   matrix; silhouette value},
Keywords-Plus = {IDENTIFICATION; MACHINE; LEAVES; SYSTEM},
Research-Areas = {Engineering},
Web-of-Science-Categories  = {Engineering, Multidisciplinary; Engineering, Electrical \& Electronic},
Author-Email = {neha.goyal2309@gmail.com
   kapil@nitkkr.ac.in
   nitin@nituk.ac.in},
Affiliations = {National Institute of Technology (NIT System); National Institute of
   Technology Kurukshetra; National Institute of Technology (NIT System);
   National Institute of Technology Uttarakhand},
ResearcherID-Numbers = {Gupta, Kapil/A-7493-2016},
ORCID-Numbers = {Goyal, Neha/0000-0002-7016-4663
   Gupta, Kapil/0000-0003-0264-948X},
Funding-Acknowledgement = {University Grant Commission (UGC), India, through the Fellowship under
   the UGC National Eligibility Test Junior Research Fellowship Scheme
   {[}3320/NET-JULY 2016]},
Funding-Text = {The work of Neha Goyal was supported by the University Grant Commission
   (UGC), India, through the Fellowship under the UGC National Eligibility
   Test Junior Research Fellowship Scheme under Grant 3320/NET-JULY 2016.},
Cited-References = {{[}Anonymous], 2000, WORLD PAT INF, DOI DOI 10.1016/S0172-2190(00)00083-1.
   Bebbington A, 2005, J BIOL EDUC, V39, P62.
   Belhumeur PN, 2008, LECT NOTES COMPUT SC, V5305, P116, DOI 10.1007/978-3-540-88693-8\_9.
   BLASHFIELD RK, 1991, J CLASSIF, V8, P277.
   BOTTOU L, 1994, INT C PATT RECOG, P77, DOI 10.1109/ICPR.1994.576879.
   Chandra Mayank Arya, 2021, International Journal of Information Technology, V13, P1, DOI 10.1007/s41870-017-0080-1.
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199.
   Cheng LL, 2008, ICICSE: 2008 INTERNATIONAL CONFERENCE ON INTERNET COMPUTING IN SCIENCE AND ENGINEERING, PROCEEDINGS, P106.
   Cope JS, 2012, EXPERT SYST APPL, V39, P7562, DOI 10.1016/j.eswa.2012.01.073.
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411.
   Dallimer M, 2012, BIOSCIENCE, V62, P47, DOI 10.1525/bio.2012.62.1.9.
   Dong C, 2015, IEEE IJCNN.
   Friedman J. H., 1996, ANOTHER APPROACH POL.
   Gaston KJ, 2004, PHILOS T R SOC B, V359, P655, DOI 10.1098/rstb.2003.1442.
   Gatt S, 2007, J BIOL EDUC, V41, P117, DOI 10.1080/00219266.2007.9656080.
   Goeau H., 2013, PL NTNET MOBILE APP, P423, DOI {[}10.1145/2502081.2502251, DOI 10.1145/2502081.2502251].
   Goyal Neha, 2020, 2020 IEEE International Conference on Computing, Power and Communication Technologies (GUCON), P268, DOI 10.1109/GUCON48875.2020.9231240.
   Goyal N, 2019, MULTIMED TOOLS APPL, V78, P27785, DOI 10.1007/s11042-019-7588-2.
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797.
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314.
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427.
   Hu RX, 2012, IEEE T IMAGE PROCESS, V21, P4667, DOI 10.1109/TIP.2012.2207391.
   Huang FJ, 2019, CLUSTER COMPUT, V22, P11143, DOI 10.1007/s10586-017-1336-z.
   Kaur P.P., 2021, SOFT COMPUTING INTEL, P227.
   Kumar N, 2012, LECT NOTES COMPUT SC, V7573, P502, DOI 10.1007/978-3-642-33709-3\_36.
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41.
   Mabberley DJ., 2017, MABBERLEYS PLANT BOO, V4, DOI {[}10.1017/9781316335581, DOI 10.1017/9781316335581].
   Mahajan S, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13020356.
   Maulik U, 2002, IEEE T PATTERN ANAL, V24, P1650, DOI 10.1109/TPAMI.2002.1114856.
   Nie FP, 2020, NEUROCOMPUTING, V401, P153, DOI 10.1016/j.neucom.2019.10.051.
   Ogbuabor Godwin, 2018, International Journal of Computer Science \& Information Technology, V10, P27, DOI 10.5121/ijcsit.2018.10203.
   Platt JC, 2000, ADV NEUR IN, V12, P547.
   Robinson BS, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0156572.
   Sachar S, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114181.
   Stagg BC, 2013, J BIOL EDUC, V47, P104, DOI 10.1080/00219266.2013.764341.
   Nguyen T, 2015, EXPERT SYST APPL, V42, P2184, DOI 10.1016/j.eswa.2014.10.027.
   Thinsungnoena T., 2015, LEARNING, V3, P44, DOI DOI 10.12792/ICIAE2015.012.
   Waldchen J, 2018, METHODS ECOL EVOL, V9, P2216, DOI 10.1111/2041-210X.13075.
   Waldchen J, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1005993.
   Wu SG, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, VOLS 1-3, P120.
   Yigit E, 2019, COMPUT ELECTRON AGR, V156, P369, DOI 10.1016/j.compag.2018.11.036.
   Zhao ZQ, 2015, NEUROCOMPUTING, V151, P1112, DOI 10.1016/j.neucom.2014.02.077.},
Number-of-Cited-References = {42},
Times-Cited = {3},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {5},
Journal-ISO = {IEEE Trans. Ind. Appl.},
Doc-Delivery-Number = {1L4SE},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000799279300103},
DA = {2023-08-12},
}

@article{ WOS:000084853500005,
Author = {Lehrer, M},
Title = {Shape perception in the honeybee: Symmetry as a global framework},
Journal = {INTERNATIONAL JOURNAL OF PLANT SCIENCES},
Year = {1999},
Volume = {160},
Number = {6, S},
Pages = {S51-S65},
Month = {NOV},
Abstract = {This study is concerned with the honeybee's spatial vision in light of
   the spatial signals that natural flowers display. A large amount of
   behavioral data shows that bees are perfectly adept at learning and
   exploiting a variety of spatial cues in the task of recognizing and
   discriminating between visual stimuli. These cues include spatial
   frequency, distribution of contrasting areas, orientation of contours,
   size and distance, different types of edges, and symmetry (or, in a
   broader sense, geometry). Symmetry constitutes a global feature that is
   only one of the cues that the target offers. Symmetrical stimuli always
   contain several further spatial cues that become relevant as the bee
   comes nearer to the stimuli. The results reviewed here show that the
   spatial signals used by the bee depend on whether the stimuli are
   presented on a horizontal or a vertical plane, on whether bees make
   their choices at a lesser or a greater distance, and on whether the
   target's image is stationary at the level of the eye, as opposed to
   moving. Further, it is shown that pattern recognition in the bee does
   not always require a learning process (i.e., several types of response
   to visual stimuli are based on hard-wired, innate behavioral programs).
   Finally, the results show that although it is not a prerequisite for
   spatial vision, color vision participates in spatial vision, whereas
   spatial cues extracted from image motion are processed by a color-blind
   system.},
Publisher = {UNIV CHICAGO PRESS},
Address = {1427 E 60TH ST, CHICAGO, IL 60637-2954 USA},
Type = {Article},
Language = {English},
Affiliation = {Lehrer, M (Corresponding Author), Univ Zurich, Inst Zool, Dept Neurobiol, Winterthurerstr 190, CH-8057 Zurich, Switzerland.
   Univ Zurich, Inst Zool, Dept Neurobiol, CH-8057 Zurich, Switzerland.},
DOI = {10.1086/314216},
ISSN = {1058-5893},
EISSN = {1537-5315},
Keywords = {flower recognition; shape perception; edge detection; motion vision;
   distance estimation},
Keywords-Plus = {SOLITARY WASPS CERCERIS; FLOWER-LIKE PATTERNS; NAVIGATION EN-ROUTE;
   MOTION PARALLAX; SPATIAL VISION; ORIENTATION FLIGHTS; DISTANCE
   ESTIMATION; APIS-MELLIFERA; DIFFERENT CUES; BEES},
Research-Areas = {Plant Sciences},
Web-of-Science-Categories  = {Plant Sciences},
Author-Email = {miriam@zool.unizh.ch},
Affiliations = {University of Zurich},
Cited-References = {ANDERSON AM, 1977, ANIM BEHAV, V25, P80, DOI 10.1016/0003-3472(77)90069-0.
   ANDERSON AM, 1977, J COMP PHYSIOL, V114, P335, DOI 10.1007/BF00657328.
   {[}Anonymous], 1965, TANZSPRACHE ORIENTIE, DOI 10.1007/978-3-642-94916-6.
   {[}Anonymous], {[}No title captured], DOI DOI 10.1007/978-3642-67868-4.
   AUTRUM H, 1964, Z VERGL PHYSIOL, V48, P357, DOI 10.1007/BF00299270.
   BRUNNERT U, 1994, J COMP PHYSIOL A, V175, P363, DOI 10.1007/BF00192995.
   Campan R, 1997, EXS, V84, P1.
   Campan R., 1982, Bulletin de la Societe d'Histoire Naturelle de Toulouse, V117, P41.
   CARTWRIGHT BA, 1979, J EXP BIOL, V82, P367.
   CARTWRIGHT BA, 1981, J COMP PHYSL, V151, P521.
   Chittka L, 1996, NATURWISSENSCHAFTEN, V83, P136, DOI 10.1007/BF01142181.
   COLLETT TS, 1992, PHILOS T R SOC B, V337, P295, DOI 10.1098/rstb.1992.0107.
   Collett TS, 1996, J EXP BIOL, V199, P227.
   Collett TS, 1997, EXS, V84, P41.
   COLLETT TS, 1978, J EXP BIOL, V76, P237.
   CRUSE H, 1974, KYBERNETIK, V15, P73, DOI 10.1007/BF00270651.
   Dafni A, 1997, BIOL REV, V72, P239, DOI 10.1017/S0006323196005002.
   Dafni A, 1999, EVOLUTIONARY THEORY AND PROCESSES: MODERN PERSPECTIVES, P363.
   Dafni A, 1996, BOT J LINN SOC, V120, P371, DOI 10.1111/j.1095-8339.1996.tb00487.x.
   ERBER J, 1982, J COMP PHYSIOL, V146, P273, DOI 10.1007/BF00610247.
   Esch HE, 1996, J EXP BIOL, V199, P155.
   EXNER S, 1976, SITZUNGSBER BER KAIS, V172, P156.
   Fauria K, 1998, J INSECT BEHAV, V11, P649, DOI 10.1023/A:1022394708973.
   FREE J B, 1970, Behaviour, V37, P269, DOI 10.1163/156853970X00376.
   Giurfa M, 1996, J COMP PHYSIOL A, V178, P699.
   Giurfa M, 1996, NATURE, V382, P458, DOI 10.1038/382458a0.
   Giurfa M, 1999, INT J PLANT SCI, V160, pS41, DOI 10.1086/314214.
   GOULD JL, 1988, ANIM BEHAV, V36, P487, DOI 10.1016/S0003-3472(88)80019-8.
   HERTZ M, 1930, Z VERGL PHYSIOL, V11, P107.
   HERTZ MATHILDE, 1933, BIOL ZENTRALBL, V53, P10.
   Horridge A, 1997, FROM LIVING EYES TO SEEING MACHINES, P52.
   HORRIDGE A, 1994, BIOESSAYS, V16, P877, DOI 10.1002/bies.950161205.
   HORRIDGE GA, 1995, J INSECT PHYSIOL, V41, P681, DOI 10.1016/0022-1910(95)00021-L.
   HORRIDGE GA, 1992, PHILOS T R SOC B, V337, P49, DOI 10.1098/rstb.1992.0082.
   HORRIDGE GA, 1986, PROC R SOC SER B-BIO, V229, P13, DOI 10.1098/rspb.1986.0071.
   Horridge GA, 1996, J INSECT PHYSIOL, V42, P755, DOI 10.1016/0022-1910(96)00026-1.
   HUBEL DH, 1968, J PHYSIOL-LONDON, V195, P215, DOI 10.1113/jphysiol.1968.sp008455.
   HUBEL DH, 1987, J NEUROSCI, V7, P3378.
   KAISER W, 1974, J COMP PHYSIOL, V89, P391, DOI 10.1007/BF00695355.
   LEHRER M, 1995, NATURWISSENSCHAFTEN, V82, P145, DOI 10.1007/BF01177278.
   LEHRER M, 1990, PROC R SOC SER B-BIO, V238, P321, DOI 10.1098/rspb.1990.0002.
   LEHRER M, 1995, PHILOS T R SOC B, V347, P123, DOI 10.1098/rstb.1995.0017.
   LEHRER M, 1993, J COMP PHYSIOL A, V172, P549, DOI 10.1007/BF00213678.
   LEHRER M, 1988, NATURE, V332, P356, DOI 10.1038/332356a0.
   LEHRER M, 1994, VISION RES, V34, P2363, DOI 10.1016/0042-6989(94)90282-8.
   LEHRER M, 1994, J COMP PHYSIOL A, V175, P171, DOI 10.1007/BF00215113.
   Lehrer M, 1997, ISR J PLANT SCI, V45, P157, DOI 10.1080/07929978.1997.10676681.
   Lehrer M, 1999, J COMP PHYSIOL A, V184, P195, DOI 10.1007/s003590050318.
   LEHRER M, 1994, VISION RES, V34, P511, DOI 10.1016/0042-6989(94)90164-3.
   LEHRER M, 1987, Israel Journal of Entomology, V21, P51.
   LEHRER M, 1993, J COMP PHYSIOL A, V173, P23, DOI 10.1007/BF00209615.
   Lehrer M, 1998, J EXP BIOL, V201, P3275.
   LEHRER M, 1991, NATURWISSENSCHAFTEN, V78, P274, DOI 10.1007/BF01134357.
   LEHRER M, 1985, J COMP PHYSIOL A, V157, P405, DOI 10.1007/BF00615140.
   LIVINGSTONE MS, 1987, J NEUROSCI, V7, P3416.
   MAZOCHINPORSHNY.GA, 1977, J OBSCH BIOL, V38, P855.
   Menzel R., 1989, P281.
   MENZEL R, 1986, J COMP PHYSIOL A, V158, P165, DOI 10.1007/BF01338560.
   MENZEL R, 1983, J COMP PHYSIOL, V151, P441, DOI 10.1007/BF00605460.
   Moller AP, 1999, INT J PLANT SCI, V160, pS135, DOI 10.1086/314219.
   Neal PR, 1998, ANNU REV ECOL SYST, V29, P345, DOI 10.1146/annurev.ecolsys.29.1.345.
   RONACHER B, 1979, BIOL CYBERN, V32, P63, DOI 10.1007/BF00337437.
   SCHLIEPER C, 1927, Z VERGL PHYSIOL, V6, P453.
   SCHNETTER B, 1927, INFORMATION PROCESSI, P195.
   SOBEL EC, 1990, J COMP PHYSIOL A, V167, P579, DOI 10.1007/BF00192653.
   SPRENGEL CK, 1993, ENTDECKTE GEHEIMNIS.
   SRINIVASAN MV, 1994, J INSECT PHYSIOL, V40, P183, DOI 10.1016/0022-1910(94)90041-8.
   Srinivasan MV, 1997, EXS, V84, P95.
   SRINIVASAN MV, 1993, NATURE, V362, P539, DOI 10.1038/362539a0.
   SRINIVASAN MV, 1994, PHILOS T R SOC B, V343, P199, DOI 10.1098/rstb.1994.0021.
   SRINIVASAN MV, 1989, J COMP PHYSIOL A, V165, P605, DOI 10.1007/BF00610992.
   SRINIVASAN MV, 1991, VISUAL NEUROSCI, V6, P519, DOI 10.1017/S095252380000136X.
   Srinivasan MV, 1996, J EXP BIOL, V199, P237.
   SRINIVASAN MV, 1990, PROC R SOC SER B-BIO, V238, P331, DOI 10.1098/rspb.1990.0003.
   Srinivasan MV, 1997, J EXP BIOL, V200, P2513.
   SRINIVASAN MV, 1985, VISION RES, V25, P997, DOI 10.1016/0042-6989(85)90210-X.
   SRINIVASAN MV, 1988, J COMP PHYSIOL A, V162, P159, DOI 10.1007/BF00606081.
   VANHATEREN JH, 1990, J COMP PHYSIOL A, V167, P649, DOI 10.1007/BF00192658.
   WALCHER F, 1994, PHYSIOL ENTOMOL, V19, P230, DOI 10.1111/j.1365-3032.1994.tb01047.x.
   WALLACE GK, 1959, J EXP BIOL, V36, P512.
   WEHNER R, 1977, Z NATURFORSCH C, V32, P469.
   WEHNER R, 1972, J COMP PHYSIOL PSYCH, V77, P256, DOI 10.1007/BF00696429.
   WEHNER R, 1966, Z VERGL PHYSIOL, V52, P290, DOI 10.1007/BF02427714.
   WEHNER R, 1974, COMPOUND EYE VISION, P75.
   Wolf E, 1935, J GEN PHYSIOL, V18, P853, DOI 10.1085/jgp.18.6.853.
   Wolf E., 1933, Zeitschrift fuer Vergleichende Physiologie Berlin, V20, P151, DOI 10.1007/BF00340756.
   Zeil J, 1996, J EXP BIOL, V199, P245.
   ZEIL J, 1993, J COMP PHYSIOL A, V172, P207, DOI 10.1007/BF00189397.
   ZERRAHN G, 1934, Z VERGL PHYSIOL, V20, P117.},
Number-of-Cited-References = {89},
Times-Cited = {22},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {15},
Journal-ISO = {Int. J. Plant Sci.},
Doc-Delivery-Number = {276AM},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000084853500005},
DA = {2023-08-12},
}

@article{ WOS:000740088600001,
Author = {Blesslin Elizabeth, C. P. and Baulkani, S.},
Title = {Novel Network for Medicinal Leaves Identification},
Journal = {IETE JOURNAL OF RESEARCH},
Year = {2023},
Volume = {69},
Number = {4},
Pages = {1772-1782},
Month = {MAY 19},
Abstract = {From the ancient days, plant leaves are used to cure various infectious
   diseases. Even today, herbal leaves are preferred by medicinal experts
   for treating cancer, asthma, heart problems, etc. The recognition of
   these herbal plants is based on the visual perception of villagers.
   There are many kinds of species that seem to be very similar in color
   and shape. There is a high probability of human error in the
   identification of such plants. It is inevitable to correctly identify
   the species of plants to treat the patients. Therefore, a smart plant
   classification system is essentially required to eliminate human error.
   This research work develops a hybrid system that is based on deep
   convolutional neural networks. The system is named as AousethNet which
   is a modification of AlexNet by replacing its classifier namely, SoftMax
   with the Majority vote classifier. It is trained to predict the plant
   species from a huge number of leaf samples from four datasets namely
   Mendeley, D-Leaf, Flavia, and Folio. Typically, the performance of
   AousethNet with Mendeley dataset attained an accuracy of 99.89\%,
   precision 98.61\%, and very less recognition time of 0.087 s/image. This
   system is found to have good feature extraction and strong
   discrimination ability compared with the original version of AlexNet.},
Publisher = {TAYLOR \& FRANCIS LTD},
Address = {2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Elizabeth, CPB (Corresponding Author), Arunachala Coll Engn Women, Dept Elect \& Commun Engn, Kanyakumari 629203, Tamil Nadu, India.
   Blesslin Elizabeth, C. P., Arunachala Coll Engn Women, Dept Elect \& Commun Engn, Kanyakumari 629203, Tamil Nadu, India.
   Baulkani, S., Govt Coll Engn, Dept Elect \& Commun Engn, Tirunelveli 627007, Tamil Nadu, India.},
DOI = {10.1080/03772063.2021.2016504},
EarlyAccessDate = {JAN 2022},
ISSN = {0377-2063},
EISSN = {0974-780X},
Keywords = {AlexNet; AousethNet; Deep convolutional neural networks; Majority vote
   classifier; Medicinal leaves identification; SoftMax},
Keywords-Plus = {CLASSIFICATION; RECOGNITION},
Research-Areas = {Engineering; Telecommunications},
Web-of-Science-Categories  = {Engineering, Electrical \& Electronic; Telecommunications},
Author-Email = {bless\_christo@yahoo.co.in
   ramabaulkani@yahoo.co.in},
Cited-References = {Alok N., 2021, MACHINE LEARNING HEA, P187, DOI DOI 10.1002/9781119792611.CH12.
   Bansal M, 2021, SOFT COMPUT, V25, P4423, DOI 10.1007/s00500-020-05453-y.
   Beghin T, 2010, LECT NOTES COMPUT SC, V6475, P345, DOI 10.1007/978-3-642-17691-3\_32.
   Begue A, 2017, INT J ADV COMPUT SC, V8, P166.
   Chhabra P, 2020, NEURAL COMPUT APPL, V32, P2725, DOI 10.1007/s00521-018-3677-9.
   Dabral I, 2019, INT C DEEP LEARN ART, P290, DOI {[}10.1007/978-3-030-67187-7\_30, DOI 10.1007/978-3-030-67187-7\_30].
   Dileep MR, 2019, TENCON IEEE REGION, P321, DOI 10.1109/TENCON.2019.8929394.
   Dobrescu A, 2020, FRONT PLANT SCI, V11, DOI 10.3389/fpls.2020.00141.
   Dudi B., 2019, INT J ADV TRENDS COM, V8, P999, DOI DOI 10.30534/IJATCSE/2019/03842019.
   Garg D, 2018, MULTIMED TOOLS APPL, V77, P26545, DOI 10.1007/s11042-018-5878-8.
   Gyires-Toth BP, 2019, CYBERN INF TECHNOL, V19, P88, DOI 10.2478/cait-2019-0005.
   Jeon WS, 2017, INT J FUZZY LOG INTE, V17, P26, DOI 10.5391/IJFIS.2017.17.1.26.
   Jiang HX, 2020, IEEE ACCESS, V8, P68828, DOI 10.1109/ACCESS.2020.2986946.
   Khan, 2016, INTRO IMPORTANCE MED.
   Kumar K, 2021, MULTIMED TOOLS APPL, V80, P11079, DOI 10.1007/s11042-020-10157-4.
   Kumar M, 2020, ARTIF INTELL REV, V53, P2075, DOI 10.1007/s10462-019-09727-2.
   Kumar M, 2019, IEEE ACCESS, V7, P163912, DOI 10.1109/ACCESS.2019.2952176.
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P21557, DOI 10.1007/s11042-017-5587-8.
   Kumari Shreya, 2021, International Conference on Deep Learning, Artificial Intelligence and Robotics ICDLAIR 2019. Proceedings. Lecture Notes in Networks and Systems (LNNS 175), P339, DOI 10.1007/978-3-030-67187-7\_35.
   Lagar-Cavilla H. A., 2009, 2012 INT C DIG IM CO, P1, DOI DOI 10.1109/DICTA.2012.6411702.
   Lai Y, 2019, J PHYS C SERIES, V1314.
   Liu ZB, 2016, FOOD ANAL METHOD, V9, P3133, DOI 10.1007/s12161-016-0497-3.
   Monika, 2021, Computational Methods and Data Engineering. Proceedings of ICMDE 2020. Advances in Intelligent Systems and Computing (AISC 1227), P207, DOI 10.1007/978-981-15-6876-3\_16.
   Negi A, 2021, AGR INFORMATICS AUTO, P117, DOI DOI 10.1002/9781119769231.CH6.
   Pankaja K, 2017, 2017 INTERNATIONAL CONFERENCE ON INNOVATIVE MECHANISMS FOR INDUSTRY APPLICATIONS (ICIMIA), P442, DOI 10.1109/ICIMIA.2017.7975654.
   Pereira CS, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19224850.
   Rangarajan AK, 2018, PROCEDIA COMPUT SCI, V133, P1040, DOI 10.1016/j.procs.2018.07.070.
   Sharma S., 2020, IETE J RES, V1, P11.
   Sharma S, 2019, ADV INTELL SYST COMP, V748, P423, DOI 10.1007/978-981-13-0923-6\_37.
   Suh HK, 2018, BIOSYST ENG, V174, P50, DOI 10.1016/j.biosystemseng.2018.06.017.
   Tan JW, 2020, IEEE ACM T COMPUT BI, V17, P82, DOI 10.1109/TCBB.2018.2848653.},
Number-of-Cited-References = {31},
Times-Cited = {2},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Journal-ISO = {IETE J. Res.},
Doc-Delivery-Number = {G0BL3},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000740088600001},
DA = {2023-08-12},
}

@article{ WOS:000356395000005,
Author = {Son, Hyojoo and Kim, Changmin and Kim, Changwan},
Title = {Fully Automated As-Built 3D Pipeline Extraction Method from
   Laser-Scanned Data Based on Curvature Computation},
Journal = {JOURNAL OF COMPUTING IN CIVIL ENGINEERING},
Year = {2015},
Volume = {29},
Number = {4},
Month = {JUL},
Abstract = {There has been a growing demand for the three-dimensional (3D)
   reconstruction of as-built pipelines. The as-built 3D pipeline
   reconstruction process consists of the measurement of an industrial
   plant, identification of pipelines, and generation of 3D models of the
   pipelines. Although measurement is now efficiently performed using
   laser-scanning technology, and in spite of significant progress in 3D
   pipeline model generation, the identification of pipelines from large
   and complex sets of laser-scanned data continues to pose a challenge.
   The aim of this study is to propose a method to automatically extract 3D
   points corresponding to as-built pipelines that occupy large areas of
   industrial plants from laser-scanned data. The proposed extraction
   method consists of the following steps: preprocessing, segmentation of
   the 3D point cloud, feature extraction based on curvature computation,
   and pipeline classification. An experiment was performed at an operating
   industrial plant to validate the proposed method. The experimental
   result revealed that the proposed method can indeed contribute to the
   automation of as-built 3D pipeline reconstruction. (C) 2014 American
   Society of Civil Engineers.},
Publisher = {ASCE-AMER SOC CIVIL ENGINEERS},
Address = {1801 ALEXANDER BELL DR, RESTON, VA 20191-4400 USA},
Type = {Article},
Language = {English},
Affiliation = {Kim, C (Corresponding Author), Chung Ang Univ, Dept Architectural Engn, Seoul 156756, South Korea.
   Son, Hyojoo; Kim, Changmin; Kim, Changwan, Chung Ang Univ, Dept Architectural Engn, Seoul 156756, South Korea.},
DOI = {10.1061/(ASCE)CP.1943-5487.0000401},
Article-Number = {B4014003},
ISSN = {0887-3801},
EISSN = {1943-5487},
Keywords = {As-built reconstruction; As-built pipeline; Industrial plant; Pipeline
   extraction; Curvature computation},
Keywords-Plus = {LIDAR POINT CLOUDS; AIRBORNE LIDAR; RECONSTRUCTION; CONSTRUCTION;
   GENERATION; ALGORITHM; SURFACES; MODEL},
Research-Areas = {Computer Science; Engineering},
Web-of-Science-Categories  = {Computer Science, Interdisciplinary Applications; Engineering, Civil},
Author-Email = {hjson0908@cau.ac.kr
   changmin1101@cau.ac.kr
   changwan@cau.ac.kr},
Affiliations = {Chung Ang University},
ResearcherID-Numbers = {Son, Hyojoo/AAL-2182-2021
   Son, Hyojoo/AHA-1259-2022
   },
ORCID-Numbers = {Son, Hyojoo/0000-0002-5338-9799
   Kim, Changmin/0000-0002-1017-8297},
Funding-Acknowledgement = {High-tech Urban Development Program - Ministry of Land, Transport and
   Maritime Affairs of the Korean government {[}12 High-tech Urban C02];
   National Research Foundation of Korea {[}2012H1A2A1048987] Funding
   Source: Korea Institute of Science \& Technology Information (KISTI),
   National Science \& Technology Information Service (NTIS)},
Funding-Text = {This research was supported by a grant (12 High-tech Urban C02) from
   High-tech Urban Development Program funded by Ministry of Land,
   Transport and Maritime Affairs of the Korean government.},
Cited-References = {Ahmed M., 2013, P 30 INT S AUT ROB C.
   {[}Anonymous], EDGEWISE PLANT 4 0 C.
   {[}Anonymous], AUTOCAD PLANT 3D 201.
   {[}Anonymous], SMARTPLANT 3D 2013 C.
   {[}Anonymous], LEIC CYCL 8 0 COMP S.
   Bayramoglu N. Y., 2011, THESIS MIDDLE E TECH.
   Bey A., 2011, P INT SOC PHOT REM S.
   Chen CF, 2010, COMPUT GEOSCI-UK, V36, P717, DOI 10.1016/j.cageo.2009.12.001.
   Chunmei H., 2009, P INT FOR COMP SCI T.
   Dias P, 2006, COMPUT-AIDED CIV INF, V21, P486, DOI 10.1111/j.1467-8667.2006.00453.x.
   Doneus M., 2011, P INT 23 CIPA INT CO.
   Easa SM, 2008, COMPUT-AIDED CIV INF, V23, P560, DOI 10.1111/j.1467-8667.2008.00560.x.
   Ermes P., 2000, P INT ARCH PHOT REM.
   FARIN G, 1997, CURVES SURFACES COMP.
   Galvez A, 2012, INFORM SCIENCES, V192, P174, DOI 10.1016/j.ins.2010.11.007.
   Gomez-Garcia-Bermejo J, 2013, COMPUT-AIDED CIV INF, V28, P98, DOI 10.1111/j.1467-8667.2012.00785.x.
   Hinks T, 2009, J COMPUT CIVIL ENG, V23, P330, DOI 10.1061/(ASCE)0887-3801(2009)23:6(330).
   Jin X., 2011, ADV MAT RES, V383-390, P4286.
   JOHNSON AE, 1997, P INT C REC ADV 3D D.
   Kawashima K., 2011, P INT SOC PHOT REM S.
   Khoshelham K, 2012, SENSORS-BASEL, V12, P1437, DOI 10.3390/s120201437.
   Kiraly G., 2008, PHOTOGRAMM J FIN, V21, P37.
   Ko KH, 2011, COMPUT AIDED DESIGN, V43, P848, DOI 10.1016/j.cad.2011.04.013.
   Li BS, 2010, J COMPUT CIVIL ENG, V24, P223, DOI 10.1061/(ASCE)CP.1943-5487.0000023.
   Li Y, 2013, OPT LASER TECHNOL, V54, P288, DOI 10.1016/j.optlastec.2013.06.007.
   Liang X., 2008, P 2008 INT WORKSH EA.
   Martins FAR, 2005, MECHATRONICS, V15, P837, DOI 10.1016/j.mechatronics.2005.01.004.
   Masuda H., 2010, COMPUTER AIDED DESIG, V7, P349.
   McLaughlin J, 2004, COMPUT-AIDED CIV INF, V19, P3, DOI 10.1111/j.1467-8667.2004.00333.x.
   Piegl L, 1997, NURBS BOOK.
   Pottmann H., 2004, P EUR C COMP VIS SPR.
   Rabbani T., 2006, P ISPRS COMM 5 S IM.
   Rabbani T, 2006, THESIS DELFT U TECHN.
   Remondino F, 2006, PHOTOGRAMM REC, V21, P269, DOI 10.1111/j.1477-9730.2006.00383.x.
   Roh HY, 2004, COMPUT METHOD APPL M, V193, P2261, DOI 10.1016/j.cma.2004.01.019.
   Sampath A, 2007, PHOTOGRAMM ENG REM S, V73, P805, DOI 10.14358/PERS.73.7.805.
   Sareen KK, 2012, COMPUT-AIDED CIV INF, V27, P555, DOI 10.1111/j.1467-8667.2011.00742.x.
   Son H., 2013, P 2013 ASCE INT WORK.
   Tangelder J. W. H., 1999, P INT ARCH PHOT REM.
   Tooke TR, 2013, BUILD ENVIRON, V60, P234, DOI 10.1016/j.buildenv.2012.10.015.
   Truong-Hong L, 2012, J COMPUT CIVIL ENG, V26, P691, DOI DOI 10.1061/(ASCE)CP.1943-5487.0000188.
   Tsai YC, 2010, COMPUT-AIDED CIV INF, V25, P78, DOI 10.1111/j.1467-8667.2009.00622.x.
   Veldhuis H, 1998, ISPRS J PHOTOGRAMM, V53, P6, DOI 10.1016/S0924-2716(97)00031-2.
   Wang MA, 2011, PHOTOGRAMM REC, V26, P32, DOI 10.1111/j.1477-9730.2011.00624.x.
   Xie WC, 2012, COMPUT AIDED DESIGN, V44, P1127, DOI 10.1016/j.cad.2012.05.004.
   Yakovleva N., 2010, PIPELINE DEV COMMUNI.
   Zheng G, 2012, INT J APPL EARTH OBS, V19, P226, DOI 10.1016/j.jag.2012.05.002.},
Number-of-Cited-References = {47},
Times-Cited = {43},
Usage-Count-Last-180-days = {5},
Usage-Count-Since-2013 = {55},
Journal-ISO = {J. Comput. Civil. Eng.},
Doc-Delivery-Number = {CK7ES},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000356395000005},
DA = {2023-08-12},
}

@article{ WOS:000618077800006,
Author = {Tavakoli, H. and Alirezazadeh, P. and Hedayatipour, A. and Nasib, A. H.
   Banijamali and Landwehr, N.},
Title = {Leaf image-based classification of some common bean cultivars using
   discriminative convolutional neural networks},
Journal = {COMPUTERS AND ELECTRONICS IN AGRICULTURE},
Year = {2021},
Volume = {181},
Month = {FEB},
Abstract = {In recent years, many efforts have been made to apply image processing
   techniques for plant leaf identification. However, categorizing leaf
   images at the cultivar/variety level, because of the very low
   inter-class variability, is still a challenging task. In this research,
   we propose an automatic discriminative method based on convolutional
   neural networks (CNNs) for classifying 12 different cultivars of common
   beans that belong to three various species. We show that employing
   advanced loss functions, such as Additive Angular Margin Loss and Large
   Margin Cosine Loss, instead of the standard softmax loss function for
   the classification can yield better discrimination between classes and
   thereby mitigate the problem of low inter-class variability. The method
   was evaluated by classifying species (level I), cultivars from the same
   species (level II), and cultivars from different species (level III),
   based on images from the leaf foreside and backside. The results
   indicate that the performance of the classification algorithm on the
   leaf backside image dataset is superior. The maximum mean classification
   accuracies of 95.86, 91.37 and 86.87\% were obtained at the levels I, II
   and III, respectively. The proposed method outperforms the previous
   relevant works and provides a reliable approach for plant cultivars
   identification.},
Publisher = {ELSEVIER SCI LTD},
Address = {THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Tavakoli, H (Corresponding Author), Leibniz Inst Agr Engn \& Bioecon eV ATB, Dept Engn Crop Prod, Max Eyth Allee 100, D-14469 Potsdam, Germany.
   Tavakoli, H., Leibniz Inst Agr Engn \& Bioecon eV ATB, Dept Engn Crop Prod, Max Eyth Allee 100, D-14469 Potsdam, Germany.
   Alirezazadeh, P.; Landwehr, N., Leibniz Inst Agr Engn \& Bioecon eV ATB, JRG Data Sci Agr, Max Eyth Allee 100, D-14469 Potsdam, Germany.
   Hedayatipour, A., Agr \& Nat Resources Res Ctr Markazi Prov, Arak 38135889, Iran.
   Nasib, A. H. Banijamali, Arak Univ, Dept Mech Engn Biosyst, Fac Agr, Arak 3815688349, Iran.
   Landwehr, N., Univ Potsdam, Dept Comp Sci, August Bebel Str 89, D-14482 Potsdam, Germany.},
DOI = {10.1016/j.compag.2020.105935},
Article-Number = {105935},
ISSN = {0168-1699},
EISSN = {1872-7107},
Keywords = {Bean; Plant identification; Digital image analysis; VGG16; Loss
   functions},
Keywords-Plus = {PLANT; IDENTIFICATION; RECOGNITION; FEATURES; TEXTURE; COLOR},
Research-Areas = {Agriculture; Computer Science},
Web-of-Science-Categories  = {Agriculture, Multidisciplinary; Computer Science, Interdisciplinary
   Applications},
Author-Email = {htavakoli@atb-potsdam.de},
Affiliations = {Leibniz Institut fur Agrartechnik und Biookonomie (ATB); Leibniz
   Institut fur Agrartechnik und Biookonomie (ATB); Arak University;
   University of Potsdam},
ORCID-Numbers = {Tavakoi, Hamed/0000-0002-6184-1765},
Cited-References = {Abadi M., 2016, TENSORFLOW LARGE SCA.
   Agarwal G, 2006, TAXON, V55, P597, DOI 10.2307/25065637.
   Barre P, 2017, ECOL INFORM, V40, P50, DOI 10.1016/j.ecoinf.2017.05.005.
   Chaki J, 2015, PATTERN RECOGN LETT, V58, P61, DOI 10.1016/j.patrec.2015.02.010.
   Champ J, 2016, PATTERN RECOGN LETT, V81, P71, DOI 10.1016/j.patrec.2016.05.022.
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848.
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482.
   Du JX, 2007, APPL MATH COMPUT, V185, P883, DOI 10.1016/j.amc.2006.07.072.
   Du JX, 2013, NEUROCOMPUTING, V116, P150, DOI 10.1016/j.neucom.2012.03.028.
   Dyrmann M, 2016, BIOSYST ENG, V151, P72, DOI 10.1016/j.biosystemseng.2016.08.024.
   Golzarian MR, 2011, PLANT METHODS, V7, DOI 10.1186/1746-4811-7-28.
   Grinblat GL, 2016, COMPUT ELECTRON AGR, V127, P418, DOI 10.1016/j.compag.2016.07.003.
   Hinton G., 2012, NEURAL INFORMAT, V25.
   Hu RX, 2012, IEEE T IMAGE PROCESS, V21, P4667, DOI 10.1109/TIP.2012.2207391.
   Ibaraki Y., 2014, PLANT IMAGE ANAL FUN.
   Kamilaris A, 2018, COMPUT ELECTRON AGR, V147, P70, DOI 10.1016/j.compag.2018.02.016.
   Kaya A, 2019, COMPUT ELECTRON AGR, V158, P20, DOI 10.1016/j.compag.2019.01.041.
   Larese MG, 2014, EXPERT SYST APPL, V41, P4638, DOI 10.1016/j.eswa.2014.01.029.
   Larese MG, 2014, PATTERN RECOGN, V47, P158, DOI 10.1016/j.patcog.2013.06.012.
   LeCun Yann, 1995, CONVOLUTIONAL NETWOR, V3361, P10.
   Liu NA, 2016, NEUROCOMPUTING, V216, P460, DOI 10.1016/j.neucom.2016.08.005.
   Liu WY, 2017, PROC CVPR IEEE, P6738, DOI 10.1109/CVPR.2017.713.
   Liu WY, 2016, PR MACH LEARN RES, V48.
   Neto JC, 2006, COMPUT ELECTRON AGR, V50, P121, DOI 10.1016/j.compag.2005.09.004.
   Osdaghi E, 2015, CROP PROT, V74, P37, DOI 10.1016/j.cropro.2015.04.002.
   Patil J. K., 2016, ENG AGR ENV FOOD, V10, P69, DOI DOI 10.1016/J.EAEF.2016.11.004.
   Pereira CS, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19224850.
   Perez AJ, 2000, COMPUT ELECTRON AGR, V25, P197, DOI 10.1016/S0168-1699(99)00068-X.
   Pydipati R, 2006, COMPUT ELECTRON AGR, V52, P49, DOI 10.1016/j.compag.2006.01.004.
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707.
   Sladojevic S, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3289801.
   Sole-Casals J, 2009, ADV SOFT COMP, V49, P243.
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244.
   Thyagharajan KK, 2019, ARCH COMPUT METHOD E, V26, P933, DOI 10.1007/s11831-018-9266-3.
   Turkoglu M, 2019, APPL MATH COMPUT, V352, P1, DOI 10.1016/j.amc.2019.01.054.
   Wang B, 2020, BIOSYST ENG, V194, P99, DOI 10.1016/j.biosystemseng.2020.03.019.
   Wang F, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1041, DOI 10.1145/3123266.3123359.
   Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552.
   Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180.
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7\_31.
   Yang HW, 2019, COMPUT ELECTRON AGR, V162, P739, DOI 10.1016/j.compag.2019.05.003.
   Yigit E, 2019, COMPUT ELECTRON AGR, V156, P369, DOI 10.1016/j.compag.2018.11.036.
   Zhong DX, 2020, IEEE T CIRC SYST VID, V30, P1559, DOI 10.1109/TCSVT.2019.2904283.},
Number-of-Cited-References = {43},
Times-Cited = {20},
Usage-Count-Last-180-days = {3},
Usage-Count-Since-2013 = {19},
Journal-ISO = {Comput. Electron. Agric.},
Doc-Delivery-Number = {QH2AA},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000618077800006},
DA = {2023-08-12},
}

@article{ WOS:000574101100002,
Author = {Goyal, Neha and Kumar, Nitin and Kapil},
Title = {On solving leaf classification using linear regression},
Journal = {MULTIMEDIA TOOLS AND APPLICATIONS},
Year = {2021},
Volume = {80},
Number = {3},
Pages = {4533-4551},
Month = {JAN},
Abstract = {Plant's conservation is getting close attention nowadays. It requires
   awareness about ecology among masses. Plant species identification has
   been proved as a primary step in literature for biodiversity
   conservation. It is a sequential process from leaf images as input
   followed by image enhancement algorithms, and feature extraction phase
   to classification. The complete process of identifying a leaf image
   requires substantial time. The article focuses on introducing a simpler
   and computationally inexpensive framework with a performance at par or
   better as compared to the existing framework. The article covers several
   findings and results while transforming the proposed framework for plant
   identification to a parameter specific optimized framework. The findings
   include optimizing the leaf image dimension, the impact of RGB to
   grayscale conversion method, and comparative analysis of the proposed
   framework for classification from images with other frameworks that
   first extract specific features and then classify. It also represents
   the whole framework as a regression problem. Further, improvement is
   incorporated by integrating the benefits of kernel trick in linear
   regression. Our finding confirms that the framework not only recognizing
   the leaf images with comparable accuracy but also reduces the
   computational time significantly to identify leaf images as compared to
   other frameworks.},
Publisher = {SPRINGER},
Address = {VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Goyal, N (Corresponding Author), NIT, Kurukshetra, Uttarakhand, India.
   Goyal, Neha; Kumar, Nitin; Kapil, NIT, Kurukshetra, Uttarakhand, India.},
DOI = {10.1007/s11042-020-09899-y},
EarlyAccessDate = {SEP 2020},
ISSN = {1380-7501},
EISSN = {1573-7721},
Keywords = {Linear regression; Kernel function; Color to gray-scale conversion;
   Image down-sampling; Image projection},
Keywords-Plus = {FEATURES},
Research-Areas = {Computer Science; Engineering},
Web-of-Science-Categories  = {Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory \& Methods; Engineering,
   Electrical \& Electronic},
Author-Email = {neha.goyal2309@gmail.com
   nitin@nituk.ac.in
   kapil@nitkkr.ac.in},
Affiliations = {National Institute of Technology (NIT System); National Institute of
   Technology Kurukshetra},
ResearcherID-Numbers = {Goyal, Neha/AAF-3497-2022
   Goyal, Neha/AFH-8800-2022
   },
ORCID-Numbers = {Goyal, Neha/0000-0002-7016-4663},
Funding-Acknowledgement = {University Grant Commission, India},
Funding-Text = {We acknowledge University Grant Commission, India for supporting this
   research by providing fellowship to one of the author, Ms. Neha Goyal.
   We are also thankful to the reviewers for their valuable and
   constructive comments and suggestions for the paper. Their inputs have
   helped us in strengthening the overall quality of the paper.},
Cited-References = {{[}Anonymous], 2007, 2007 IEEE INT S SIGN.
   Bagri N., 2015, INT J ADV SCI TECHNO, P41, DOI {[}DOI 10.14257/IJAST.2015.80.04, 10.14257/ijast.2015.80.04].
   Bruno OM, 2008, INFORM SCIENCES, V178, P2722, DOI 10.1016/j.ins.2008.01.023.
   Chen S, 2012, CROSS DISCIPLINARY B, P183.
   Corlett Richard T., 2016, Plant Diversity, V38, P10, DOI 10.1016/j.pld.2016.01.001.
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411.
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047\_33.
   Dikbas S, 2007, 2007 IEEE INT C IM P, V2.
   Du JX, 2007, APPL MATH COMPUT, V185, P883, DOI 10.1016/j.amc.2006.07.072.
   Ertugrul OF, 2015, INT J BIOMED DATA MI, P1.
   EVERITT BS, 1991, APPL MULTIVARIATE DA.
   Goettsch B, 2015, NAT PLANTS, V1, DOI {[}10.1038/NPLANTS.2015.142, 10.1038/nplants.2015.142].
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314.
   Hu RX, 2012, IEEE T IMAGE PROCESS, V21, P4667, DOI 10.1109/TIP.2012.2207391.
   Ja-Won Seo, 2013, 2013 IEEE INT C IM P.
   Jin ZM, 2015, MULTIDIM SYST SIGN P, V26, P869, DOI 10.1007/s11045-014-0295-2.
   Kadir Abdul, 2012, Journal of Theoretical and Applied Information Technology, V41, P82.
   Kulkarni A. H., 2013, INT J ADV RES COMPUT, V2, P984.
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41.
   Liu QG, 2017, MULTIMED TOOLS APPL, V76, P14055, DOI 10.1007/s11042-016-3748-9.
   Milan Sulc, 2014, EUR C COMP VIS.
   Munisami T, 2015, PROCEDIA COMPUT SCI, V58, P740, DOI 10.1016/j.procs.2015.08.095.
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128.
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076.
   Park J, 2008, J SYST SOFTWARE, V81, P71, DOI 10.1016/j.jss.2007.05.001.
   Pearline SA, 2019, J INTELL FUZZY SYST, V36, P1997, DOI 10.3233/JIFS-169911.
   Pimm SL, 2015, ANN MO BOT GARD, V100, P170, DOI 10.3417/2012018.
   Pornpanomchai C, 2011, THAI HERB LEAF IMAGE.
   Silva Pedro FB, 2013, INT C IM AN REC.
   Soderkvist O, 2001, COMPUTER VISION CLAS.
   Sowmya V, 2017, SIGNAL IMAGE VIDEO P, V11, P129, DOI 10.1007/s11760-016-0911-8.
   Tran D-T, 2014, P 5 S INF COMM TECHN.
   Tricot C, 1994, CURVES FRACTAL DIMEN.
   Turkoglu M, 2019, APPL MATH COMPUT, V352, P1, DOI 10.1016/j.amc.2019.01.054.
   Verma M, 2019, 2019 IEEE SECOND INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND KNOWLEDGE ENGINEERING (AIKE), P1, DOI 10.1109/AIKE.2019.00009.
   Waldchen J, 2018, METHODS ECOL EVOL, V9, P2216, DOI 10.1111/2041-210X.13075.
   Waldchen J, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1005993.
   Waldchen J, 2018, ARCH COMPUT METHOD E, V25, P507, DOI 10.1007/s11831-016-9206-z.
   Wang B, 2013, J MULTIMED, V8, P4.
   Yan J, 2006, INFORM SCIENCES, V176, P2042, DOI 10.1016/j.ins.2005.11.005.
   Yigit E, 2019, COMPUT ELECTRON AGR, V156, P369, DOI 10.1016/j.compag.2018.11.036.
   Zhang X, 2019, MULTIMED TOOLS APPL, V78, P27463, DOI 10.1007/s11042-019-07846-0.},
Number-of-Cited-References = {42},
Times-Cited = {6},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {7},
Journal-ISO = {Multimed. Tools Appl.},
Doc-Delivery-Number = {PS9RK},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000574101100002},
DA = {2023-08-12},
}

@article{ WOS:000737449300001,
Author = {Wang, Da and Li, Dongling and Fu, Li and Zheng, Yuhong and Gu, Yonghua
   and Chen, Fei and Zhao, Shichao},
Title = {Can Electrochemical Sensors Be Used for Identification and Phylogenetic
   Studies in Lamiaceae?},
Journal = {SENSORS},
Year = {2021},
Volume = {21},
Number = {24},
Month = {DEC},
Abstract = {Electrochemical sensors have shown potential in recent years for plant
   species identification and phylogenetic studies. These works have been
   used to investigate the affinities of different species in many genera.
   However, the ability of electrochemical sensors to study relationships
   between different genera within a family has not been investigated. In
   this work, we selected 31 species in the Labiatae and 5 exotaxa as
   subjects to investigate the feasibility of electrochemical sensors at
   the genus level. The results show that electrochemical sensors are still
   very effective for the identification of these plants. Different pattern
   recognition techniques can make the identification more efficient. Also,
   the fingerprint profiles collected by the sensors can be used for
   phylogenetic studies of Labiatae. The phylogram divides all the species
   into five clusters, where the exotaxa are in one cluster. Species in the
   Labiatae are mainly distributed in four other clusters. Importantly, the
   different genera of species all showed close affinities, representing
   that electrochemical fingerprinting can well distinguish the affinities
   between the different genera. The results of this work demonstrate the
   great potential of electrochemical sensors in the study of plant
   phylogeny. Its application is not limited to the study at the species
   level, but can be extended to the genus level.},
Publisher = {MDPI},
Address = {ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND},
Type = {Article},
Language = {English},
Affiliation = {Fu, L (Corresponding Author), Hangzhou Dianzi Univ, Coll Mat \& Environm Engn, Key Lab Novel Mat Sensor Zhejiang Prov, Hangzhou 310018, Peoples R China.
   Wang, Da; Fu, Li; Chen, Fei; Zhao, Shichao, Hangzhou Dianzi Univ, Coll Mat \& Environm Engn, Key Lab Novel Mat Sensor Zhejiang Prov, Hangzhou 310018, Peoples R China.
   Li, Dongling; Zheng, Yuhong; Gu, Yonghua, Inst Bot, Jiangsu Prov Platform Conservat \& Utilizat Agr Ge, Nanjing 210014, Jiangsu, Peoples R China.
   Li, Dongling; Zheng, Yuhong; Gu, Yonghua, Chinese Acad Sci, Nanjing Bot Garden Mem Sun Yat Sen, Nanjing 210014, Peoples R China.},
DOI = {10.3390/s21248216},
Article-Number = {8216},
EISSN = {1424-8220},
Keywords = {electrochemical sensor; Labiatae; plant identification; fingerprints;
   plant phylogeny},
Keywords-Plus = {ISODON LAMIACEAE; TRIBE MENTHEAE; VOLTAMMETRY; EVOLUTION; BIOGEOGRAPHY;
   RADIATION; TAXONOMY; ORIGIN; PLANT; L.},
Research-Areas = {Chemistry; Engineering; Instruments \& Instrumentation},
Web-of-Science-Categories  = {Chemistry, Analytical; Engineering, Electrical \& Electronic;
   Instruments \& Instrumentation},
Affiliations = {Hangzhou Dianzi University; Chinese Academy of Sciences},
ResearcherID-Numbers = {Zheng, Yu/GRJ-5808-2022
   },
ORCID-Numbers = {Fu, Li/0000-0002-5957-7790},
Funding-Acknowledgement = {National Natural Science Foundation of China {[}22004026]},
Funding-Text = {FundingThis research financially supported by the National Natural
   Science Foundation of China (22004026).},
Cited-References = {Ayaz A, 2020, GENETIKA-BELGRADE, V52, P435, DOI 10.2298/GENSR2002435A.
   Briquet J-L, 1989, POLITIX, V2, P6, DOI 10.3406/polix.1989.1392.
   Bunsawat J, 2004, SYST BOT, V29, P959, DOI 10.1600/0363644042450973.
   Ortiz AC, 2021, FORESTS, V12, DOI 10.3390/f12060703.
   Chen JX, 2021, MITOCHONDRIAL DNA B, V6, P1888, DOI 10.1080/23802359.2021.1934157.
   Chen YP, 2021, PLANT DIVERSITY, V43, P54, DOI 10.1016/j.pld.2020.06.004.
   Chen YP, 2019, SYST BOT, V44, P913, DOI 10.1600/036364419X15710776741486.
   Chen YP, 2016, TAXON, V65, P123, DOI 10.12705/651.8.
   Chiorcea-Paquim AM, 2020, COMPR REV FOOD SCI F, V19, P1680, DOI 10.1111/1541-4337.12566.
   Domenech-Carbo A, 2020, J ELECTROANAL CHEM, V877, DOI 10.1016/j.jelechem.2020.114494.
   Domenech-Carbo A, 2021, J SOLID STATE ELECTR, V25, P195, DOI 10.1007/s10008-020-04770-4.
   Domenech-Carbo A, 2017, ANAL METHODS-UK, V9, P2041, DOI {[}10.1039/C7AY00323D, 10.1039/c7ay00323d].
   Drew BT, 2013, BOT J LINN SOC, V171, P171, DOI 10.1111/j.1095-8339.2012.01325.x.
   Drew BT, 2012, AM J BOT, V99, P933, DOI 10.3732/ajb.1100549.
   Fan BY, 2021, BIOSENSORS-BASEL, V11, DOI 10.3390/bios11050155.
   Frezza C, 2021, BIOCHEM SYST ECOL, V96, DOI 10.1016/j.bse.2021.104247.
   Fu L, 2021, J HERB MED, V30, DOI 10.1016/j.hermed.2021.100512.
   Fu L, 2021, BIOELECTROCHEMISTRY, V140, DOI 10.1016/j.bioelechem.2021.107829.
   Fu L, 2020, FRONT CHEM, V8, DOI 10.3389/fchem.2020.00092.
   Fu L, 2018, BIOSENS BIOELECTRON, V120, P102, DOI 10.1016/j.bios.2018.08.052.
   Fu L, 2018, ELECTROCHEM COMMUN, V92, P39, DOI 10.1016/j.elecom.2018.05.018.
   Geng R, 2019, MOLECULES, V24, DOI 10.3390/molecules24010070.
   Grauso L, 2021, PHYTOCHEM REV, V20, P227, DOI 10.1007/s11101-020-09676-7.
   Karimi-Maleh H, 2022, CHEMOSPHERE, V291, DOI 10.1016/j.chemosphere.2021.132928.
   Karimi-Maleh H, 2022, J HAZARD MATER, V423, DOI 10.1016/j.jhazmat.2021.127058.
   Karpinski TM, 2020, BIOMOLECULES, V10, DOI 10.3390/biom10010103.
   Khanuja SPS, 2000, EUPHYTICA, V111, P121, DOI 10.1023/A:1003829512956.
   Liu SS, 2022, J AOAC INT, V105, P202, DOI 10.1093/jaoacint/qsab066.
   Macias FA, 2007, PHYTOCHEMISTRY, V68, P2917, DOI 10.1016/j.phytochem.2007.10.010.
   MURRAY MJ, 1972, CAN J GENET CYTOL, V14, P13, DOI 10.1139/g72-002.
   Novak I, 2013, ELECTROANAL, V25, P2631, DOI 10.1002/elan.201300410.
   Pulotova T, 1973, UZB BIOL ZH, V17, P17.
   Roma-Marzio F, 2017, PHYTOCHEMISTRY, V141, P48, DOI 10.1016/j.phytochem.2017.05.008.
   Thompson HJ, 2021, NUTRIENTS, V13, DOI 10.3390/nu13041295.
   TUCKER AO, 1991, ECON BOT, V45, P200, DOI 10.1007/BF02862048.
   Ullah F, 2019, PLANT SCI TODAY, V6, P373, DOI 10.14719/pst.2019.6.4.571.
   Wakawa AI, 2018, INT J PHYTOPHARM, V7, P464.
   Wang Y, 2021, MITOCHONDRIAL DNA B, V6, P89, DOI 10.1080/23802359.2020.1847617.
   Wang YY, 2020, ANAL SCI, V36, P1237, DOI 10.2116/analsci.20P079.
   Xu YT, 2020, BIOELECTROCHEMISTRY, V133, DOI 10.1016/j.bioelechem.2020.107455.
   Yang RT, 2020, MICROMACHINES-BASEL, V11, DOI 10.3390/mi11110967.
   Yu XQ, 2014, MOL PHYLOGENET EVOL, V77, P183, DOI 10.1016/j.ympev.2014.04.017.
   Zhang BM, 2018, CHIN J NAT MEDICINES, V16, P811, DOI 10.1016/S1875-5364(18)30123-7.
   Zhang X, 2020, REV MEX ING QUIM, V19, P281, DOI 10.24275/rmiq.Bio1750.
   Zhao F, 2020, INT J PLANT SCI, V181, P812, DOI 10.1086/710083.
   Zheng YH, 2021, BIOSENSORS-BASEL, V11, DOI 10.3390/bios11100403.
   Zhong JS, 2010, SYST BOT, V35, P207, DOI 10.1600/036364410790862614.
   Zhou JT, 2020, ANAL LETT, V53, P2517, DOI 10.1080/00032719.2020.1746327.
   Zimowska B, 2020, DIVERSITY-BASEL, V12, DOI 10.3390/d12020041.},
Number-of-Cited-References = {49},
Times-Cited = {29},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {8},
Journal-ISO = {Sensors},
Doc-Delivery-Number = {XZ1WA},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000737449300001},
OA = {gold, Green Published},
DA = {2023-08-12},
}

@article{ WOS:000227624300016,
Author = {Brown, RB and Noble, SD},
Title = {Site-specific weed management: sensing requirements - what do we need to
   see?},
Journal = {WEED SCIENCE},
Year = {2005},
Volume = {53},
Number = {2},
Pages = {252-258},
Month = {MAR-APR},
Note = {Symposium on Site-Specific Weed Management held at the Annual Conference
   of the Weed-Science-Society-of-America, Kansas City, MO, 2004},
Organization = {Weed Sci Soc Amer},
Abstract = {Automated detection and identification of weeds in crop fields is the
   greatest obstacle to development of practical site-specific weed
   management systems. Research progress is summarized for two different
   approaches to the problem, remote sensing weed mapping and ground-based
   detection using digital cameras or nonimaging sensors. The general
   spectral and spatial limitations reported for each type of weed
   identification system are reviewed. Airborne remote sensing has been
   successful for detection of distinct weed patches when the patches are
   dense and uniform and have unique spectral characteristics.
   Identification of weeds is hampered by spectral mixing in the relatively
   large pixels (typically larger than 1 by 1 m) and will not be possible
   from imagery where weed seedlings are sparsely distributed among crop
   plants. The use of multispectral imaging sensors such as color digital
   cameras on a ground-based mobile platform shows more promise for weed
   identification in field crops. Spectral features plus spatial features
   such as leaf shape and texture and plant organization may be extracted
   from these images. However, there is a need for research in areas such
   as artificial lighting, spectral band requirements, image processing,
   multiple spatial resolution systems, and multiperspective images.},
Publisher = {CAMBRIDGE UNIV PRESS},
Address = {32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA},
Type = {Article; Proceedings Paper},
Language = {English},
Affiliation = {Brown, RB (Corresponding Author), Univ Guelph, Sch Engn, Guelph, ON N1G 2W1, Canada.
   Univ Guelph, Sch Engn, Guelph, ON N1G 2W1, Canada.},
DOI = {10.1614/WS-04-068R1},
ISSN = {0043-1745},
EISSN = {1550-2759},
Keywords = {machine vision; remote sensing; site-specific; spectral reflectance;
   weed identification},
Keywords-Plus = {FRACTAL DIMENSION; PLANT-IDENTIFICATION; SPECTRAL PROPERTIES; IMAGE
   SEGMENTATION; MACHINE VISION; MAPPING WEEDS; DISCRIMINATION; SHAPE;
   LEAF; REFLECTANCE},
Research-Areas = {Agriculture; Plant Sciences},
Web-of-Science-Categories  = {Agronomy; Plant Sciences},
Author-Email = {rbbrown@uoguelph.ca},
Affiliations = {University of Guelph},
ORCID-Numbers = {Noble, Scott/0000-0003-4917-993X},
Cited-References = {Aitkenhead MJ, 2003, COMPUT ELECTRON AGR, V39, P157, DOI 10.1016/S0168-1699(03)00076-0.
   Apostol S, 2003, CAN J REMOTE SENS, V29, P57, DOI 10.5589/m02-076.
   Bajwa SG, 2001, T ASAE, V44, P1965, DOI 10.13031/2013.6995.
   BARON RJ, 2002, CSAE SCGR ANN M SASK.
   Blackshaw RE, 1998, WEED SCI, V46, P127, DOI 10.1017/S0043174500090287.
   Borkowski W, 1999, CAN J FOREST RES, V29, P1301, DOI 10.1139/cjfr-29-9-1301.
   Borregaard T, 2000, J AGR ENG RES, V75, P389, DOI 10.1006/jaer.1999.0519.
   BROWN RB, 1994, T ASAE, V37, P297, DOI 10.13031/2013.28084.
   BROWN RB, 1993, CANADIAN J REMOTE SE, V19, P88.
   Burks TF, 2002, WEED SCI, V50, P802, DOI 10.1614/0043-1745(2002)050{[}0802:IOWMLO]2.0.CO;2.
   CHAISATTAPAGON C, 1991, INT WINT M ST JOS MI.
   Chi YT, 2003, T ASAE, V46, P175.
   Cho SI, 2002, BIOSYST ENG, V83, P275, DOI 10.1006/bioe.2002.0117.
   Critten DL, 1997, J AGR ENG RES, V67, P61, DOI 10.1006/jaer.1997.0153.
   El-Faki MS, 2000, T ASAE, V43, P1969, DOI 10.13031/2013.3103.
   Elmore AJ, 2000, REMOTE SENS ENVIRON, V73, P87, DOI 10.1016/S0034-4257(00)00100-0.
   EVERITT JH, 1990, WEED SCI, V38, P273, DOI 10.1017/S0043174500056526.
   EVERITT JH, 1992, WEED SCI, V40, P621, DOI 10.1017/S0043174500058215.
   FELTON WL, 1992, AGR ENG, V73, P9.
   Feyaerts F, 2001, PATTERN RECOGN LETT, V22, P667, DOI 10.1016/S0167-8655(01)00006-X.
   Foroutan-Pour K, 2001, AGRON J, V93, P333, DOI 10.2134/agronj2001.932333x.
   FRANZ E, 1991, T ASAE, V34, P682.
   FRANZ E, 1991, T ASAE, V34, P673.
   GUYER DE, 1986, T ASAE, V29, P1500.
   GUYER DE, 1993, T ASAE, V36, P163.
   Hemming J, 2001, J AGR ENG RES, V78, P233, DOI 10.1006/jaer.2000.0639.
   Henry WB, 2004, WEED SCI, V52, P788, DOI 10.1614/WS-03-051R.
   Jurado-Exposito M, 2003, CROP PROT, V22, P1177, DOI 10.1016/S0261-2194(03)00159-5.
   Keranen Mika, 2003, Precision Agriculture, V4, P53, DOI 10.1023/A:1021863005378.
   KINCAID DT, 1983, CAN J BOT, V61, P2333, DOI 10.1139/b83-256.
   Lamb DW, 1998, WEED RES, V38, P443, DOI 10.1046/j.1365-3180.1998.00112.x.
   Lamb DW, 1999, WEED RES, V39, P481, DOI 10.1046/j.1365-3180.1999.00167.x.
   Lamb DW, 2001, J AGR ENG RES, V78, P117, DOI 10.1006/jaer.2000.0630.
   LANDGREBE D, 1986, BRIEF HIST LAB APPL.
   Manh AG, 2001, J AGR ENG RES, V80, P139, DOI 10.1006/jaer.2001.0725.
   McGwire K, 2000, REMOTE SENS ENVIRON, V72, P360, DOI 10.1016/S0034-4257(99)00112-1.
   Medlin CR, 2000, WEED SCI, V48, P393, DOI 10.1614/0043-1745(2000)048{[}0393:URSTDW]2.0.CO;2.
   MENGES RM, 1985, WEED SCI, V33, P569, DOI 10.1017/S0043174500082862.
   MERRIT SJ, 1994, 1994 INT SUMM M ST J.
   Moshou D., 2002, Precision Agriculture, V3, P209, DOI 10.1023/A:1015590520873.
   NOBLE SD, 2002, CSAE SCGR ANN M SASK.
   NOBLE SD, 2002, THESIS U SASKATCHEWA.
   Perez A. J., 1997, Proceedings First European Conference for Information Technology in Agriculture, P45.
   PRICE JC, 1994, REMOTE SENS ENVIRON, V49, P181, DOI 10.1016/0034-4257(94)90013-2.
   RAMON H, 2002, ASP APPL BIOL, V66, P147.
   REW LJ, 1997, ASPECTS APPL BIOL, V48, P49.
   SHEARER SA, 1990, T ASAE, V33, P2037.
   Shiraishi M, 1996, J MANUF SCI E-T ASME, V118, P382, DOI 10.1115/1.2831041.
   Tang L, 2000, T ASAE, V43, P1019, DOI 10.13031/2013.2970.
   VRINDTS E, 2000, AGENG 2000.
   VRINDTS E, 1997, P 1 EUR C PREC AGR W, V1, P537.
   Wang N, 2001, T ASAE, V44, P409, DOI 10.13031/2013.4673.
   Wang N, 2000, PROC SPIE, V4203, P63, DOI 10.1117/12.411740.
   Williams AP, 2002, REMOTE SENS ENVIRON, V82, P446, DOI 10.1016/S0034-4257(02)00061-5.
   Woebbecke D.M., 1992, OPTICS AGR FORESTRY, V1836, P208, DOI DOI 10.1117/12.144030.
   WOEBBECKE DM, 1995, T ASAE, V38, P271, DOI 10.13031/2013.27839.
   Zwiggelaar R, 1998, CROP PROT, V17, P189, DOI 10.1016/S0261-2194(98)00009-X.},
Number-of-Cited-References = {57},
Times-Cited = {73},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {23},
Journal-ISO = {Weed Sci.},
Doc-Delivery-Number = {906EW},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000227624300016},
DA = {2023-08-12},
}

@inproceedings{ WOS:000455620700034,
Author = {Gulac, Fatih and Bayazit, Ulug},
Editor = {Yildirim, T and Manolopoulos, Y and Angelov, P and Iliadis, L},
Title = {Plant and Phenology Recognition from Field Images Using Texture and
   Color Features},
Booktitle = {2018 INNOVATIONS IN INTELLIGENT SYSTEMS AND APPLICATIONS (INISTA)},
Year = {2018},
Note = {IEEE (SMC) International Conference on Innovations in Intelligent
   Systems and Applications (INISTA), Thessaloniki, GREECE, JUL 03-05, 2018},
Organization = {Aristotle Univ Thessaloniki; Democritus Univ Thrace; IEEE Systems \&
   Cybernet Soc; IEEE; Yildiz Techn Univ},
Abstract = {Determination of the phenological stages of plants is important for the
   growth of healthy and productive plants. The knowledge of transition
   times of phenological stages of a plant can provide valuable data for
   planning, organizing and timely execution of agricultural activities
   (spraying, irrigation etc.). TARBIL is an agricultural monitoring and
   information system that is founded and supported by Republic of Turkey
   Ministry of Food, Agriculture and Livestock. This system has a network
   of stations located in many parts of Turkey. Stations, that contain many
   sensors and cameras, periodically collect images and meteorological data
   from the agricultural fields. Previous works focus on either only about
   plant identification or only phenological stage recognition using only
   one texture analysis method. Our approachment to the problem is novel
   because not only the recognition of the plant type or the recognition of
   only the phenological stage, but also joint identification of the plant
   type and the phenological stages are provided with several texture and
   color feature analysis methods. In this work, a study is conducted to
   compare the use of several image texture features along with color
   features extracted from TARBIL field image data for the classification
   of the plants and their phenological stages. Experimental results show
   that HOG (Histograms of Oriented Gradients) yields the best performance
   among the texture features tested.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Gulac, F (Corresponding Author), Istanbul Tech Univ, Dept Comp Engn, Istanbul, Turkey.
   Gulac, Fatih; Bayazit, Ulug, Istanbul Tech Univ, Dept Comp Engn, Istanbul, Turkey.},
ISBN = {978-1-5386-5150-6},
Keywords = {agriculture; plant phenology; image processing; texture; color; feature
   descriptors},
Research-Areas = {Computer Science; Engineering},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science, Theory \&
   Methods; Engineering, Electrical \& Electronic},
Author-Email = {fgulac@itu.edu.tr
   ulugbayazit@itu.edu.tr},
Affiliations = {Istanbul Technical University},
ResearcherID-Numbers = {Bayazit, Ulug/ABB-2362-2020},
ORCID-Numbers = {Bayazit, Ulug/0000-0001-6556-4104},
Cited-References = {Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177.
   Durmus S, 2017, SIG PROCESS COMMUN.
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314.
   Kadir A, 2011, INT J COMPUTER TREND, P225, DOI DOI 10.48550/ARXIV.1401.4447.
   Pesaresi M, 2008, IEEE J-STARS, V1, P180, DOI 10.1109/JSTARS.2008.2002869.
   Stricker M., 1995, SPIE C STOR RETR IM, V2420.
   Syahputra Hermawan, 2014, Journal of Computer Science, V10, P697, DOI 10.3844/jcssp.2014.697.704.
   Vibhute A., 2012, INT J COMPUT APPL, V52, P34, DOI DOI 10.5120/8176-1495.
   Yalcin Hulya, 2015, 2015 Fourth International Conference on Agro-Geoinformatics (Agro-Geoinformatics), P338, DOI 10.1109/Agro-Geoinformatics.2015.7248114.},
Number-of-Cited-References = {9},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BL7TW},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000455620700034},
DA = {2023-08-12},
}

@article{ WOS:000415909100012,
Author = {Blomley, Rosmarie and Hovi, Aarne and Weinmann, Martin and Hinz, Stefan
   and Korpela, Ilkka and Jutzi, Boris},
Title = {Tree species classification using within crown localization of waveform
   LiDAR attributes},
Journal = {ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING},
Year = {2017},
Volume = {133},
Pages = {142-156},
Month = {NOV},
Abstract = {Since forest planning is increasingly taking an ecological,
   diversity-oriented perspective into account, remote sensing technologies
   are becoming ever more important in assessing existing resources with
   reduced manual effort. While the light detection and ranging (LiDAR)
   technology provides a good basis for predictions of tree height and
   biomass, tree species identification based on this type of data is
   particularly challenging in structurally heterogeneous forests. In this
   paper, we analyse existing approaches with respect to the geometrical
   scale of feature extraction (whole tree, within crown partitions or
   within laser footprint) and conclude that currently features are always
   extracted separately from the different scales. Since multi-scale
   approaches however have proven successful in other applications, we aim
   to utilize the within-tree-crown distribution of within-footprint signal
   characteristics as additional features. To do so, a spin image
   algorithm, originally devised for the extraction of 3D surface features
   in object recognition, is adapted. This algorithm relies on spinning an
   image plane around a defined axis, e.g. the tree stem, collecting the
   number of LiDAR returns or mean values of returns attributes per pixel
   as respective values. Based on this representation, spin image features
   are extracted that comprise only those components of highest variability
   among a given set of library trees. The relative performance and the
   combined improvement of these spin image features with respect to
   non-spatial statistical metrics of the waveform (WF) attributes are
   evaluated for the tree species classification of Scots pine (Pinus
   sylvestris L.), Norway spruce (Picea abies (L.) Karst.) and Silver/Downy
   birch (Betula pendula Roth/Betula pubescens Ehrh.) in a boreal forest
   environment. This evaluation is performed for two WF LiDAR datasets that
   differ in footprint size, pulse density at ground, laser wavelength and
   pulse width. Furthermore, we evaluate the robustness of the proposed
   method with respect to internal parameters and tree size. The results
   reveal, that the consideration of the crown-internal distribution of
   within-footprint signal characteristics captured in spin image features
   improves the classification results in nearly all test cases. (C) 2017
   International Society for Photogrammetry and Remote Sensing, Inc.
   (ISPRS). Published by Elsevier B.V. All rights reserved.},
Publisher = {ELSEVIER},
Address = {RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Blomley, R (Corresponding Author), Karlsruhe Inst Technol, Inst Photogrammetry \& Remote Sensing, Englerstr 7, D-76131 Karlsruhe, Germany.
   Blomley, Rosmarie; Weinmann, Martin; Hinz, Stefan; Jutzi, Boris, Karlsruhe Inst Technol, Inst Photogrammetry \& Remote Sensing, Englerstr 7, D-76131 Karlsruhe, Germany.
   Hovi, Aarne, Aalto Univ, Sch Engn, Dept Built Environm, POB 15800, Aalto 00076, Finland.
   Korpela, Ilkka, Univ Helsinki, Dept Forest Sci, POB 24, FIN-00014 Helsinki, Finland.},
DOI = {10.1016/j.isprsjprs.2017.08.013},
ISSN = {0924-2716},
EISSN = {1872-8235},
Keywords = {WF-recording LiDAR; Feature design; Geometric features; Multi-scale;
   Tree species; Classification},
Keywords-Plus = {LASER-SCANNING DATA; INDIVIDUAL TREES; AIRBORNE LIDAR; CONTEXTUAL
   CLASSIFICATION; FOREST; INTENSITY; SHAPE; IDENTIFICATION; VEGETATION;
   FEATURES},
Research-Areas = {Physical Geography; Geology; Remote Sensing; Imaging Science \&
   Photographic Technology},
Web-of-Science-Categories  = {Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science \& Photographic Technology},
Author-Email = {rosmarie.blomley@kit.edu},
Affiliations = {Helmholtz Association; Karlsruhe Institute of Technology; Aalto
   University; University of Helsinki},
ResearcherID-Numbers = {Hinz, Stefan/HDN-5781-2022
   },
ORCID-Numbers = {Hinz, Stefan/0000-0002-7323-9800
   Hovi, Aarne/0000-0002-4384-5279
   Weinmann, Martin/0000-0002-8654-7546},
Funding-Acknowledgement = {Carl-Zeiss-Stiftung (Nachwuchsforderprogramm); Academy of Finland;
   Metsahallitus; Metsamiesten saatio; TEKES; University of Helsinki;
   University of Eastern Finland},
Funding-Text = {The study was supported by the Carl-Zeiss-Stiftung
   (Nachwuchsforderprogramm 2014), the Academy of Finland, Metsahallitus,
   Metsamiesten saatio, TEKES, the University of Helsinki, and the
   strategic funds of the University of Eastern Finland. We thank Harri
   Hytonen, Timo Ketolainen, and the many forestry students for the field
   work.},
Cited-References = {Alves LF, 2002, J TROP ECOL, V18, P245, DOI 10.1017/S026646740200216X.
   {[}Anonymous], 2014, THE ISPRS ANN THE PH, DOI DOI 10.5194/ISPRSANNALS-II-3-111-2014.
   Armston J, 2013, REMOTE SENS ENVIRON, V134, P24, DOI 10.1016/j.rse.2013.02.021.
   Barilotti A., 2009, ISPRS ARCH 3, P129.
   Blomley R, 2016, ISPRS ANN PHOTO REM, V3, P169, DOI 10.5194/isprsannals-III-3-169-2016.
   Blomley R., 2017, P ISPRS GEOSP WEEK 2, P1.
   Brandtberg T, 2007, ISPRS J PHOTOGRAMM, V61, P325, DOI 10.1016/j.isprsjprs.2006.10.006.
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324.
   Brodu N, 2012, ISPRS J PHOTOGRAMM, V68, P121, DOI 10.1016/j.isprsjprs.2012.01.006.
   Chehata N., 2009, INT ARCH PHOTOGRAMME, V39, P207.
   Demantke J, 2011, INT ARCH PHOTOGRAMM, V38-5, P97.
   Disney MI, 2010, REMOTE SENS ENVIRON, V114, P1546, DOI 10.1016/j.rse.2010.02.009.
   Dong PL, 2009, INT J REMOTE SENS, V30, P6621, DOI 10.1080/01431160903140761.
   Frome A, 2004, LECT NOTES COMPUT SC, V3023, P224.
   GATZIOLIS D, 2009, P SILV 2009 C COLL S.
   Gressin A, 2012, ISPRS ANN PHOTOGRAMM, V1-3, P111, DOI DOI 10.5194/ISPRSANNALS-I-3-111-2012.
   Hancock S, 2015, REMOTE SENS ENVIRON, V164, P208, DOI 10.1016/j.rse.2015.04.013.
   Hancock S, 2012, AGR FOREST METEOROL, V161, P123, DOI 10.1016/j.agrformet.2012.03.014.
   Heinzel J, 2011, INT J APPL EARTH OBS, V13, P152, DOI 10.1016/j.jag.2010.09.010.
   Holmgren J, 2008, INT J REMOTE SENS, V29, P1537, DOI 10.1080/01431160701736471.
   Holmgren J, 2004, REMOTE SENS ENVIRON, V90, P415, DOI 10.1016/S0034-4257(03)00140-8.
   Hovi A, 2016, REMOTE SENS ENVIRON, V173, P224, DOI 10.1016/j.rse.2015.08.019.
   Hovi A, 2014, REMOTE SENS ENVIRON, V140, P665, DOI 10.1016/j.rse.2013.10.003.
   HUGHES GF, 1968, IEEE T INFORM THEORY, V14, P55, DOI 10.1109/TIT.1968.1054102.
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655.
   Junninen H, 2009, BOREAL ENVIRON RES, V14, P447.
   Jutzi B, 2006, ISPRS J PHOTOGRAMM, V61, P95, DOI 10.1016/j.isprsjprs.2006.09.001.
   Kandare K., 2017, REMOTE SENS, V9, P1.
   Kato A, 2009, REMOTE SENS ENVIRON, V113, P1148, DOI 10.1016/j.rse.2009.02.010.
   Kim S, 2011, REMOTE SENS ENVIRON, V115, P3329, DOI 10.1016/j.rse.2011.07.016.
   Kim S, 2009, REMOTE SENS ENVIRON, V113, P1575, DOI 10.1016/j.rse.2009.03.017.
   Ko C., 2012, ISPRS ANN PHOTOGRAMM, V1, P129.
   Ko C, 2013, CAN J REMOTE SENS, V39, pS73, DOI 10.5589/m13-024.
   Koike T, 2001, TREE PHYSIOL, V21, P951, DOI 10.1093/treephys/21.12-13.951.
   Korpela I, 2006, SILVA FENN, V40, P109, DOI 10.14214/sf.355.
   Korpela I, 2004, SILVA FENN, P1.
   Korpela I, 2007, SILVA FENN, V41, P457, DOI 10.14214/sf.283.
   Korpela I, 2013, ISPRS J PHOTOGRAMM, V83, P81, DOI 10.1016/j.isprsjprs.2013.06.002.
   Korpela I, 2011, REMOTE SENS ENVIRON, V115, P2062, DOI 10.1016/j.rse.2011.04.008.
   Korpela I, 2010, ISPRS J PHOTOGRAMM, V65, P369, DOI 10.1016/j.isprsjprs.2010.04.003.
   Korpela I, 2010, SILVA FENN, V44, P319, DOI 10.14214/sf.156.
   Korpela IS, 2008, REMOTE SENS ENVIRON, V112, P3891, DOI 10.1016/j.rse.2008.06.007.
   Li JL, 2013, AGR FOREST METEOROL, V171, P104, DOI 10.1016/j.agrformet.2012.11.012.
   Lindberg E, 2012, REMOTE SENS ENVIRON, V118, P151, DOI 10.1016/j.rse.2011.11.015.
   Litkey P., 2007, PROC ISPRS WORKSHOP, P258.
   Mallet C, 2011, ISPRS J PHOTOGRAMM, V66, pS71, DOI 10.1016/j.isprsjprs.2011.09.008.
   Mallet C, 2009, ISPRS J PHOTOGRAMM, V64, P1, DOI 10.1016/j.isprsjprs.2008.09.007.
   MATTHECK CI, 1991, TREES MECH DESIGN.
   Menalled FD, 2001, PLANT ECOL, V152, P1, DOI 10.1023/A:1011495916036.
   Morsdorf F, 2004, REMOTE SENS ENVIRON, V92, P353, DOI 10.1016/j.rse.2004.05.013.
   Morsdorf F, 2009, REMOTE SENS ENVIRON, V113, P2152, DOI 10.1016/j.rse.2009.05.019.
   Neuenschwander AL, 2009, J APPL REMOTE SENS, V3, DOI 10.1117/1.3229944.
   Ni-Meister W, 2001, IEEE T GEOSCI REMOTE, V39, P1943, DOI 10.1109/36.951085.
   Niemeyer J, 2014, ISPRS J PHOTOGRAMM, V87, P152, DOI 10.1016/j.isprsjprs.2013.11.001.
   Orka HO, 2012, CAN J REMOTE SENS, V38, P125, DOI 10.5589/m12-021.
   Orka HO, 2009, REMOTE SENS ENVIRON, V113, P1163, DOI 10.1016/j.rse.2009.02.002.
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648.
   Packalen P, 2008, CAN J FOREST RES, V38, P1750, DOI 10.1139/X08-037.
   Persson A, 2002, PHOTOGRAMM ENG REM S, V68, P925.
   Persson A., 2005, P ISPRS WORKSH LAS S, P228.
   Popescu SC, 2008, REMOTE SENS ENVIRON, V112, P767, DOI 10.1016/j.rse.2007.06.011.
   Puttonen E, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.00222.
   Raty J, 2016, FOR ECOSYST, V3, DOI 10.1186/s40663-016-0060-0.
   Reitberger J, 2008, INT J REMOTE SENS, V29, P1407, DOI 10.1080/01431160701736448.
   Reitberger J, 2009, ISPRS J PHOTOGRAMM, V64, P561, DOI 10.1016/j.isprsjprs.2009.04.002.
   Richter K, 2015, ISPRS ANN PHOTO REM, VII-3, P65, DOI 10.5194/isprsannals-II-3-W5-65-2015.
   Romanczyk P., 2015, THESIS.
   Rusu RB, 2009, IEEE INT CONF ROBOT, P1848.
   Schindler K, 2012, IEEE T GEOSCI REMOTE, V50, P4534, DOI 10.1109/TGRS.2012.2192741.
   Schmidt A, 2014, IEEE GEOSCI REMOTE S, V11, P1614, DOI 10.1109/LGRS.2014.2302317.
   SchUlkopf B., 1997, SUPPORT VECTOR LEARN.
   STRAHLER AH, 1986, REMOTE SENS ENVIRON, V20, P121, DOI 10.1016/0034-4257(86)90018-0.
   Strimbu VF, 2015, ISPRS J PHOTOGRAMM, V104, P30, DOI 10.1016/j.isprsjprs.2015.01.018.
   Suratno A, 2009, ISPRS J PHOTOGRAMM, V64, P683, DOI 10.1016/j.isprsjprs.2009.07.001.
   Tombari F, 2010, LECT NOTES COMPUT SC, V6313, P356, DOI 10.1007/978-3-642-15558-1\_26.
   Vauhkonen J, 2014, MANAG FOR ECOSYST, V27, P135, DOI 10.1007/978-94-017-8663-8\_7.
   Vauhkonen J, 2014, ISPRS J PHOTOGRAMM, V96, P57, DOI 10.1016/j.isprsjprs.2014.07.001.
   Vauhkonen J, 2012, FORESTRY, V85, P27, DOI 10.1093/forestry/cpr051.
   Vauhkonen J, 2010, REMOTE SENS ENVIRON, V114, P1263, DOI 10.1016/j.rse.2010.01.016.
   Vauhkonen J, 2009, FOREST SCI, V55, P37.
   Velizhev A., 2012, INT SOC PHOT REM SEN, V2, DOI DOI 10.5194/ISPRSANNALS-I-3-179-2012.
   Vosselman G., 2004, ISPRS 2004 P ISPRS W, V46, P33.
   Wagner W, 2006, ISPRS J PHOTOGRAMM, V60, P100, DOI 10.1016/j.isprsjprs.2005.12.001.
   Weinmann M., 2017, ISPRS ANN PHOTOGRAMM, V10, P313, DOI {[}DOI 10.5194/ISPRSANNALS-II-5-W2-313-2013, 10.5194/isprsannals-II-5-W2-313-2013].
   Weinmann M, 2015, ISPRS J PHOTOGRAMM, V105, P286, DOI 10.1016/j.isprsjprs.2015.01.016.
   West KF, 2004, P SOC PHOTO-OPT INS, V5426, P133, DOI 10.1117/12.542536.
   Yao W, 2012, REMOTE SENS ENVIRON, V123, P368, DOI 10.1016/j.rse.2012.03.027.
   Yu XW, 2014, FORESTS, V5, P1011, DOI 10.3390/f5051011.},
Number-of-Cited-References = {88},
Times-Cited = {23},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {36},
Journal-ISO = {ISPRS-J. Photogramm. Remote Sens.},
Doc-Delivery-Number = {FN3OQ},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000415909100012},
DA = {2023-08-12},
}

@article{ WOS:000892785000005,
Author = {Li, Qianxia and Yan, Lihui and Huang, Denghong and Zhou, Zhongfa and
   Zhang, Yang and Xiao, Dongna},
Title = {Construction of a small sample dataset and identification of Pitaya
   trees (Selenicereus) based on UAV image on close-range acquisition},
Journal = {JOURNAL OF APPLIED REMOTE SENSING},
Year = {2022},
Volume = {16},
Number = {2},
Month = {APR 1},
Abstract = {Rapid and accurate crop information extraction is important for detailed
   agricultural management and efficient yield estimation. However, the
   natural environment of the Karst Plateau in southwest China is fragile,
   the ground surface is broken, and the weather is complex and cloudy,
   making it difficult to obtain high-quality crop samples for crop
   information extraction in this complex environment. We obtained images
   of Pitaya trees from plateau mountain environments using DJI Mavic 2 Pro
   UAV, constructed a small UAV close-range acquisition sample dataset,
   which included initial, supplementary, and augmented datasets, covering
   samples in complex natural scenes such as twining vines, weed and tree
   cover, blurred images, and shadows. We studied the influence of complex
   scenes on the extraction accuracy of Pitaya trees using the U-Net model
   to accurately delineate Pitaya trees in complex UAV images. The results
   show: (1) the U-Net model trained by the augmented dataset had the
   highest recognition precision of 99.20\% for Pitaya trees, F1-score of
   96.66\%, and Kappa coefficient of 0.91. (2) The number of samples and
   the complexity of land types had strong impact on the recognition
   accuracy. From 200 to 21,593 samples, the accuracy of the recognition
   results, F1-score and Kappa coefficient increased by 17.47\%, 17.95\%,
   and 0.26\%, respectively. Moreover, the missed detection rate
   significantly decreased (18.27\% to 0.80\%), the false alarm rate
   (5.36\% to 1.04\%). (3) When the sample types were increased from 1 to
   10, the learning of sample features by the U-Net model, including
   shadows, blurred images, and twining vines, was strengthened. This
   enhanced the robustness and generalization ability of the model. The
   small sample dataset in this study meets the requirements of identifying
   and extracting information for Pitaya trees from the background of the
   rugged terrain and complex features in plateau and mountain areas. (c)
   2022 Society of Photo-Optical Instrumentation Engineers (SPIE)},
Publisher = {SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS},
Address = {1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA},
Type = {Article},
Language = {English},
Affiliation = {Zhou, ZF (Corresponding Author), Guizhou Normal Univ, Sch Karst Sci, Sch Geog \& Environm Sci, Guiyang, Peoples R China.
   Zhou, ZF (Corresponding Author), State Engn Technol Inst Karst Desertificat Contr, Guiyang, Peoples R China.
   Li, Qianxia; Yan, Lihui; Huang, Denghong; Zhou, Zhongfa; Zhang, Yang; Xiao, Dongna, Guizhou Normal Univ, Sch Karst Sci, Sch Geog \& Environm Sci, Guiyang, Peoples R China.
   Li, Qianxia; Yan, Lihui; Huang, Denghong; Zhou, Zhongfa, State Engn Technol Inst Karst Desertificat Contr, Guiyang, Peoples R China.},
DOI = {10.1117/1.JRS.16.024502},
Article-Number = {024502},
EISSN = {1931-3195},
Keywords = {UAV close-range acquisition; small sample dataset; Pitaya tree; plant
   recognition; U-net deep learning network model; Plateau Mountain},
Keywords-Plus = {CLASSIFICATION},
Research-Areas = {Environmental Sciences \& Ecology; Remote Sensing; Imaging Science \&
   Photographic Technology},
Web-of-Science-Categories  = {Environmental Sciences; Remote Sensing; Imaging Science \& Photographic
   Technology},
Author-Email = {fa6897@163.com},
Affiliations = {Guizhou Normal University},
ResearcherID-Numbers = {Liu, Yujie/IWU-6535-2023
   Zhang, Yunxuan/IXD-9283-2023
   zhang, yuyang/IVV-5089-2023},
ORCID-Numbers = {Liu, Yujie/0000-0002-1153-6156
   },
Funding-Acknowledgement = {National Natural Science Foundation of China {[}41661088]; Science and
   Technology Foundation of Guizhou Province {[}ZK {[}2021] General 194];
   Guizhou Normal University {[}GZNUD{[}2018]28]; Major Special Project of
   Guizhou Science and Technology {[}{[}2013]6024]},
Funding-Text = {This work was supported by National Natural Science Foundation of China
   (41661088); the Science and Technology Foundation of Guizhou Province
   (ZK {[}2021] General 194); the Doctoral Research Project supported by
   Guizhou Normal University (GZNUD{[}2018]28); and Major Special Project
   of Guizhou Science and Technology {[}2013]6024. The authors declare no
   conflicts of interest.},
Cited-References = {Adhikari SP, 2019, FRONT PLANT SCI, V10, DOI 10.3389/fpls.2019.01404.
   {[}Anonymous], CIFAR 10 CIFAR 100 D.
   {[}白洋 Bai Yang], 2020, {[}测绘通报, Bulletin of Surveying and Mapping], P85.
   Chebrolu N, 2017, INT J ROBOT RES, V36, P1045, DOI 10.1177/0278364917720510.
   Cong M, 2022, GEOCARTO INT, V37, P3116, DOI 10.1080/10106049.2020.1852614.
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848.
   Freudenberg M, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030312.
   {[}韩蕊 Han Rui], 2021, {[}林业工程学报, Journal of Forestry Engineering], V6, P147.
   Haug S, 2015, LECT NOTES COMPUT SC, V8928, P105, DOI {[}10.1007/978-3-319-16220-1-8, 10.1007/978-3-319-16220-1\_8].
   Huang DH, 2021, J APPL REMOTE SENS, V15, DOI 10.1117/1.JRS.15.042402.
   Jin X, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13091853.
   Khan A, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9101602.
   Kwak GH, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9040643.
   Li HG, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9050441.
   Li X., 2020, J AGR MACH, V51, P144.
   Liakos KG, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082674.
   {[}廖娟 Liao Juan], 2021, {[}农业机械学报, Transactions of the Chinese Society for Agricultural Machinery], V52, P171.
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1\_48.
   Ma X, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0215676.
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79.
   Oh S, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12182981.
   Osco LP, 2021, PRECIS AGRIC, V22, P1171, DOI 10.1007/s11119-020-09777-5.
   Potgieter AB, 2017, FRONT PLANT SCI, V8, DOI 10.3389/fpls.2017.01532.
   Pound MP, 2017, GIGASCIENCE, V6, DOI 10.1093/gigascience/gix083.
   Romera-Paredes B, 2016, LECT NOTES COMPUT SC, V9910, P312, DOI 10.1007/978-3-319-46466-4\_19.
   Ronneberger O., 2015, P INT C MED IM COMP, DOI DOI 10.1007/978-3-319-24574-4\_28.
   Sa I, 2018, IEEE ROBOT AUTOM LET, V3, P588, DOI 10.1109/LRA.2017.2774979.
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0.
   Song ZS, 2020, COMPUT ELECTRON AGR, V179, DOI 10.1016/j.compag.2020.105812.
   Tatsumi K, 2015, COMPUT ELECTRON AGR, V115, P171, DOI 10.1016/j.compag.2015.05.001.
   Tian YouWen, 2007, Transactions of the Chinese Society of Agricultural Engineering, V23, P175.
   {[}王施云 Wang Shiyun], 2021, {[}计算机科学, Computer Science], V48, P162.
   Wei SS, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11010068.
   Wu JT, 2020, COMPUT ELECTRON AGR, V174, DOI 10.1016/j.compag.2020.105504.
   Xiong X, 2017, PLANT METHODS, V13, DOI 10.1186/s13007-017-0254-7.
   {[}严恩萍 Yan Enping], 2021, {[}农业工程学报, Transactions of the Chinese Society of Agricultural Engineering], V37, P39.
   Yang CY, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185354.
   Yang GJ, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9070642.
   Yang MD, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13071358.
   Yang MD, 2020, COMPUT ELECTRON AGR, V179, DOI 10.1016/j.compag.2020.105817.
   Yang MD, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12040633.
   Yang MD, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9060583.
   Yuan M, 2019, REMOTE SENS LETT, V10, P506, DOI 10.1080/2150704X.2019.1574990.
   Yue JB, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9070708.
   Zhang CH, 2012, PRECIS AGRIC, V13, P693, DOI 10.1007/s11119-012-9274-5.
   {[}张振军 ZHANG Zhenjun], 2007, {[}测绘通报, Bulletin of Surveying and Mapping], P26.
   Zhou DB, 2020, ISPRS INT J GEO-INF, V9, DOI 10.3390/ijgi9120728.
   {[}朱孟 Zhu Meng], 2019, {[}热带地理, Tropical Geography], V39, P502.
   Zou KL, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13020310.},
Number-of-Cited-References = {49},
Times-Cited = {1},
Usage-Count-Last-180-days = {15},
Usage-Count-Since-2013 = {15},
Journal-ISO = {J. Appl. Remote Sens.},
Doc-Delivery-Number = {6S1WI},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000892785000005},
DA = {2023-08-12},
}

@article{ WOS:000456754100036,
Author = {Yigit, Enes and Sabanci, Kadir and Toktas, Abdurrahim and Kayabasi,
   Ahmet},
Title = {A study on visual features of leaves in plant identification using
   artificial intelligence techniques},
Journal = {COMPUTERS AND ELECTRONICS IN AGRICULTURE},
Year = {2019},
Volume = {156},
Pages = {369-377},
Month = {JAN},
Abstract = {In this paper, artificial intelligence techniques (AIT) such as
   artificial neural network, naive bayes algorithm, random forest
   algorithm, K-nearest neighborhood (KNN) and support vector machine (SVM)
   are implemented to design an automatic identifier for the plant leaves.
   For this purpose, data of 637 healthy leaves consisting of 32 different
   plant species are used. 22 visual features (VF) of each leaf are
   extracted by using image processing techniques. These 22 VF are
   considered in 4 groups including dimension (D\#6), color (C\#6), texture
   (T\#5) and pattern (P\#5). In order to investigate the effects of these
   groups on the classifying performance, 15 possible different
   combinations from the 4 groups are constituted. The models are then
   trained via the data of 510 leaves, and their accuracy are tested
   through the data of 127 leaves. From the results of the test, SVM model
   with the accuracy of 92.91\% is found to be the most successful
   identifier for combination including all groups. The next best result is
   achieved with the accuracy of 87.40\% for the combination of D\#6, C\#6
   and P\#5 groups. Since the most important issue in the classification
   process is the use of the minimum number of VF, 16 most effective VF on
   the identification are determined by means of correlation-based feature
   selection (CFS) method. The best result for these 16 VF is also achieved
   with the accuracy of 94.49\% by the SVM model. Then the performance of
   the proposed method is tested to identify the diseased and defected
   leaves. Therefore, 637 healthy and 33 diseased/defected leaves are put
   together. Randomly selected 536 leaves corresponding to 80\% of all
   leaves are used for training and the remaining 134 leaves are used for
   testing, and identified with the accuracy of 92.53\% by the SVM model.
   With this study, it is numerically revealed that the P\#5 is the most
   effective feature group. Moreover, it has been determined that the most
   effective feature in the P\#5 group is the feature of edge Fourier
   transform. The results point out that, if An' models are properly
   modelled and trained, they can be successfully and effectively applied
   to the identification of the plants even if there are diseased and
   defected samples.},
Publisher = {ELSEVIER SCI LTD},
Address = {THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Yigit, E (Corresponding Author), Karamanoglu Mehmetbey Univ, Dept Elect Elect Engn, Engn Fac, TR-70100 Karaman, Turkey.
   Yigit, Enes; Sabanci, Kadir; Toktas, Abdurrahim; Kayabasi, Ahmet, Karamanoglu Mehmetbey Univ, Dept Elect Elect Engn, Engn Fac, TR-70100 Karaman, Turkey.},
DOI = {10.1016/j.compag.2018.11.036},
ISSN = {0168-1699},
EISSN = {1872-7107},
Keywords = {Plant species; Identification; Image processing technique; Artificial
   intelligence techniques; Fourier Transform},
Keywords-Plus = {SHAPE},
Research-Areas = {Agriculture; Computer Science},
Web-of-Science-Categories  = {Agriculture, Multidisciplinary; Computer Science, Interdisciplinary
   Applications},
Author-Email = {enesyigit@kmu.edu.tr},
Affiliations = {Karamanoglu Mehmetbey University},
ResearcherID-Numbers = {SABANCI, Kadir/AAK-5215-2021
   Toktas, Abdurrahim/D-7354-2015
   Kayabasi, Ahmet/V-4093-2017
   },
ORCID-Numbers = {SABANCI, Kadir/0000-0003-0238-9606
   Toktas, Abdurrahim/0000-0002-7687-9061
   Kayabasi, Ahmet/0000-0002-9756-8756
   yigit, Enes/0000-0002-0960-5335},
Cited-References = {{[}Anonymous], P EUR C COMP VIS SEP.
   {[}Anonymous], 1999, PHD THESIS.
   {[}Anonymous], 2013, ARXIV14014447.
   {[}Anonymous], DIGITAL IMAGE PROCES.
   Arun C, 2017, JURNAL ILMU KOMPUTER, V10, P19, DOI {[}10.21609/jiki.v10i1.405, DOI 10.21609/JIKI.V10I1.405].
   Bakhshipour A, 2018, COMPUT ELECTRON AGR, V145, P153, DOI 10.1016/j.compag.2017.12.032.
   Beghin T, 2010, LECT NOTES COMPUT SC, V6475, P345, DOI 10.1007/978-3-642-17691-3\_32.
   Christianini N., 2000, INTRO SUPPORT VECTOR.
   Grinblat GL, 2016, COMPUT ELECTRON AGR, V127, P418, DOI 10.1016/j.compag.2016.07.003.
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314.
   Hu RX, 2012, IEEE T IMAGE PROCESS, V21, P4667, DOI 10.1109/TIP.2012.2207391.
   Jie L, 2011, PROCEDIA ENG, V23, P504, DOI DOI 10.1016/J.PR0ENG.2011.11.
   Karegowda AG, 2010, INT J INF TECHNOL KN, V2, P271.
   Kazmi W, 2015, COMPUT ELECTRON AGR, V118, P290, DOI 10.1016/j.compag.2015.08.023.
   Kumar N, 2012, LECT NOTES COMPUT SC, V7573, P502, DOI 10.1007/978-3-642-33709-3\_36.
   Lagar-Cavilla H. A., 2009, 2012 INT C DIG IM CO, P1, DOI DOI 10.1109/DICTA.2012.6411702.
   Munisami T, 2015, PROCEDIA COMPUT SCI, V58, P740, DOI 10.1016/j.procs.2015.08.095.
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076.
   Ozkan I.A., 2017, INT J INTELL SYST AP, V5, P285, DOI {[}10.18201/ijisae.2017534420, DOI 10.18201/IJISAE.2017534420].
   Pawara P, 2017, LECT NOTES COMPUT SC, V10617, P615, DOI 10.1007/978-3-319-70353-4\_52.
   Piramli MM., 2016, J TELECOMMUN ELECT C, V8, P23.
   Raid AM., 2014, INT J COMPUT SCI ENG, V4, P9, DOI DOI 10.5121/IJCSEIT.2014.4302.
   Sabanci K, 2017, J SCI FOOD AGR, V97, P2588, DOI 10.1002/jsfa.8080.
   Schroff F., 2008, BMVC.
   Sladojevic S, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3289801.
   Yasar A., 2015, INT J INTELLIGENT SY, V3, P136, DOI {[}DOI 10.18201/IJISAE.49279, 10.18201/ijisae.49279].
   Yigit E., 2018, INT J INTELLIGENT SY, V1, P29, DOI {[}10.18201/ijisae.2018637927, DOI 10.18201/IJISAE.2018637927].
   Zhao C, 2015, PATTERN RECOGN, V48, P3203, DOI 10.1016/j.patcog.2015.04.004.},
Number-of-Cited-References = {28},
Times-Cited = {34},
Usage-Count-Last-180-days = {3},
Usage-Count-Since-2013 = {18},
Journal-ISO = {Comput. Electron. Agric.},
Doc-Delivery-Number = {HI9CY},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000456754100036},
DA = {2023-08-12},
}

@article{ WOS:A1995RE89100037,
Author = {ZHANG, N and CHAISATTAPAGON, C},
Title = {EFFECTIVE CRITERIA FOR WEED IDENTIFICATION IN WHEAT FIELDS USING MACHINE
   VISION},
Journal = {TRANSACTIONS OF THE ASAE},
Year = {1995},
Volume = {38},
Number = {3},
Pages = {965-974},
Month = {MAY-JUN},
Abstract = {A machine vision system was used to identify weeds commonly found in
   Kansas wheat fields, including Russian thistle, redroot pigweed, Palmer
   amaranth, wild buckwheat, and kochia. Three different approaches, color
   analysis, shape analysis, and texture analysis, were used in the study.
   For the color analysis approach, ratios of pixel gray levels in images
   taken using four selected color filters were useful in classifying
   pixels into five different categories-wheat leaf weed leaf, weed stem,
   soil, and sand. A red/green filter pair was found effective in
   identifying reddish stems of redroot pigweed, Russian thistle, and
   kochia. Five shape parameters, eccentricity, compactness, and three
   invariant moments, were used in leaf shape studies and were found
   effective in distinguishing broadleaf weed species such as redroot
   pigweed, wild buckwheat, and kochia from wheat. For the texture analysis
   approach, Fourier spectra of selected windows within leaf areas of wheat
   and weed species were analyzed. An index of fineness was defined using
   the spectra. Leaves with fine textures such as kochia can be
   distinguished from others using this index. Curves of normalized radial
   spectral energy were derived from the spectra. Leaves with distinct
   directionality features such as wheat and some broadleaf weed species
   can be distinguished using parameters defined using these curves. This
   study is the first step of a project with an overall goal of developing
   techniques of selective herbicide application based on weed defection.},
Publisher = {AMER SOC AGR ENGINEERS},
Address = {2950 NILES RD, ST JOSEPH, MI 49085-9659},
Type = {Article},
Language = {English},
Affiliation = {ZHANG, N (Corresponding Author), KANSAS STATE UNIV AGR \& APPL SCI,DEPT BIOL \& AGR ENGN,MANHATTAN,KS 66506, USA.},
ISSN = {0001-2351},
Keywords = {WEEDS; MACHINE VISION; IMAGE PROCESSING; IDENTIFICATION; WHEAT;
   HERBICIDES},
Keywords-Plus = {PLANT-IDENTIFICATION},
Research-Areas = {Agriculture},
Web-of-Science-Categories  = {Agricultural Engineering},
Cited-References = {{[}Anonymous], WHEAT.
   {[}Anonymous], 1985, VISION MAN MACHINE.
   BOWERS SA, 1964, SOIL SCI, V100, P130.
   BROWN RB, 1990, ASAE901061 PAP.
   BROWN RB, 1991, ASAE911050 PAP.
   CHANDLER JM, 1984, CROP LOSS DUE WEEDS.
   CIPRA JE, 1971, SOIL SCI SOC AM PRO, V35, P1014, DOI 10.2136/sssaj1971.03615995003500060043x.
   ELACHI C, 1987, INTRO PHYSICS TECHNI.
   FELTON WL, 1991, AUTOMATED AGR 21 CEN, P427.
   FRANZ E, 1990, ASAE907040 PAP.
   FRANZ E, 1990, ASAE907044 PAP.
   Gonzalez RC., 1992, DIGITAL IMAGE PROCES.
   GUYER DE, 1986, T ASAE, V29, P1500.
   HAN YJ, 1990, T ASAE, V33, P1402, DOI 10.13031/2013.31486.
   HAN YJ, 1988, ASAE882540 PAP.
   HAYES JC, 1989, ASAE892663 PAP.
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692.
   Jain A.K., 1989, FUNDAMENTALS DIGITAL.
   MCDONALD T, 1990, T ASAE, V33, P1345, DOI 10.13031/2013.31479.
   SHEARER SA, 1991, T ASAE, V34, P1661, DOI 10.13031/2013.31785.
   SHEARER SA, 1990, T ASAE, V33, P2037.
   SHIN B, 1989, ASAE897512 PAP.
   THOMPSON JF, 1990, ASAE907516 PAP.
   THOMPSON JF, 1990, ASAE901629 PAP.
   1985, SAS USERS GUIDE STAT.
   1991, KHOROS MANUAL.
   1981, EC STAT SER.},
Number-of-Cited-References = {27},
Times-Cited = {67},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {18},
Journal-ISO = {Trans. ASAE},
Doc-Delivery-Number = {RE891},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:A1995RE89100037},
DA = {2023-08-12},
}

@article{ WOS:000610045100005,
Author = {Martins, Jefferson G. and Oliveira, Luiz E. S. and Weingaertner, Daniel
   and Barison, Andersson and Oliveira, Gerlon A. R. and Liao, Luciano M.},
Title = {A database for automatic classification of gender in Araucaria
   angustifolia plants},
Journal = {SOFT COMPUTING},
Year = {2021},
Volume = {25},
Number = {7},
Pages = {5503-5517},
Month = {APR},
Abstract = {Forests have been disorderly exploited, and many species are considered
   endangered. Some initiatives have been taken in order to prevent forests
   from being destroyed. A good alternative would be to plan a spatial
   distribution of plants, with higher number of females than males.
   Determining the gender of seedlings would provide important information
   for a possible strategy. Another common problem that researchers in this
   field very often face, in order to perform their experiments, is the
   lack of a representative database. To overcome this difficulty, we
   introduce a new database in this work, which is composed of nuclear
   magnetic resonance of adult Araucaria angustifolia plants. In order to
   gain better insight into this database, we have tested different
   strategies and classifiers. A first set of experiments took three
   classifiers trained to discriminate males from females considering the
   original database. A second round of experiments applied the genetic
   algorithm technique to select subsets of attributes based on
   single-objective and two-objective functions. After analyzing the
   achieved results, we have also proposed a new strategy based on
   statistical measures for selecting subsets from the attributes. A
   comprehensive set of experiments has shown that the proposed selecting
   strategy has achieved better performances, with an accuracy of 80.3\%
   (AUC = 79.4). We believe that researchers will find this database a
   useful tool in their work on determining the Araucaria angustifolia
   gender. On the other hand, the proposed selecting strategy would be
   useful for reducing the complexity of databases and accelerating the
   process of building classification models.},
Publisher = {SPRINGER},
Address = {ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES},
Type = {Article},
Language = {English},
Affiliation = {Martins, JG (Corresponding Author), Fed Univ Technol Parana UTFPR, Rua Cristo Rei 19, BR-85902490 Toledo, PR, Brazil.
   Martins, Jefferson G., Fed Univ Technol Parana UTFPR, Rua Cristo Rei 19, BR-85902490 Toledo, PR, Brazil.
   Oliveira, Luiz E. S.; Weingaertner, Daniel; Barison, Andersson, Fed Univ Parana UFPR, Rua Cel Francisco H Santos 100, BR-81531990 Curitiba, PR, Brazil.
   Oliveira, Gerlon A. R.; Liao, Luciano M., Fed Univ Goias UFG, Av Esperanca S-N, BR-74690900 Goiania, Go, Brazil.},
DOI = {10.1007/s00500-020-05551-x},
EarlyAccessDate = {JAN 2021},
ISSN = {1432-7643},
EISSN = {1433-7479},
Keywords = {Pattern recognition; Gender plant classification; Feature selection},
Keywords-Plus = {ANT COLONY OPTIMIZATION; NMR; ALGORITHM},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications},
Author-Email = {martins@utfpr.edu.br},
Affiliations = {Universidade Tecnologica Federal do Parana; Universidade Federal do
   Parana},
ResearcherID-Numbers = {Lião, Luciano Morais M./F-1487-2015
   Martins, Jefferson/AAQ-2427-2021
   OLIVEIRA, GERLON/T-4201-2019},
ORCID-Numbers = {Lião, Luciano Morais M./0000-0001-9985-2980
   Martins, Jefferson/0000-0003-0480-6573
   OLIVEIRA, GERLON/0000-0002-7936-5429},
Funding-Acknowledgement = {National Council for Scientific and Technological Development (CNPq)
   {[}301653/2011-9, 471050/2013-0]},
Funding-Text = {This research has been supported by The National Council for Scientific
   and Technological Development (CNPq) {[}grants 301653/2011-9,
   471050/2013-0].},
Cited-References = {Abu Arqub O, 2014, INFORM SCIENCES, V279, P396, DOI 10.1016/j.ins.2014.03.128.
   {[}Anonymous], 1995, PROTEIN NMR SPECTROS.
   Atanazio KA., 2018, P SEM SUL BRAS SUST, P243.
   BANDEL G, 1967, Silvicultura em Sao Paulo, V6, P209.
   Bandel G, 1971, I PESQUI ESTUD FLORE, V2, P119.
   Blum C, 2005, PHYS LIFE REV, V2, P353, DOI 10.1016/j.plrev.2005.10.001.
   Zanon MLB, 2009, CIENC FLOREST, V19, P425, DOI 10.5902/19805098897.
   Carvalho BG, 2012, THESIS U FEDERAL GOI.
   Carvalho PER., 2003, ESPECIES FLORESTAIS.
   Dorigo M., 1992, THESIS POLITECNICO M.
   Dorigo M, 2006, IEEE COMPUT INTELL M, V1, P28, DOI 10.1109/MCI.2006.329691.
   Dusan Teodorovic F., 2005, ADV METHODS TRANSP, P51.
   ERNST RR, 1966, REV SCI INSTRUM, V37, P93, DOI 10.1063/1.1719961.
   Euceda LR, 2015, SCAND J CLIN LAB INV, V75, P193, DOI 10.3109/00365513.2014.1003593.
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010.
   Freitas AM, 2009, J ETHNOPHARMACOL, V126, P512, DOI 10.1016/j.jep.2009.09.005.
   Geem ZW, 2001, SIMULATION, V76, P60, DOI 10.1177/003754970107600201.
   Goldberg D. E., 1989, GENETIC ALGORITHMS S, V1st.
   Guerra MP., 2002, SUSTENTAVEL MATA ATL, P85.
   Holland J. H., 1975, ADAPTATION NATURAL A.
   Houle ME, 2010, LECT NOTES COMPUT SC, V6187, P482, DOI 10.1007/978-3-642-13818-8\_34.
   JEENER J, 1967, PHYS REV, V157, P232, DOI 10.1103/PhysRev.157.232.
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968.
   Keun HC, 2003, ANAL CHIM ACTA, V490, P265, DOI 10.1016/S0003-2670(03)00094-1.
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671.
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260.
   Kuo F.Y., 2005, NOTICES AMS, V52, P9.
   MacLean CD., 2007, LIFTING CURSE DIMENS, DOI {[}10.1007/978-0-387-49650-4\_3, DOI 10.1007/978-0-387-49650-4\_3].
   Murakami MH, 2002, THESIS U FEDERAL PAR.
   Murakami MH, 2003, SILVAE GENET, V52, P5.
   Nicholson JK, 2008, NATURE, V455, P1054, DOI 10.1038/4551054a.
   Oliveira GAR, 2016, VIBRATION BASED STRU.
   Rinnan A, 2009, TRAC-TREND ANAL CHEM, V28, P1201, DOI 10.1016/j.trac.2009.07.007.
   Rith K, 1999, SCI AM, V281, P58, DOI 10.1038/scientificamerican0799-58.
   Sahab MG, 2013, ELSEV INSIGHT, P25, DOI 10.1016/B978-0-12-398364-0.00002-4.
   Sastry K., 2005, SEARCH METHODOLOGIES, P97, DOI {[}DOI 10.1007/0-387-28356-0\_4, 10.1007/0-387-28356-0\_4].
   Sloan T, 2001, PHILOS T R SOC A, V359, P379, DOI 10.1098/rsta.2000.0730.
   Sousa SAA, 2013, CHEMOMETR INTELL LAB, V122, P93, DOI 10.1016/j.chemolab.2013.01.006.
   Stefenon VM, 2008, FOREST ECOL MANAG, V255, P2718, DOI 10.1016/j.foreco.2008.01.036.
   Suarez C, 1999, BBA-GEN SUBJECTS, V1426, P429, DOI 10.1016/S0304-4165(98)00164-0.
   Vu TN, 2013, METABOLITES, V3, P259, DOI 10.3390/metabo3020259.
   Wendling I, 2011, COMUNICADO TECNICO E, V1, P1.
   Yang Xin She, 2010, NAT INSPIRED METAHEU.
   Yang XS, 2009, WOR CONG NAT BIOL, P210, DOI 10.1109/nabic.2009.5393690.
   Yang XS, 2013, INT J BIO-INSPIR COM, V5, P141, DOI 10.1504/IJBIC.2013.055093.
   Zanette F., 2017, ARAUCARIA PARTICULAR, P15.
   Zanette F., 2016, ACTA BIOL PARAN, V44.
   Zanette F., 2014, ENXERTIA ARAUCARIA P.
   Zanette F, 2011, REV BRAS FRUTIC, V33, P1364, DOI 10.1590/S0100-29452011000400040.},
Number-of-Cited-References = {49},
Times-Cited = {1},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {3},
Journal-ISO = {Soft Comput.},
Doc-Delivery-Number = {QX9ZT},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000610045100005},
DA = {2023-08-12},
}

@inproceedings{ WOS:000380381400003,
Author = {Winberg, Simon L.},
Book-Group-Author = {IEEE},
Title = {Development of the Fynbos Leaf Optical Recognition Application (FLORA):
   An innovation journey of a tool to assist in identifying plants},
Booktitle = {2015 IEEE INTERNATIONAL SYMPOSIUM ON TECHNOLOGY AND SOCIETY (ISTAS)},
Series = {IEEE International Symposium on Technology and Society},
Year = {2015},
Note = {IEEE International Symposium on Technology and Society (ISTAS), Dublin,
   IRELAND, NOV 11-12, 2015},
Organization = {IEEE},
Abstract = {The Fynbos Leaf Optical Recognition Application (FLORA) is a software
   program to automatically identify fynbos plants using leaf photographs.
   While it is easier to classify fynbos when they are flowering, most
   fynbos flower for only short periods therefore FLORA was designed to
   identify plants by leaves instead of flowers. This paper presents the
   innovation journey of FLORA, highlighting transitions in development
   spaces, impact of requirements changes, and other significant challenges
   and lessons learned in the journey. The development was done out in a
   university research context and vacillated between being in a closed
   space and being a more open initiative. The project settled on being a
   collaborative and open innovation whereby the system supports a more
   diverse community of users and contributors. While the original
   requirements concerned a small scientific community of students and
   scientists botanists, the revised system, which the innovation journey
   lead towards, aims instead towards a wider community including tourists
   and schools pupils. It is hoped the innovation will have a broader
   societal influence in particular at schools level, where it is hoped
   that FLORA will both inspire young learns, and in particular tech savvy
   kids who spend too much time indoors, to spend time outdoors and to
   improve their awareness and appreciation of nature. This paper concludes
   with ways the project could have been streamlined from early on to
   better support the users and to facilitate the transition from a close
   to an open innovation.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Winberg, SL (Corresponding Author), Univ Cape Town, Dept Elect Engn, Cape Town, South Africa.
   Winberg, Simon L., Univ Cape Town, Dept Elect Engn, Cape Town, South Africa.},
ISSN = {2158-3404},
ISBN = {978-1-4799-8283-7},
Keywords = {image processing; plant identification; custom database design;
   innovation journey},
Keywords-Plus = {MANAGEMENT},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Interdisciplinary Applications},
Author-Email = {simon.winberg@uct.ac.za},
Affiliations = {University of Cape Town},
Cited-References = {{[}Anonymous], 2004, HIGH EDUC POLICY.
   Enkel E, 2009, R\&D MANAGE, V39, P311, DOI 10.1111/j.1467-9310.2009.00570.x.
   Liu Yu, 2003, Journal of Software, V14, P1364.
   Moran VC, 2012, BIOCONTROL, V57, P139, DOI 10.1007/s10526-011-9403-5.
   Pentland BT, 1999, ACAD MANAGE REV, V24, P711.
   Rip A, 1997, SOC SCI INFORM, V36, P615, DOI 10.1177/053901897036004003.
   Rip A., 2002, IDENTIFYING LOCI INF.
   Rip A, 2010, ADV SER MANAG, V7, P199, DOI 10.1108/S1877-6361(2010)0000007015.
   Robilliard PN, 1999, COMMUN ACM, V42, P87, DOI 10.1145/291469.291476.
   Schot J, 2008, TECHNOL ANAL STRATEG, V20, P537, DOI 10.1080/09537320802292651.
   Teasley SD, 2002, IEEE T SOFTWARE ENG, V28, P671, DOI 10.1109/TSE.2002.1019481.
   Van Wyk B., 2000, PHOTOGUIDE WILD FLOW.
   Winberg S., 2013, COMP VIS PATT REC IM, P1.},
Number-of-Cited-References = {13},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BF1EF},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000380381400003},
DA = {2023-08-12},
}

@article{ WOS:000085026500045,
Author = {Steward, BL and Tian, LF},
Title = {Machine-vision weed density estimation for real-time, outdoor lighting
   conditions},
Journal = {TRANSACTIONS OF THE ASAE},
Year = {1999},
Volume = {42},
Number = {6},
Pages = {1897-1909},
Month = {NOV-DEC},
Abstract = {A system to estimate the weed density between two rows of soybeans was
   developed. An environmentally adaptive segmentation algorithm (EASA) was
   used to segment the plants from the background of the image. The effect
   of two image data transformations on the segmentation performance of the
   EASA was investigated, and the RGB-IV1V2 transformation resulted in
   significantly higher quality segmentation results based on morphological
   opening and closing pixel loss over the RGB-rgb transformation. An
   adaptive scanning algorithm (ASA) was developed and used to
   automatically detect crop inter-row edges and to estimate the number of
   weeds in the inter-row area. Two sets of images were acquired under
   sunny and overcast sky conditions. The ASA-detected crop row edge
   positions were significantly correlated with the manually detected crop
   row positions, with the distribution skewed towards positions internal
   to the row. ASA weed density estimates were highly correlated with
   manual weed counts for both lighting conditions. However; when a limited
   range of the data was considered, much lower correlations resulted,
   revealing a loss of spatial color resolution due to the transmission of
   the video signal. The mean execution time of the ASA was 0.038 s for
   0.91 m (3 ft) long inter-row regions showing that the algorithm met the
   real-time constraints necessary to be used as a sensing system for a
   variable-rate herbicide applicator.},
Publisher = {AMER SOC AGRICULTURAL \& BIOLOGICAL ENGINEERS},
Address = {2950 NILES RD, ST JOSEPH, MI 49085-9659 USA},
Type = {Article},
Language = {English},
Affiliation = {Tian, LF (Corresponding Author), Univ Illinois, Dept Agr Engn, 1304 W Penn Ave, Urbana, IL 61801 USA.
   Univ Illinois, Dept Agr Engn, Urbana, IL 61801 USA.},
ISSN = {0001-2351},
Keywords = {image processing; sensing system; adaptive techniques; weed control;
   site-specific crop management},
Keywords-Plus = {SOYBEAN GLYCINE-MAX; SPATIAL-DISTRIBUTION; PLANT-IDENTIFICATION; DIGITAL
   IMAGES; FIELDS; SEEDLINGS; LEAVES; COLOR},
Research-Areas = {Agriculture},
Web-of-Science-Categories  = {Agricultural Engineering},
Author-Email = {leitian@uiuc.edu},
Affiliations = {University of Illinois System; University of Illinois Urbana-Champaign},
Cited-References = {Andreasen C, 1997, WEED RES, V37, P5, DOI 10.1111/j.1365-3180.1997.tb01817.x.
   {[}Anonymous], 1977, DAYLIGHT ITS SPECTRU.
   BECK J, 1996, NEW TRENDS FARM MACH, P11.
   BENILOCH JV, 1998, P SOC PHOTO-OPT INS, V3543, P302.
   BEZENEK TM, 1994, THESIS N DAKOTA STAT.
   Brivot R, 1996, IEE P-VIS IMAGE SIGN, V143, P118, DOI 10.1049/ip-vis:19960202.
   BROWN RB, 1994, T ASAE, V37, P297, DOI 10.13031/2013.28084.
   BURRILL LC, 1978, AGRON J, V70, P505, DOI 10.2134/agronj1978.00021962007000030035x.
   CARDINA J, 1995, WEED SCI, V43, P258, DOI 10.1017/S0043174500081157.
   COOKE L, 1996, AGR RES, V44, P15.
   Critten DL, 1996, J AGR ENG RES, V64, P149, DOI 10.1006/jaer.1996.0056.
   CURRAN PJ, 1985, APPL GEOGR, V5, P347, DOI 10.1016/0143-6228(85)90012-8.
   Dave S, 1995, IEEE WESCANEX `95 - COMMUNICATIONS, POWER, AND COMPUTING, CONFERENCE PROCEEDINGS, VOLS 1 AND 2, P403, DOI 10.1109/WESCAN.1995.494064.
   Felton W. L., 1991, Automated agriculture for the 21st century. Proceedings of a conference held in Chicago, Illinois, USA, 16-17 December 1991., P427.
   FRANZ E, 1991, T ASAE, V34, P682.
   FRANZ E, 1991, T ASAE, V34, P673.
   GUYER DE, 1993, T ASAE, V36, P163.
   HAGGAR RJ, 1983, J AGR ENG RES, V28, P349, DOI 10.1016/0021-8634(83)90066-5.
   HOFFMAN DW, 1978, WEED SCI, V26, P94, DOI 10.1017/S0043174500032756.
   HOOPER AW, 1976, J AGR ENG RES, V21, P145, DOI 10.1016/0021-8634(76)90069-X.
   JOHNSON GA, 1995, WEED RES, V35, P197, DOI 10.1111/j.1365-3180.1995.tb02033.x.
   Kender JR, 1976, SATURATION HUE NORMA.
   Lindell IV, 1998, J ELECTROMAGNET WAVE, V12, P1, DOI 10.1163/156939398X00016.
   MARSHALL EJP, 1988, WEED RES, V28, P191, DOI 10.1111/j.1365-3180.1988.tb01606.x.
   Meyer GE, 1998, T ASAE, V41, P1189, DOI 10.13031/2013.17244.
   MORTENSEN DA, 1995, SITE-SPECIFIC MANAGEMENT FOR AGRICULTURAL SYSTEMS, PROCEEDINGS OF SECOND INTERNATIONAL CONFERENCE, P397.
   MORTENSEN DA, 1993, PROCEEDINGS OF SOIL SPECIFIC CROP MANAGEMENT, P113.
   NITSCH B, 1991, THESIS U NEBRASKA LI.
   Pla F., 1993, Computers and Electronics in Agriculture, V8, P57, DOI 10.1016/0168-1699(93)90058-9.
   PRATT WK, 1991, DIGITAL IMAGE PROCES.
   SHEARER SA, 1991, T ASAE, V34, P1661, DOI 10.13031/2013.31785.
   SHEARER SA, 1990, T ASAE, V33, P2037.
   SHROPSHIRE GJ, 1992, P SOC PHOTO-OPT INS, V1836, P220.
   SHROPSHIRE GJ, 1989, 897522 ASAE.
   SHROPSHIRE GJ, 1990, P SOC PHOTO-OPT INS, V1379, P222.
   SITES PW, 1988, T ASAE, V31, P257.
   SLAUGHTER DC, 1989, T ASAE, V32, P757.
   THORNTON PK, 1990, CROP PROT, V9, P337, DOI 10.1016/0261-2194(90)90003-P.
   Tian L, 1997, T ASAE, V40, P1761.
   Tian LF, 1998, COMPUT ELECTRON AGR, V21, P153, DOI 10.1016/S0168-1699(98)00037-4.
   {*}USDA, 1998, AGR INC FIN SIT OUTL.
   VONBARGEN K, 1992, P SOC PHOTO-OPT INS, V1836, P231.
   Vrindts E, 1996, BRIGHTON CROP PROTECTION CONFERENCE: PESTS \& DISEASES - 1996, VOLS 1-3, P443.
   Vrindts E., 1998, Proceedings of SPIE, V3543, P279.
   WILES LJ, 1992, WEED SCI, V40, P554, DOI 10.1017/S0043174500058124.
   WILLIAMS MM, 1998, P 4 INT C PREC AGR A.
   WILSON BJ, 1991, WEED RES, V31, P367, DOI 10.1111/j.1365-3180.1991.tb01776.x.
   WINKLE ME, 1981, WEED SCI, V29, P405, DOI 10.1017/S0043174500039904.
   WOEBBECKE DM, 1995, T ASAE, V38, P271, DOI 10.13031/2013.27839.
   WOEBBECKE DM, 1992, P INT SOC OPTICAL EN, V1836, P208.
   Wyszecki G., 1982, COLOR SCI CONCEPTS M.
   ZHANG N, 1995, T ASAE, V38, P965, DOI 10.13031/2013.27890.},
Number-of-Cited-References = {52},
Times-Cited = {27},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {3},
Journal-ISO = {Trans. ASAE},
Doc-Delivery-Number = {279CV},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000085026500045},
DA = {2023-08-12},
}

@article{ WOS:000716399700002,
Author = {Abdulazeez, Adnan Mohsin and Zeebaree, Diyar Qader and Zebari, Dilovan
   Asaad and Hameed, Thamer Hassan},
Title = {Leaf Identification Based on Shape, Color, Texture and Vines Using
   Probabilistic Neural Network},
Journal = {COMPUTACION Y SISTEMAS},
Year = {2021},
Volume = {25},
Number = {3},
Abstract = {The importance of the plant for the human being and the environment led
   to deeply been studied and classified in detail. The advancement of the
   technology is the main factor in finding many ways for plant
   identification process. Some kind of initial intelligence systems in
   order to identify plant, followed by many theories and concepts using
   methods like; Moment Invariant (MI), Zernike Moments (ZM) and Polar
   Fourier Transform (PFT), and technologies for classification like;
   Neural Network (NN), K-Nearest Neighbor Classifier (KNN) and Support
   Vector Machine (SVM), were used by many researchers through past years.
   In this paper is Centroid-Radii (C-R) combined with geometric features
   of the leaves, in order to cover most of shape feature of the leaves,
   color moments and Grey-Level Co-occurrence Matrix (GLCM) to improve the
   accuracy of the system identification. in addition to the above
   features, Veins also involved in the method been used plus Principal
   Component Analysis (PCA), which is used to convert features into
   orthogonal features and the results were inputted to the classifiers
   that used Probabilistic Neural Network (PNN). Two datasets have been
   used for test, first dataset is created especially for this work and
   collected from 24 kinds of plants and second dataset is called Flavia,
   which contains 32 kinds. The results were clearly improved to identify
   the plants. The maximum accuracy reached up to 98.50\%, when using the
   first data set and 98.16\% for the second dataset.},
Publisher = {IPN, CENTRO INVESTIGAVION COMPUTACION},
Address = {AV JUAN DIOS BATIZ, S N ESQ M OTHON MENDIZABAL, UP ADOLFO LOPEZ MATEOS
   ZACATENCO, MEXICO CITY, 07738, MEXICO},
Type = {Article},
Language = {English},
Affiliation = {Zeebaree, DQ (Corresponding Author), Duhok Polytech Univ, Res Ctr, Duhok, Kurdistan Regio, Iraq.
   Abdulazeez, Adnan Mohsin, Duhok Polytech Univ, Duhok, Kurdistan Regio, Iraq.
   Zeebaree, Diyar Qader; Zebari, Dilovan Asaad, Duhok Polytech Univ, Res Ctr, Duhok, Kurdistan Regio, Iraq.
   Hameed, Thamer Hassan, Univ Duhok, Coll Agr Engn Sci, Duhok, Iraq.},
ISSN = {1405-5546},
EISSN = {2007-9737},
Keywords = {Centroid-Radii; geometric feature extraction; principal component
   analysis; probabilistic neural network},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Information Systems},
Author-Email = {adnan.mohsin@dpu.edu.krd
   dqszeebaree@dpu.edu.krd
   diloven.zebari@dpu.edu.krd},
Affiliations = {University of Duhok},
ResearcherID-Numbers = {Zebari, Dilovan/GSN-0908-2022
   Abdulazeez, Adnan Mohsin/AFP-7769-2022
   Zeebaree, Diyar Qader/AAE-3591-2021},
ORCID-Numbers = {Zebari, Dilovan/0000-0002-7643-6359
   Zeebaree, Diyar Qader/0000-0003-0255-4632},
Cited-References = {Abdulqader D. M., 2020, MACH LEARN, V62, P233.
   Ahmed N, 2016, SCI INT, V28, DOI DOI 10.9790/0661-17134853.
   Anant Bhardwaj, 2013, International Journal of Innovation and Applied Studies, V3, P237.
   Asraf Hairuddin Muhammad, 2011, 2011 IEEE International Conference on System Engineering and Technology (ICSET), P116, DOI 10.1109/ICSEngT.2011.5993432.
   Chaki J, 2011, INT J ADV COMPUT SC, V2, P41.
   Jeon WS, 2017, INT J FUZZY LOG INTE, V17, P26, DOI 10.5391/IJFIS.2017.17.1.26.
   Kadir Abdul, 2012, Journal of Theoretical and Applied Information Technology, V41, P82.
   Kadir A, 2011, INT J COMPUTER TREND, P225, DOI DOI 10.48550/ARXIV.1401.4447.
   Kadir A., 2014, INT J ADV SCI TECHNO, V44, P113.
   Kumar M, 2019, IEEE ACCESS, V7, P163912, DOI 10.1109/ACCESS.2019.2952176.
   Lee K.-B., 2013, INT J BIOSCI BIOTECH, V5, P57, DOI {[}10.14257/ijbsbt.2013.5.5.06, DOI 10.14257/IJBSBT.2013.5.5.06, 10.3724/sp.j.1087.2009.01707, DOI 10.1007/978-94-007-5857-5\_12].
   Meeta K., 2013, INT J MODERN ENG RES, V1, P538.
   Rao P. V. Nageswara, 2009, Journal of Theoretical and Applied Information Technology, V6, P101.
   Singh K., 2010, INT J SIGNAL PROCESS, V3, P67.
   Bao TQ, 2020, J INFORM TELECOMMUN, V4, P140, DOI 10.1080/24751839.2019.1666625.
   Wang B, 2013, IEEE IMAGE PROC, P4417, DOI 10.1109/ICIP.2013.6738910.
   Wang XF, 2008, APPL MATH COMPUT, V205, P916, DOI 10.1016/j.amc.2008.05.108.
   Wu SG, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, VOLS 1-3, P120.
   Zebari R., 2020, J APPL SCI TECHNOL T, V1, P56, DOI {[}DOI 10.38094/JASTT1224, 10.38094\%2Fjastt1224].
   Zeebaree Diyar Qader, 2019, 2019 International Conference on Advanced Science and Engineering (ICOASE), P106, DOI 10.1109/ICOASE.2019.8723827.
   Zeebaree Diyar Qader, 2019, 2019 International Conference on Advanced Science and Engineering (ICOASE), P88, DOI 10.1109/ICOASE.2019.8723832.
   Zou J, 2013, PATTERN RECOGN, V46, P434, DOI 10.1016/j.patcog.2012.06.018.},
Number-of-Cited-References = {22},
Times-Cited = {2},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {2},
Journal-ISO = {Comput. Sist.},
Doc-Delivery-Number = {WU2SI},
Web-of-Science-Index = {Emerging Sources Citation Index (ESCI)},
Unique-ID = {WOS:000716399700002},
DA = {2023-08-12},
}

@inproceedings{ WOS:000502815300002,
Author = {Durairajah, Vickneswari and Gobee, Suresh and Muneer, Amgad},
Book-Group-Author = {IEEE},
Title = {Automatic Vision Based Classification System Using DNN and SVM
   Classifiers},
Booktitle = {2018 3RD INTERNATIONAL CONFERENCE ON CONTROL, ROBOTICS AND CYBERNETICS
   (CRC)},
Year = {2018},
Pages = {6-14},
Note = {3rd International Conference on Control, Robotics and Cybernetics (CRC),
   Univ Sains Malaysia, Penang, MALAYSIA, DEC 18-20, 2018},
Organization = {IEEE Comp Soc},
Abstract = {In this paper, we construct an automatic classification vision system
   that is designed to recognize Malaysian herbs that are typically used
   for medical or culinary purposes. The proposed system employs two
   classifiers, Support Vector machine (SVM) and Deep Neural Network (DNN).
   The two classifiers have been implemented using OpenCV-Python. For the
   training test SVM achieved 86.63\% recognition accuracy and DNN
   (TensorFlow) achieved 98\% recognition accuracy. For the real life
   testing SVM achieved 74.63\% recognition accuracy and DNN achieved 93\%
   recognition accuracy. In the proposed system a total of 1000 leaves were
   used. A total of 50 samples of herbs were collected for each class and
   they were divided into two datasets. The first dataset which consisted
   60\% of the herbs samples were used for the training purpose and the
   other dataset with 40\% of the herbs samples were used for the testing
   purpose. The time taken for each recognition process was 4 seconds for
   SVM and 5 seconds for DNN classifier. Also, the proposed system is
   capable of identifying the herbs leaves even though they are wet, dried
   and deformed with a recognition accuracy of 52.50\%. Finally, based on
   the experiments that were done, the system proved to be very efficient
   and accurate with the highest recognition rate being 98\%. The results
   indicate that the techniques used in the proposed system are
   significantly efficient when compared to the various techniques employed
   in the existing literature.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Durairajah, V (Corresponding Author), Asia Pacific Univ Technol \& Innovat, Sch Mechatron Engn, Kuala Lumpur, Malaysia.
   Durairajah, Vickneswari; Gobee, Suresh; Muneer, Amgad, Asia Pacific Univ Technol \& Innovat, Sch Mechatron Engn, Kuala Lumpur, Malaysia.},
DOI = {10.1109/CRC.2018.00011},
ISBN = {978-1-5386-7738-4},
Keywords = {DNN; feature extraction; GLUM technique; herb recognition; plant
   classification; segmentation; SVM; tensorflow; zernike moments},
Keywords-Plus = {RECOGNITION; SHAPE; FEATURES; PLANTS},
Research-Areas = {Automation \& Control Systems; Computer Science; Engineering; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Cybernetics;
   Engineering, Electrical \& Electronic; Robotics},
Author-Email = {vicky\_nesa@apu.edu.my
   suresh.gobee@apu.edu.my
   muneeramgad@gmail.com},
Affiliations = {Asia Pacific University of Technology \& Innovation},
ResearcherID-Numbers = {Muneer, Amgad/AAT-8412-2020
   durairajah, vickneswari/AGP-0837-2022
   Gobee, Suresh/HPG-9191-2023
   },
ORCID-Numbers = {Muneer, Amgad/0000-0002-7157-3020
   durairajah, vickneswari/0000-0002-9358-0512},
Cited-References = {Aakif A, 2015, BIOSYST ENG, V139, P66, DOI 10.1016/j.biosystemseng.2015.08.003.
   Anant Bhardwaj, 2013, International Journal of Innovation and Applied Studies, V3, P237.
   {[}Anonymous], 2013, INT J ENG SCI TECHNO.
   {[}Anonymous], 2012, INN INT SYST APPL IN.
   {[}Anonymous], 2014, P INT C ADV COMP COM.
   Babatunde O.H., 2014, ASIAN J COMPUTER INF, V2, P15.
   Chaki J, 2015, PATTERN RECOGN LETT, V58, P61, DOI 10.1016/j.patrec.2015.02.010.
   Chaki J, 2011, INT J ADV COMPUT SC, V2, P41.
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692.
   Husin Z, 2012, COMPUT ELECTRON AGR, V89, P18, DOI 10.1016/j.compag.2012.07.009.
   Jamil N, 2015, PROCEDIA COMPUT SCI, V76, P436, DOI 10.1016/j.procs.2015.12.287.
   Kadir Abdul, 2012, Journal of Theoretical and Applied Information Technology, V41, P82.
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109.
   Kim HS, 2003, IEEE T CIRC SYST VID, V13, P766, DOI 10.1109/TCSVT.2003.815955.
   Mohanaiah P., 2013, INT J SCI RES PUBLIC, V3, P1.
   Naresh YG, 2016, NEUROCOMPUTING, V173, P1789, DOI 10.1016/j.neucom.2015.08.090.
   Patil AA., 2016, INT J ENG TRENDS TEC, V8, P359, DOI {[}10.14445/22315381/IJETT-V35P273, DOI 10.14445/22315381/IJETT-V35P273].
   Prasad S., 2011, 2011 2nd International Conference on Computer and Communication Technology, P646, DOI 10.1109/ICCCT.2011.6075212.
   Prasad S, 2017, MULTIMED TOOLS APPL, V76, P6915, DOI 10.1007/s11042-016-3309-2.
   Sambhaji Ekshinage Sandip, 2014, ASIAN J ENG TECHNOLO.
   Sumathi C. S., 2013, International Journal of Future Computer and Communication, V2, P196, DOI 10.7763/IJFCC.2013.V2.151.
   Wu SG, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, VOLS 1-3, P120.},
Number-of-Cited-References = {22},
Times-Cited = {11},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {3},
Doc-Delivery-Number = {BO1XJ},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000502815300002},
DA = {2023-08-12},
}

@article{ WOS:000302189100004,
Author = {Nakarmi, A. D. and Tang, L.},
Title = {Automatic inter-plant spacing sensing at early growth stages using a 3D
   vision sensor},
Journal = {COMPUTERS AND ELECTRONICS IN AGRICULTURE},
Year = {2012},
Volume = {82},
Pages = {23-31},
Month = {MAR},
Abstract = {An inter-plant spacing sensing system using a TOF (time of flight) of
   light based 3D sensor was developed. The 3D sensor was capable of
   capturing distance information, intensity and amplitude data in a single
   shot. The side view depth images captured were stitched together using
   distance information from a wheel encoder in conjunction with a
   feature-based image sequencing process for the stem location
   identification. One obvious advantage of the system over current
   color-based 2D systems was the use of depth images for plant
   identification, which was less sensitive to color variations. A covered
   cart was designed to prevent the sunlight from directly shedding on the
   plants and to reduce the interference from wind, which in turn made the
   system usable throughout the day. The vertical camera position was
   easily adjustable making the system suitable to work with plants at
   different growth stages.
   The use of side-view images made the system capable of detecting
   inclined plants and therefore, boosted the performance of the system in
   precisely locating the stem centers, which in turn minimized the
   measurement errors. The measurement accuracy demonstrated the system
   superiority over the current systems which make use of top-view images
   for inter-plant spacing sensing. The system achieved an overall mean
   root mean squared error (RMSE) of 0.017 m with a mean plant
   misidentification ratio of 2.2\%. The coefficient of determination (R-2)
   was 0.95 between the in-field manual distance measurements and the
   system distance estimates. (C) 2011 Elsevier B.V. All rights reserved.},
Publisher = {ELSEVIER SCI LTD},
Address = {THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Tang, L (Corresponding Author), Iowa State Univ, 153 Davidson Hall, Ames, IA 50011 USA.
   Nakarmi, A. D.; Tang, L., Iowa State Univ, Ames, IA 50011 USA.},
DOI = {10.1016/j.compag.2011.12.011},
ISSN = {0168-1699},
Keywords = {3D; Machine vision; Corn plant spacing sensing; Early growth stages;
   Image processing},
Keywords-Plus = {CORN; YIELD},
Research-Areas = {Agriculture; Computer Science},
Web-of-Science-Categories  = {Agriculture, Multidisciplinary; Computer Science, Interdisciplinary
   Applications},
Author-Email = {lietang@iastate.edu},
Affiliations = {Iowa State University},
Cited-References = {Barge G.L., 2001, TIPS REDUCE PLANTER.
   Doerge T., 2002, CROP INSIGHTS, V12.
   Jin J, 2009, J FIELD ROBOT, V26, P591, DOI 10.1002/rob.20293.
   Lauer JG, 2004, AGRON J, V96, P1464, DOI 10.2134/agronj2004.1464.
   Liu WD, 2004, AGRON J, V96, P1668, DOI 10.2134/agronj2004.1668.
   Liu WD, 2004, AGRON J, V96, P275.
   Nafziger ED, 1996, J PROD AGRIC, V9, P238, DOI 10.2134/jpa1996.0238.
   Nielsen R., 1993, STAND ESTABLISHMENT.
   Nielsen R. L., 2005, EFFECT PLANT SPACING.
   ROSENFELD A, 1975, INFORM CONTROL, V29, P286, DOI 10.1016/S0019-9958(75)90448-9.
   Shrestha DS, 2003, T ASAE, V46, P559, DOI 10.13031/2013.12945.
   Tang L, 2008, T ASABE, V51, P2181, DOI 10.13031/2013.25381.
   Tang L, 2008, T ASABE, V51, P1079, DOI 10.13031/2013.24510.
   uttgen B. B, 2005, CCD CMOS LOCK IN PIX.
   VANDERLIP R L, 1988, Applied Agricultural Research, V3, P116.},
Number-of-Cited-References = {15},
Times-Cited = {43},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {23},
Journal-ISO = {Comput. Electron. Agric.},
Doc-Delivery-Number = {917PA},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000302189100004},
DA = {2023-08-12},
}

@article{ WOS:000504051800048,
Author = {Zhang, Hehu and Wang, Xiushan and Jiang, Lintao and Xu, Yibo and Jiang,
   Guoqiang},
Title = {Near color recognition based on residual vector and SVM},
Journal = {MULTIMEDIA TOOLS AND APPLICATIONS},
Year = {2019},
Volume = {78},
Number = {24},
Pages = {35313-35328},
Month = {DEC},
Abstract = {With the extensive application of machine vision in Agriculture, plant
   recognition is becoming an important research territory. Due to
   illumination change, occlusion problem, green background and other
   factors, the image segmentation quality of plant is uneven. When there
   are significantly different colors, such as red, green and blue, between
   plant target and background, classical image processing methods are up
   to the task. However, in near color scene, for example dark green target
   and bright green background, plant target recognition is still a very
   challenging task. To segment plants in above scene, the near color
   recognition method based on residual vector and SVM has been developed.
   Firstly, the color vectors were projected to the plane that crosses the
   point Origin(0, 0, 0) and is perpendicular to reference color vector
   B0(255, 255, 255). After projection, the significantly different color
   vectors were distributed in different polar angle ranges, while the near
   color vectors were concentrated in the same polar angle range. For near
   color vectors, the small polar angle difference, namely roll, was
   regarded as redundant information. Then, the angle theta between target
   color vector A(r, g, b) and B0, along with the norm of A, namely A
   parallel to(A) over right arrow parallel to was calculated. As a result,
   the three-dimensional target color vector A was converted to the
   two-dimensional residual vector (R parallel to(A) over right arrow
   parallel to,theta). Finally, SVM classifier is used to identify the
   residual vector. The results show that the linear recognition rate is
   90.25\%, the average recognition speed 0.243 s, the nonlinear
   recognition rate 87.47\%, and the average recognition speed 0.254 s.
   This study provides theoretical reference for plant target recognition
   in the near color scene.},
Publisher = {SPRINGER},
Address = {VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Wang, XS (Corresponding Author), Henan Agr Univ, Coll Mech \& Elect Engn, Dept Elect Engn, Zhengzhou, Henan, Peoples R China.
   Zhang, Hehu; Wang, Xiushan; Jiang, Lintao; Xu, Yibo; Jiang, Guoqiang, Henan Agr Univ, Coll Mech \& Elect Engn, Dept Elect Engn, Zhengzhou, Henan, Peoples R China.},
DOI = {10.1007/s11042-019-08164-1},
ISSN = {1380-7501},
EISSN = {1573-7721},
Keywords = {Near color; Residual vector; Support vector machine; Machine vision},
Keywords-Plus = {SEGMENTATION; PLANT; VEGETATION; ALGORITHM; CLUSTERS; FEATURES; VISION;
   ROBUST; SHAPE; CROP},
Research-Areas = {Computer Science; Engineering},
Web-of-Science-Categories  = {Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory \& Methods; Engineering,
   Electrical \& Electronic},
Author-Email = {towxs@163.com},
Affiliations = {Henan Agricultural University},
ResearcherID-Numbers = {zhang, hehu/AAT-8931-2020
   Zhang, Hehu/AAN-5588-2021},
ORCID-Numbers = {Zhang, Hehu/0000-0003-0862-0506},
Funding-Acknowledgement = {Henan science and technology tackling key project {[}172102210678]; Key
   research projects of universities in Henan {[}18A416002]; Henan college
   key scientific research project {[}182102110249]; Henan province
   innovation and entrepreneurship training platform for University
   Students {[}s201810466023]},
Funding-Text = {This research is supported by the following projects: Henan science and
   technology tackling key project (Grant: 172102210678); Key research
   projects of universities in Henan (Grant: 18A416002); Henan college key
   scientific research project (Grant: 182102110249); Henan province
   innovation and entrepreneurship training platform for University
   Students (Grant: s201810466023). The project team heartily expresses the
   full thanks to above units.},
Cited-References = {Abbasgholipour M, 2011, EXPERT SYST APPL, V38, P3671, DOI 10.1016/j.eswa.2010.09.023.
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120.
   {[}Anonymous], J MOD OPT.
   {[}Anonymous], OPTIK.
   {[}Anonymous], INT S EXP ROB.
   {[}Anonymous], 20 IEEE INT C IM PRO.
   {[}Anonymous], MULTIMED TOOLS APPL.
   {[}Anonymous], EXPERT SYST APPL.
   {[}Anonymous], J ELECT IMAGINING.
   Bai XD, 2014, BIOSYST ENG, V125, P80, DOI 10.1016/j.biosystemseng.2014.06.015.
   Caglayan A, 2013, LECT NOTES COMPUT SC, V8157, P161, DOI 10.1007/978-3-642-41184-7\_17.
   Chaki J, 2015, PATTERN RECOGN LETT, V58, P61, DOI 10.1016/j.patrec.2015.02.010.
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199.
   Dyrmann M., 2017, ADV ANIM BIOSCI, V8, P842, DOI {[}DOI 10.1017/S2040470017000206, 10.1017/S2040470017000206].
   Dyrmann M, 2016, BIOSYST ENG, V151, P72, DOI 10.1016/j.biosystemseng.2016.08.024.
   Guijarro M, 2011, COMPUT ELECTRON AGR, V75, P75, DOI 10.1016/j.compag.2010.09.013.
   Guo W, 2013, COMPUT ELECTRON AGR, V96, P58, DOI 10.1016/j.compag.2013.04.010.
   Hague T, 2006, PRECIS AGRIC, V7, P21, DOI 10.1007/s11119-005-6787-1.
   Hunt E. Raymond Jr, 2005, Precision Agriculture, V6, P359, DOI 10.1007/s11119-005-2324-5.
   Jeon HY, 2011, SENSORS-BASEL, V11, P6270, DOI 10.3390/s110606270.
   Kataoka T, 2003, IEEE ASME INT C ADV, P1079, DOI 10.1109/aim.2003.1225492.
   Lee SH, 2015, IEEE IMAGE PROC, P452, DOI 10.1109/ICIP.2015.7350839.
   Liu S, 2016, MULTIMED TOOLS APPL, V75, P15525, DOI 10.1007/s11042-014-2446-8.
   Liu SA, 2017, MULTIMED TOOLS APPL, V76, P5787, DOI 10.1007/s11042-014-2408-1.
   Meyer GE, 2004, COMPUT ELECTRON AGR, V42, P161, DOI 10.1016/j.compag.2003.08.002.
   Sabzi S, 2017, BIOSYST ENG, V163, P167, DOI 10.1016/j.biosystemseng.2017.09.003.
   Tellaeche A, 2008, PATTERN RECOGN, V41, P521, DOI 10.1016/j.patcog.2007.07.007.
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580\_002.
   Wu SG, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, VOLS 1-3, P120.
   Xiong JT, 2018, BIOSYST ENG, V166, P44, DOI 10.1016/j.biosystemseng.2017.11.005.
   Zhang Q, 2017, COMPUT ELECTRON AGR, V143, P66, DOI 10.1016/j.compag.2017.09.008.},
Number-of-Cited-References = {31},
Times-Cited = {1},
Usage-Count-Last-180-days = {3},
Usage-Count-Since-2013 = {9},
Journal-ISO = {Multimed. Tools Appl.},
Doc-Delivery-Number = {JX9MV},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000504051800048},
DA = {2023-08-12},
}

@article{ WOS:000480567700001,
Author = {Lottes, Philipp and Behley, Jens and Chebrolu, Nived and Milioto, Andres
   and Stachniss, Cyrill},
Title = {Robust joint stem detection and crop-weed classification using image
   sequences for plant-specific treatment in precision farming},
Journal = {JOURNAL OF FIELD ROBOTICS},
Year = {2020},
Volume = {37},
Number = {1},
Pages = {20-34},
Month = {JAN},
Abstract = {Conventional farming still relies on large quantities of agrochemicals
   for weed management which have several negative side-effects on the
   environment. Autonomous robots offer the potential to reduce the amount
   of chemicals applied, as robots can monitor and treat each plant in the
   field individually and thereby circumventing the uniform chemical
   treatment of the whole field. Such agricultural robots need the ability
   to identify individual crops and weeds in the field using sensor data
   and must additionally select effective treatment methods based on the
   type of weed. For example, certain types of weeds can only be
   effectively treated mechanically due to their resistance to herbicides,
   whereas other types can be treated trough selective spraying. In this
   article, we present a novel system that provides the necessary
   information for effective plant-specific treatment. It estimates the
   stem location for weeds, which enables the robots to perform precise
   mechanical treatment, and at the same time provides the pixel-accurate
   area covered by weeds for treatment through selective spraying. The
   major challenge in developing such a system is the large variability in
   the visual appearance that occurs in different fields. Thus, an
   effective classification system has to robustly handle substantial
   environmental changes including varying weed pressure, various weed
   types, different growth stages, changing visual appearance of the plants
   and the soil. Our approach uses an end-to-end trainable fully
   convolutional network that simultaneously estimates plant stem positions
   as well as the spatial extent of crop plants and weeds. It jointly
   learns how to detect the stems and the pixel-wise semantic segmentation
   and incorporates spatial information by considering image sequences of
   local field strips. The jointly learned feature representation for both
   tasks furthermore exploits the crop arrangement information that is
   often present in crop fields. This information is considered even if it
   is only observable from the image sequences and not a single image. Such
   image sequences, as typically provided by robots navigating over the
   field along crop rows, enable our approach to robustly estimate the
   semantic segmentation and stem positions despite the large variations
   encountered in different fields. We implemented and thoroughly tested
   our approach on images from multiple farms in different countries. The
   experiments show that our system generalizes well to previously unseen
   fields under varying environmental conditions-a key capability to deploy
   such systems in the real world. Compared to state-of-the-art approaches,
   our approach generalizes well to unseen fields and not only
   substantially improves the stem detection accuracy, that is,
   distinguishing crop and weed stems, but also improves the semantic
   segmentation performance.},
Publisher = {WILEY},
Address = {111 RIVER ST, HOBOKEN 07030-5774, NJ USA},
Type = {Article},
Language = {English},
Affiliation = {Lottes, P (Corresponding Author), Univ Bonn, Photogrammetry \& Robot Lab, Nussallee 15, D-53115 Bonn, Germany.
   Lottes, Philipp; Behley, Jens; Chebrolu, Nived; Milioto, Andres; Stachniss, Cyrill, Univ Bonn, Photogrammetry \& Robot Lab, Nussallee 15, D-53115 Bonn, Germany.},
DOI = {10.1002/rob.21901},
EarlyAccessDate = {AUG 2019},
ISSN = {1556-4959},
EISSN = {1556-4967},
Keywords = {agricultural robotics; machine learning; plant classification; precision
   farming},
Keywords-Plus = {NEURAL-NETWORKS; SUGAR-BEETS},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {philipp.lottes@igg.uni-bonn.de},
Affiliations = {University of Bonn},
ResearcherID-Numbers = {Stachniss, Cyrill/AAH-3034-2019
   },
ORCID-Numbers = {Behley, Jens/0000-0001-6483-0319
   Stachniss, Cyrill/0000-0003-1173-6972},
Funding-Acknowledgement = {European Commission {[}H2020-ICT-644227-FLOURISH]},
Funding-Text = {European Commission, Grant/Award Number: H2020-ICT-644227-FLOURISH},
Cited-References = {{[}Anonymous], 2018, GUIDE CONVOLUTION AR.
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615.
   Behley J, 2013, IEEE INT C INT ROBOT, P4195, DOI 10.1109/IROS.2013.6696957.
   Bogoslavskyi I, 2013, 2013 EUROPEAN CONFERENCE ON MOBILE ROBOTS (ECMR 2013), P158, DOI 10.1109/ECMR.2013.6698836.
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401.
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324.
   Chebrolu N, 2017, INT J ROBOT RES, V36, P1045, DOI 10.1177/0278364917720510.
   Di Cicco M, 2017, IEEE INT C INT ROBOT, P5188, DOI 10.1109/IROS.2017.8206408.
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4.
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504.
   Gislum R., 2016, CIGR AGENG C, P1.
   Haug S., 2014, WORKSH P C INT AUT S, P483.
   Haug S, 2014, IEEE WINT CONF APPL, P1142, DOI 10.1109/WACV.2014.6835733.
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI {[}10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175].
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123.
   Huang G., 2017, P 2017 IEEE C COMP V, P4700, DOI {[}DOI 10.1109/CVPR.2017.243, 10.1109/CVPR.2017.243].
   Jegou S., 2017, 100 LAYERS TIRAMISU.
   Kiani S, 2012, J AGR SCI TECH-IRAN, V14, P755.
   Kraemer F., 2017, IEEE RSJ INT C INT R.
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386.
   Kummerle R, 2013, IEEE INT CONF ROBOT, P3225, DOI 10.1109/ICRA.2013.6631026.
   Leibe B, 2005, PROC CVPR IEEE, P878.
   Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3.
   Lin M, 2014, 2014 INTERNATIONAL CONFERENCE ON MEDICAL BIOMETRICS (ICMB 2014), P1, DOI 10.1109/ICMB.2014.8.
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965.
   Lottes P., 2018, P IEEE RSJ INT C INT, DOI {[}10. 1109/iros. 2018. 8593678, DOI 10.1109/IROS.2018.8593678].
   Lottes P., 2017, 2017 IEEE INT C ROB, P3024, DOI DOI 10.1109/ICRA.2017.7989347.
   Lottes P., 2017, P IEEE RSJ INT C INT, DOI {[}10. 1109/iros. 2017. 8206403, DOI 10.1109/IROS.2017.8206403].
   Lottes P, 2018, IEEE ROBOT AUTOM LET, V3, P2870, DOI 10.1109/LRA.2018.2846289.
   Lottes P, 2017, J FIELD ROBOT, V34, P1160, DOI 10.1002/rob.21675.
   McCool C, 2017, IEEE ROBOT AUTOM LET, V2, P1344, DOI 10.1109/LRA.2017.2667039.
   Midtiby HS, 2012, BIOSYST ENG, V111, P83, DOI 10.1016/j.biosystemseng.2011.10.011.
   Milioto A., 2018, WORSH PERC INT LEARN.
   Milioto A, 2018, IEEE INT CONF ROBOT, P2229.
   Milioto A, 2017, ISPRS ANN PHOTO REM, V4-2, P41, DOI 10.5194/isprs-annals-IV-2-W3-41-2017.
   Papageorgiou C., 1988, P INT C COMP VIS.
   Paszke A., 2016, ARXIV160602147.
   Potena C, 2017, ADV INTELL SYST COMP, V531, P105, DOI 10.1007/978-3-319-48036-7\_9.
   Rahman Md Atiqur, 2016, Advances in Visual Computing. 12th International Symposium, ISVC 2016. Proceedings: LNCS 10072, P234, DOI 10.1007/978-3-319-50835-1\_22.
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4\_28.
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0.
   Slaughter DC, 2008, COMPUT ELECTRON AGR, V61, P63, DOI 10.1016/j.compag.2007.05.008.
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929.
   Stachniss C., 2005, P INT S ROB RES ISRR.
   Szegedy C., 2015, P IEEE C COMP VIS PA.
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb.
   Wurm K., 2013, J ROBOTICS AUTONOMOU, V62, P675.},
Number-of-Cited-References = {47},
Times-Cited = {42},
Usage-Count-Last-180-days = {4},
Usage-Count-Since-2013 = {32},
Journal-ISO = {J. Field Robot.},
Doc-Delivery-Number = {NT5UH},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000480567700001},
OA = {Bronze},
DA = {2023-08-12},
}

@inproceedings{ WOS:000305621100007,
Author = {Suzuki, Y. and Okamoto, H. and Kataoka, T.},
Editor = {Albrigo, LG and Ehsani, R},
Title = {Development of Discriminant Model for Weed Detection Using Hyperspectral
   Imaging},
Booktitle = {INTERNATIONAL SYMPOSIUM ON APPLICATION OF PRECISION AGRICULTURE FOR
   FRUITS AND VEGETABLES},
Series = {Acta Horticulturae},
Year = {2009},
Volume = {824},
Pages = {67-73},
Note = {International Symposium on Application of Precision Agriculture for
   Fruits and Vegetables, Orlando, FL, APR 01, 2009},
Abstract = {Physical weed control is environmentally safer than chemical methods.
   However, most of the physical methods are manual. Therefore, development
   of a robotic weeding system is necessary to practice efficient weed
   control. The objective of this study was to develop a pixel discriminant
   model for image segmentation between crop and weed using hyperspectral
   imaging. A hyperspectral image was processed pixel by pixel. First,
   every pixel spectrum was extracted from the image. Next, each pixel
   spectrum was classified into soil and plant. If the pixel spectrum was
   identified as plant, it was classified into crop and weed. In the pixel
   discriminant model for soil and plant, simple NDVI thresholding was
   employed. The pixel discriminant model for crop and weed consisted of a
   normalizer, an explanatory variable generator and the discriminator.
   Development of the explanatory variable generator was tried with two
   different methods (RAW or PCA). Development of discriminator was also
   tried with two different methods (LDA or NN). In this study, four types
   of models (RAW-LDA, RAW-NN, PCA-LDA and PCA-NN) were developed for
   discrimination between crop and weed and validated. Finally, segmented
   images for crop, weed, and soil were generated from the images by
   applying these models. Pixel discrimination between soil and plant was
   performed with high accuracy. In the pixel discrimination between crop
   and weed, success rates of all discriminant models were more than 85\%.
   As for the accuracy of the models, NN models were superior to LDA, and
   the PCA method was superior to RAW. However, with respect to processing
   speed, the RAW method was superior to PCA. As a result of image
   segmentation, most of pixel spectra in the images were identified
   correctly. In conclusion, this study showed the possibility for weed
   detection by using hyperspectral imaging.},
Publisher = {INT SOC HORTICULTURAL SCIENCE},
Address = {PO BOX 500, 3001 LEUVEN 1, BELGIUM},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Suzuki, Y (Corresponding Author), Hokkaido Univ, Grad Sch Agr, Sapporo, Hokkaido, Japan.
   Suzuki, Y., Hokkaido Univ, Grad Sch Agr, Sapporo, Hokkaido, Japan.
   Okamoto, H.; Kataoka, T., Hokkaido Univ, Res Fac Agr, Sapporo, Hokkaido, Japan.},
ISSN = {0567-7572},
ISBN = {978-90-6605-370-0},
Keywords = {machine vision; image processing; plant classification; remote sensing;
   soybean},
Keywords-Plus = {NEURAL-NETWORKS; CLASSIFICATION; CORN},
Research-Areas = {Agriculture},
Web-of-Science-Categories  = {Agricultural Economics \& Policy; Horticulture},
Affiliations = {Hokkaido University; Hokkaido University},
Cited-References = {Bajwa SG, 2001, T ASAE, V44, P1965, DOI 10.13031/2013.6995.
   Goel PK, 2003, T ASAE, V46, P539.
   Iino Y., 2005, J HOKKAIDO BRANCH JA, V45, P21.
   Karimi Y, 2005, T ASAE, V48, P1261, DOI 10.13031/2013.18490.
   Okamoto H., 2006, Agricultural Information Research, V15, P103, DOI 10.3173/air.15.103.
   Okamoto H., 2006, Agricultural Information Research, V15, P219, DOI 10.3173/air.15.219.
   OKAMOTO H, 2004, P AUT TECHN OFF ROAD, P47.
   Okamoto H, 2007, WEED BIOL MANAG, V7, P31, DOI 10.1111/j.1445-6664.2006.00234.x.
   Steward BL, 1999, T ASAE, V42, P1897, DOI 10.13031/2013.13355.
   Tang L, 2003, T ASAE, V46, P1247, DOI 10.13031/2013.13944.
   TERAWAKI M, 2002, P AUT TECHN OFF ROAD, P129.
   Yang CC, 2004, T ASAE, V47, P873, DOI 10.13031/2013.16084.
   Yang CC, 2002, T ASAE, V45, P859.
   YE X, 2006, 3 IFAC INT WORKSH BI, P165.},
Number-of-Cited-References = {14},
Times-Cited = {3},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {9},
Doc-Delivery-Number = {BAV48},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000305621100007},
DA = {2023-08-12},
}

@article{ WOS:000841988400002,
Author = {Min, Cheol Woo and Jang, Jeong Woo and Lee, Gi Hyun and Gupta, Ravi and
   Yoon, Jinmi and Park, Hyun Ji and Cho, Hye Sun and Park, Sang Ryeol and
   Kwon, Soon-Wook and Cho, Lae-Hyeon and Jung, Ki-Hong and Kim, Yu-Jin and
   Wang, Yiming and Kim, Sun Tae},
Title = {TMT-based quantitative membrane proteomics identified PRRs potentially
   involved in the perception of MSP1 in rice leaves},
Journal = {JOURNAL OF PROTEOMICS},
Year = {2022},
Volume = {267},
Month = {SEP 15},
Abstract = {Pathogen-associated molecular patterns (PAMPs) play a key role in
   triggering PAMPs triggered immunity (PTI) in plants. In the case of the
   rice-Magnaporthe oryzae pathosystem, fewer PAMPs and their pattern
   recognition re-ceptors (PRRs) have been characterized. Recently, a M.
   oryzae snodprot1 homolog protein (MSP1) has been identified that
   functions as PAMP and triggering the PTI responses in rice. However, the
   molecular mechanism underlying MSP1-induced PTI is currently elusive.
   Therefore, we generated MSP1 overexpressed transgenic lines of rice, and
   a tandem mass tag (TMT)-based quantitative membrane proteomic analysis
   was employed to deci-pher the potential MSP1-induced signaling in rice
   using total cytosolic as well as membrane protein fractions. This
   approach led to the identification of 8033 proteins of which 1826 were
   differentially modulated in response to overexpression of MSP1 and/or
   exogenous jasmonic acid treatment. Of these, 20 plasma
   membrane-localized receptor-like kinases (RLKs) showed increased
   abundance in MSP1 overexpression lines. Moreover, activation of proteins
   related to the protein degradation and modification, calcium signaling,
   redox, and MAPK signaling was observed in transgenic lines expressing
   MSP1 in the apoplast. Taken together, our results identified potential
   PRR candidates involved in MSP1 recognition and suggested the overview
   mechanism of the MSP1-induced PTI signaling in rice leaves.Significance:
   In plants, recognition of pathogen pathogen-derived molecules, such as
   PAMPs, by plant plant-derived PRRs has an essential role for in the
   activation of PTI against pathogen invasion. Typically, PAMPs are
   recognized by plasma membrane (PM) localized PRRs, however, identifying
   the PM-localized PRR proteins is challenging due to their low abundance.
   In this study, we performed an integrated membrane protein enrichment by
   microsomal membrane extraction (MME) method and subsequent
   TMT-labeling-based quantitative proteomic analysis using MSP1
   overexpressed rice. Based on these results, we successfully identified
   various intracellular and membrane membrane-localized proteins that
   participated in the MSP1-induced immune response and characterized the
   potential PM-localized PRR candidates in rice.},
Publisher = {ELSEVIER},
Address = {RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Kim, ST (Corresponding Author), Pusan Natl Univ, Life \& Ind Convergence Res Inst, Dept Plant Biosci, Miryang 50463, South Korea.
   Min, Cheol Woo; Jang, Jeong Woo; Lee, Gi Hyun; Yoon, Jinmi; Kwon, Soon-Wook; Cho, Lae-Hyeon; Kim, Sun Tae, Pusan Natl Univ, Life \& Ind Convergence Res Inst, Dept Plant Biosci, Miryang 50463, South Korea.
   Gupta, Ravi, Kookmin Univ, Coll Gen Educ, Seoul 02707, South Korea.
   Park, Hyun Ji; Cho, Hye Sun, Korea Res Inst Biosci \& Biotechnol, Plant Syst Engn Res Ctr, Daejeon 34141, South Korea.
   Park, Sang Ryeol, Rural Dev Adm, Natl Inst Agr Sci, Jeonju 54874, South Korea.
   Jung, Ki-Hong, Kyung Hee Univ, Crop Biotech Inst, Grad Sch Biotechnol, Yongin 17104, South Korea.
   Kim, Yu-Jin, Pusan Natl Univ, Life \& Ind Convergence Res Inst, Dept Life Sci \& Environm Biochem, Miryang 50463, South Korea.
   Wang, Yiming, Nanjing Agr Univ, Dept Plant Pathol, Key Lab Biol Interact \& Crop Hlth, Nanjing 210095, Peoples R China.},
DOI = {10.1016/j.jprot.2022.104687},
EarlyAccessDate = {AUG 2022},
Article-Number = {104687},
ISSN = {1874-3919},
EISSN = {1876-7737},
Keywords = {Rice; Magnaporthe oryzae; MSP1; TMT; Proteomics; PRRs},
Keywords-Plus = {RECEPTOR-LIKE KINASE; DISEASE-RESISTANCE; MAGNAPORTHE-GRISEA;
   PROTEIN-KINASE; COMPUTATIONAL PLATFORM; IMMUNE-RESPONSES; SECRETED
   PROTEIN; BLAST FUNGUS; PLANT; GENE},
Research-Areas = {Biochemistry \& Molecular Biology},
Web-of-Science-Categories  = {Biochemical Research Methods},
Author-Email = {stkim71@pusan.ac.kr},
Affiliations = {Pusan National University; Kookmin University; Korea Research Institute
   of Bioscience \& Biotechnology (KRIBB); National Institute of
   Agricultural Sciences; Rural Development Administration (RDA), Republic
   of Korea; Kyung Hee University; Pusan National University; Nanjing
   Agricultural University},
ResearcherID-Numbers = {Park, Hyun-Ji/ABA-6694-2021
   Gupta, Ravi/K-5977-2019
   },
ORCID-Numbers = {Park, Hyun-Ji/0000-0001-9688-4418
   Gupta, Ravi/0000-0001-5242-9528
   Yoon, Jinmi/0000-0003-2882-6878
   Wang, Yiming/0000-0003-0513-9039},
Funding-Acknowledgement = {National Research Foundation of Korea (NRF) - Ministry of Education,
   Science, and Technology {[}2019R1A2C2085868, 2021R1A4A2001968,
   2021K1A3A1A61003041, 2022R1C1C2003947]; National Research Foundation of
   Korea {[}2019R1A2C2085868, 2021K1A3A1A61003041, 2022R1C1C2003947]
   Funding Source: Korea Institute of Science \& Technology Information
   (KISTI), National Science \& Technology Information Service (NTIS)},
Funding-Text = {This work was funded by grants from the National Research Foun- dation
   of Korea (NRF) funded by Ministry of Education, Science, and Technology
   (grant no. 2019R1A2C2085868, 2021R1A4A2001968, and 2021K1A3A1A61003041
   provided to STK and grant no. 2022R1C1C2003947 provided to CWM) .},
Cited-References = {Albrecht C, 2012, P NATL ACAD SCI USA, V109, P303, DOI 10.1073/pnas.1109921108.
   An G., 1989, PLANT MOL BIOL MANUA, P29, DOI {[}10.1007/978-94-009-0951-9\_3, DOI 10.1007/978-94-009-0951-9\_3].
   Baccelli I, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0100959.
   Bai L, 2009, PLANT J, V60, P314, DOI 10.1111/j.1365-313X.2009.03956.x.
   Bellande K, 2017, INT J MOL SCI, V18, DOI 10.3390/ijms18061164.
   Bigeard J, 2015, MOL PLANT, V8, P521, DOI 10.1016/j.molp.2014.12.022.
   Boller T, 2009, ANNU REV PLANT BIOL, V60, P379, DOI 10.1146/annurev.arplant.57.032905.105346.
   Bonza MC, 2011, PLANT BIOLOGY, V13, P421, DOI 10.1111/j.1438-8677.2010.00405.x.
   Borassi C, 2021, FEBS LETT, V595, P2593, DOI 10.1002/1873-3468.14185.
   Canonne J, 2011, PLANT SIGNAL BEHAV, V6, P13, DOI 10.4161/psb.6.1.14037.
   Cheng XY, 2013, PLANT J, V76, P687, DOI 10.1111/tpj.12328.
   Cheval C, 2013, BBA-MOL CELL RES, V1833, P1766, DOI 10.1016/j.bbamcr.2013.01.031.
   Cho LH, 2018, MOL CELLS, V41, P665, DOI 10.14348/molcells.2018.0148.
   Couto D, 2016, NAT REV IMMUNOL, V16, P537, DOI 10.1038/nri.2016.77.
   Dai N, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0060990.
   De Vleesschauwer D, 2012, PLANT PHYSIOL, V158, P1833, DOI 10.1104/pp.112.193672.
   Doczi R, 2007, PLANT CELL, V19, P3266, DOI 10.1105/tpc.106.050039.
   Eitas TK, 2010, CURR OPIN PLANT BIOL, V13, P472, DOI 10.1016/j.pbi.2010.04.007.
   Fernandez J, 2018, TRENDS MICROBIOL, V26, P582, DOI 10.1016/j.tim.2017.12.007.
   Frey NFD, 2012, PLANT PHYSIOL, V159, P798, DOI 10.1104/pp.111.192575.
   Frias M, 2013, MOL PLANT PATHOL, V14, P191, DOI 10.1111/j.1364-3703.2012.00842.x.
   Fu J, 2011, FRONT PLANT SCI, V2, DOI 10.3389/fpls.2011.00074.
   Gao XQ, 2019, FRONT PLANT SCI, V9, DOI 10.3389/fpls.2018.01913.
   Glazebrook J, 2005, ANNU REV PHYTOPATHOL, V43, P205, DOI 10.1146/annurev.phyto.43.040204.135923.
   Gomez-Gomez L, 2000, MOL CELL, V5, P1003, DOI 10.1016/S1097-2765(00)80265-8.
   Grant M, 2000, PLANT J, V23, P441, DOI 10.1046/j.1365-313x.2000.00804.x.
   Gupta R, 2020, PLANTS-BASEL, V9, DOI 10.3390/plants9030290.
   Gupta R, 2019, INT J MOL SCI, V20, DOI 10.3390/ijms20174135.
   Harun-Or-Rashid M, 2018, FRONT PLANT SCI, V9, DOI 10.3389/fpls.2018.01904.
   Hayafune M, 2014, P NATL ACAD SCI USA, V111, pE404, DOI 10.1073/pnas.1312099111.
   He YQ, 2017, NEW PHYTOL, V214, P388, DOI 10.1111/nph.14376.
   Hu JL, 2020, PLOS PATHOG, V16, DOI 10.1371/journal.ppat.1008801.
   Jeon JS, 2000, PLANT J, V22, P561, DOI 10.1046/j.1365-313x.2000.00767.x.
   Jeong JS, 2007, FEMS MICROBIOL LETT, V273, P157, DOI 10.1111/j.1574-6968.2007.00796.x.
   Jonak C, 2002, CURR OPIN PLANT BIOL, V5, P415, DOI 10.1016/S1369-5266(02)00285-6.
   Jones JDG, 2006, NATURE, V444, P323, DOI 10.1038/nature05286.
   Kessler SA, 2010, SCIENCE, V330, P968, DOI 10.1126/science.1195211.
   Kim DK, 2018, MOL NEURODEGENER, V13, DOI 10.1186/s13024-017-0234-4.
   Kim ST, 2004, PROTEOMICS, V4, P3569, DOI 10.1002/pmic.200400999.
   Kim ST, 2003, PROTEOMICS, V3, P2368, DOI 10.1002/pmic.200300577.
   Koopmans F, 2018, PROTEOMICS, V18, DOI 10.1002/pmic.201700304.
   Laxalt AM, 2002, CURR OPIN PLANT BIOL, V5, P332, DOI 10.1016/S1369-5266(02)00268-6.
   Lee JY, 2013, J PROTEOME RES, V12, P432, DOI 10.1021/pr300794y.
   Li C, 2015, ELIFE, V4, DOI {[}10.7554/eLife.06587, 10.7554/eLife.05378].
   Li J, 2002, CELL, V110, P213, DOI 10.1016/S0092-8674(02)00812-7.
   Li L, 2014, CELL HOST MICROBE, V15, P329, DOI 10.1016/j.chom.2014.02.009.
   Liu PL, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-24266-6.
   Liu TT, 2012, SCIENCE, V336, P1160, DOI 10.1126/science.1218867.
   Masachis S, 2016, NAT MICROBIOL, V1, DOI {[}10.1038/NMICROBIOL.2016.43, 10.1038/nmicrobiol.2016.43].
   Meinhardt LW, 2014, BMC GENOMICS, V15, DOI 10.1186/1471-2164-15-164.
   Meng Q, 2019, FRONT PLANT SCI, V10, DOI 10.3389/fpls.2019.01383.
   Meng Q, 2019, J PROTEOMICS, V196, P120, DOI 10.1016/j.jprot.2018.04.015.
   Min C.W., 2022, DATA BRIEF.
   Min CW, 2020, J AGR FOOD CHEM, V68, P8057, DOI 10.1021/acs.jafc.0c00986.
   Min CW, 2020, CELLS-BASEL, V9, DOI 10.3390/cells9061517.
   Min CW, 2019, PLANT BIOTECHNOL REP, V13, P111, DOI 10.1007/s11816-019-00518-3.
   Min CW, 2017, J PROTEOMICS, V169, P125, DOI 10.1016/j.jprot.2017.06.022.
   Miyakawa T, 2014, PLANT PHYSIOL, V166, P766, DOI 10.1104/pp.114.242636.
   Modi V, 2019, P NATL ACAD SCI USA, V116, P6818, DOI 10.1073/pnas.1814279116.
   Monaghan J, 2012, CURR OPIN PLANT BIOL, V15, P349, DOI 10.1016/j.pbi.2012.05.006.
   Nakashita H, 2003, PLANT J, V33, P887, DOI 10.1046/j.1365-313X.2003.01675.x.
   Newman MA, 2013, FRONT PLANT SCI, V4, DOI 10.3389/fpls.2013.00139.
   Noman A, 2019, INT J MOL SCI, V20, DOI 10.3390/ijms20081882.
   Padmanabhan M, 2009, CELL MICROBIOL, V11, P191, DOI 10.1111/j.1462-5822.2008.01260.x.
   Park H, 2011, MOL CELLS, V32, P561, DOI 10.1007/s10059-011-0178-4.
   Perez-Riverol Y, 2019, NUCLEIC ACIDS RES, V47, pD442, DOI 10.1093/nar/gky1106.
   Plubell DL, 2017, MOL CELL PROTEOMICS, V16, P873, DOI 10.1074/mcp.M116.065524.
   Ranty B, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.00327.
   Rao SF, 2021, BMC PLANT BIOL, V21, DOI 10.1186/s12870-021-03208-x.
   Reyna NS, 2006, MOL PLANT MICROBE IN, V19, P530, DOI 10.1094/MPMI-19-0530.
   Rodriguez MCS, 2010, ANNU REV PLANT BIOL, V61, P621, DOI 10.1146/annurev-arplant-042809-112252.
   Saini S, 2015, FRONT PLANT SCI, V6, DOI 10.3389/fpls.2015.00950.
   Shimizu T, 2010, PLANT J, V64, P204, DOI 10.1111/j.1365-313X.2010.04324.x.
   Silva NF, 2002, PLANT MOL BIOL, V50, P667, DOI 10.1023/A:1019951120788.
   Song D, 2006, PLANT BIOLOGY, V8, P587, DOI 10.1055/s-2006-924149.
   Song FM, 2002, PHYSIOL MOL PLANT P, V61, P31, DOI 10.1006/pmpp.2002.0414.
   Stenvik GE, 2008, PLANT CELL, V20, P1805, DOI 10.1105/tpc.108.059139.
   Stergiopoulos I, 2009, ANNU REV PHYTOPATHOL, V47, P233, DOI 10.1146/annurev.phyto.112408.132637.
   Sun JM, 2017, BMC GENOMICS, V18, DOI 10.1186/s12864-017-4155-y.
   Taj G, 2010, PLANT SIGNAL BEHAV, V5, P1370, DOI 10.4161/psb.5.11.13020.
   Tang DZ, 2017, PLANT CELL, V29, P618, DOI 10.1105/tpc.16.00891.
   Tarutani Y, 2004, BIOSCI BIOTECH BIOCH, V68, P1935, DOI 10.1271/bbb.68.1935.
   Torres MA, 2006, PLANT PHYSIOL, V141, P373, DOI 10.1104/pp.106.079467.
   Van Nguyen T, 2021, PLANTS-BASEL, V10, DOI 10.3390/plants10071409.
   Tyanova S, 2016, NAT PROTOC, V11, P2301, DOI 10.1038/nprot.2016.136.
   Tyanova S, 2016, NAT METHODS, V13, P731, DOI {[}10.1038/NMETH.3901, 10.1038/nmeth.3901].
   Vaattovaara A, 2019, COMMUN BIOL, V2, DOI 10.1038/s42003-019-0306-9.
   Vaid N, 2013, MOL PLANT, V6, P1405, DOI 10.1093/mp/sst033.
   van der Luit AH, 2000, PLANT PHYSIOL, V123, P1507, DOI 10.1104/pp.123.4.1507.
   Van Nguyen T, 2021, FRONT PLANT SCI, V12, DOI 10.3389/fpls.2021.723369.
   Wang Y, 2016, MOL PLANT MICROBE IN, V29, P299, DOI 10.1094/MPMI-12-15-0266-R.
   Wang ZY, 2012, ANNU REV GENET, V46, P701, DOI 10.1146/annurev-genet-102209-163450.
   Wisniewski JR, 2009, NAT METHODS, V6, P359, DOI {[}10.1038/NMETH.1322, 10.1038/nmeth.1322].
   Xu TD, 2014, SCIENCE, V343, P1025, DOI 10.1126/science.1245125.
   Yang DL, 2013, MOL PLANT, V6, P675, DOI 10.1093/mp/sst056.
   Yang YY, 2009, PLANT BIOTECHNOL J, V7, P763, DOI 10.1111/j.1467-7652.2009.00442.x.
   Yang ZH, 2020, J EXP BOT, V71, P2112, DOI 10.1093/jxb/erz541.
   Yoshida S, 1976, LAB MANUAL PHYSL STU, V3rd.
   Yu MH, 2018, INT J MOL SCI, V19, DOI 10.3390/ijms19124091.
   Zhang J, 2010, MOL PLANT, V3, P783, DOI 10.1093/mp/ssq035.
   Zhang L, 2014, PLANT SIGNAL BEHAV, V9, DOI 10.4161/15592324.2014.973818.
   Zhang L, 2009, PLANT PHYSIOL, V149, P916, DOI 10.1104/pp.108.131144.
   Zhao JZ, 2021, FRONT PLANT SCI, V12, DOI 10.3389/fpls.2021.660966.
   Zhao YF, 2019, MOL PLANT, V12, P59, DOI 10.1016/j.molp.2018.10.008.},
Number-of-Cited-References = {104},
Times-Cited = {4},
Usage-Count-Last-180-days = {7},
Usage-Count-Since-2013 = {13},
Journal-ISO = {J. Proteomics},
Doc-Delivery-Number = {3V9OU},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000841988400002},
DA = {2023-08-12},
}

@article{ WOS:000747677300001,
Author = {Sun, Zhu and Guo, Xiangyu and Xu, Yang and Zhang, Songchao and Cheng,
   Xiaohui and Hu, Qiong and Wang, Wenxiang and Xue, Xinyu},
Title = {Image Recognition of Male Oilseed Rape (Brassica napus) Plants Based on
   Convolutional Neural Network for UAAS Navigation Applications on
   Supplementary Pollination and Aerial Spraying},
Journal = {AGRICULTURE-BASEL},
Year = {2022},
Volume = {12},
Number = {1},
Month = {JAN},
Abstract = {To ensure the hybrid oilseed rape (OSR, Brassica napus) seed production,
   two important things are necessary, the stamen sterility on the female
   OSR plants and the effective pollen spread onto the pistil from the OSR
   male plants to the OSR female plants. The unmanned agricultural aerial
   system (UAAS) has developed rapidly in China. It has been used on
   supplementary pollination and aerial spraying during the hybrid OSR seed
   production. This study developed a new method to rapidly recognize the
   male OSR plants and extract the row center line for supporting the UAAS
   navigation. A male OSR plant recognition model was constructed based on
   the convolutional neural network (CNN). The sequence images of male OSR
   plants were extracted, the feature regions and points were obtained from
   the images through morphological and boundary process methods and
   horizontal segmentation, respectively. The male OSR plant image
   recognition accuracies of different CNN structures and segmentation
   sizes were discussed. The male OSR plant row center lines were fitted
   using the least-squares method (LSM) and Hough transform. The results
   showed that the segmentation algorithm could segment the male OSR plants
   from the complex background. The highest average recognition accuracy
   was 93.54\%, and the minimum loss function value was 0.2059 with three
   convolutional layers, one fully connected layer, and a segmentation size
   of 40 pix x 40 pix. The LSM is better for center line fitting. The
   average recognition model accuracies of original input images were 98\%
   and 94\%, and the average root mean square errors (RMSE) of angle were
   3.22 degrees and 1.36 degrees under cloudy day and sunny day lighting
   conditions, respectively. The results demonstrate the potential of using
   digital imaging technology to recognize the male OSR plant row for UAAS
   visual navigation on the applications of hybrid OSR supplementary
   pollination and aerial spraying, which would be a meaningful supplement
   in precision agriculture.},
Publisher = {MDPI},
Address = {ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND},
Type = {Article},
Language = {English},
Affiliation = {Zhang, SC (Corresponding Author), Nanjing Inst Agr Mech, Minist Agr \& Rural Affairs, Nanjing 210014, Peoples R China.
   Zhang, SC (Corresponding Author), SinoUSA Pesticide Applicat Technol Cooperat Lab, Nanjing 210014, Peoples R China.
   Xue, XY (Corresponding Author), Minist Agr \& Rural Affairs, Key Lab Aviat Plant Protect, Anyang 455000, Peoples R China.
   Sun, Zhu; Guo, Xiangyu; Xu, Yang; Zhang, Songchao, Nanjing Inst Agr Mech, Minist Agr \& Rural Affairs, Nanjing 210014, Peoples R China.
   Sun, Zhu; Guo, Xiangyu; Xu, Yang; Zhang, Songchao, SinoUSA Pesticide Applicat Technol Cooperat Lab, Nanjing 210014, Peoples R China.
   Guo, Xiangyu, Zhejiang Univ, Coll Biosyst Engn \& Food Sci, Hangzhou 310058, Peoples R China.
   Cheng, Xiaohui; Hu, Qiong; Wang, Wenxiang, Chinese Acad Agr Sci, Oil Crops Res Inst, Wuhan 430062, Peoples R China.
   Xue, Xinyu, Minist Agr \& Rural Affairs, Key Lab Aviat Plant Protect, Anyang 455000, Peoples R China.},
DOI = {10.3390/agriculture12010062},
Article-Number = {62},
EISSN = {2077-0472},
Keywords = {hybrid oilseed rape; male parent recognition; convolutional neural
   network; image processing; UAAS visual navigation; seed production;
   aerial spraying},
Keywords-Plus = {INDUSTRY; VISION; SYSTEM; OIL},
Research-Areas = {Agriculture},
Web-of-Science-Categories  = {Agronomy},
Author-Email = {sunzhu@caas.cn
   guoxiangyu@caas.cn
   xuyang01@caas.cn
   zhangsongchao@caas.cn
   chengxiaohui@caas.cn
   huqiong01@caas.cn
   wangwenxiang@caas.cn
   xuexinyu@caas.cn},
Affiliations = {Chinese Academy of Agricultural Sciences; Nanjing Institute of
   Agricultural Mechanization, CAAS; Ministry of Agriculture \& Rural
   Affairs; Zhejiang University; Chinese Academy of Agricultural Sciences;
   Oil Crops Research Institute, CAAS; Ministry of Agriculture \& Rural
   Affairs},
ORCID-Numbers = {zhang, songchao/0000-0001-9146-449X},
Funding-Acknowledgement = {China Agriculture Research System of MOF; MARA {[}CARS-12]; National Key
   Research and Development Program of China {[}2017YFD0701000];
   Agricultural Science and Technology Innovation Project of the Chinese
   Academy of Agricultural Sciences, Crop Protection Machinery Team;
   Technology Innovation Guidance Plan of Gansu Province Science and
   Technology Project {[}21CX6NG291]; Jiangsu Science and Technology
   Development Plan {[}BE2019305]},
Funding-Text = {This research was funded by China Agriculture Research System of MOF and
   MARA (Grant NO. CARS-12), the National Key Research and Development
   Program of China (Grant No. 2017YFD0701000), the Agricultural Science
   and Technology Innovation Project of the Chinese Academy of Agricultural
   Sciences, Crop Protection Machinery Team (Grant No. CAAS-ASTIP-CPMT),
   the Technology Innovation Guidance Plan of Gansu Province Science and
   Technology Project (Grant No. 21CX6NG291) and the Jiangsu Science and
   Technology Development Plan (BE2019305).},
Cited-References = {Ahmad F, 2020, COMPUT ELECTRON AGR, V172, DOI 10.1016/j.compag.2020.105350.
   Cai GW, 2014, UNMANNED SYST, V2, P175, DOI 10.1142/S2301385014300017.
   {[}曹光乔 Cao Guangqiao], 2020, {[}农业机械学报, Transactions of the Chinese Society for Agricultural Machinery], V51, P1.
   Ciocca G, 2018, COMPUT VIS IMAGE UND, V176, P70, DOI 10.1016/j.cviu.2018.09.001.
   Cong RH, 2020, INT J PLANT PROD, V14, P77, DOI 10.1007/s42106-019-00069-1.
   Delgado M, 2018, IND CROP PROD, V125, P401, DOI 10.1016/j.indcrop.2018.09.013.
   {[}关卓怀 Guan Zhuohuai], 2020, {[}农业机械学报, Transactions of the Chinese Society for Agricultural Machinery], V51, P19.
   Huang XM, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10248854.
   Lan YuBin, 2018, Transactions of the Chinese Society of Agricultural Engineering, V34, P104.
   Liu QX, 2019, IND CROP PROD, V140, DOI 10.1016/j.indcrop.2019.111560.
   Liu Y, 2021, TRENDS FOOD SCI TECH, V113, P193, DOI 10.1016/j.tifs.2021.04.042.
   Liu YF, 2019, COMPUT ELECTRON AGR, V162, P126, DOI 10.1016/j.compag.2019.04.009.
   Lu J, 2010, SCI FERTILIZATION TE.
   Maravall D, 2015, NEUROCOMPUTING, V151, P101, DOI 10.1016/j.neucom.2014.09.077.
   Meng QK, 2015, COMPUT ELECTRON AGR, V112, P128, DOI 10.1016/j.compag.2014.11.006.
   Opromolla R, 2021, AEROSP SCI TECHNOL, V119, DOI 10.1016/j.ast.2021.107167.
   Paoletti ME, 2019, ISPRS J PHOTOGRAMM, V158, P279, DOI 10.1016/j.isprsjprs.2019.09.006.
   {[}彭顺正 Peng Shunzheng], 2017, {[}农业工程学报, Transactions of the Chinese Society of Agricultural Engineering], V33, P45.
   Requier F, 2015, ECOL APPL, V25, P881, DOI 10.1890/14-1011.1.
   Shim YY, 2017, EUR J LIPID SCI TECH, V119, DOI 10.1002/ejlt.201600358.
   Si YongSheng, 2010, Nongye Jixie Xuebao = Transactions of the Chinese Society for Agricultural Machinery, V41, P163.
   Sun KW, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21051714.
   Szubert K, 2018, CELLULOSE, V25, P6269, DOI 10.1007/s10570-018-2018-6.
   {[}黄小毛 Huang Xiaomao], 2020, {[}农业机械学报, Transactions of the Chinese Society for Agricultural Machinery], V51, P34.
   Tang ZQ, 2021, CONTROL ENG PRACT, V112, DOI 10.1016/j.conengprac.2021.104827.
   Vollmann J., 2009, OILSEED RAPE OIL CRO, P91.
   Wang G., 2017, INTELL COMPUT APPL, V7, P46.
   Wang XiaoQin, 2015, Transactions of the Chinese Society of Agricultural Engineering, V31, P152.
   Wang Y., 2017, THESIS NW A F U XIAN.
   Xu Bo, 2015, Transactions of the Chinese Society of Agricultural Engineering, V31, P173.
   Xue XY, 2016, COMPUT ELECTRON AGR, V128, P58, DOI 10.1016/j.compag.2016.07.022.
   Yang LL, 2012, COMPUT ELECTRON AGR, V89, P116, DOI 10.1016/j.compag.2012.08.011.
   {[}杨洋 Yang Yang], 2020, {[}农业工程学报, Transactions of the Chinese Society of Agricultural Engineering], V36, P162.
   {[}曾宏伟 Zeng Hongwei], 2020, {[}农业工程学报, Transactions of the Chinese Society of Agricultural Engineering], V36, P18.
   {[}张漫 Zhang Man], 2020, {[}农业机械学报, Transactions of the Chinese Society for Agricultural Machinery], V51, P1.
   {[}张勤 Zhang Qin], 2020, {[}农业机械学报, Transactions of the Chinese Society for Agricultural Machinery], V51, P34.
   Zhang SC, 2021, AGRONOMY-BASEL, V11, DOI 10.3390/agronomy11102035.
   Zhang SC, 2020, INT J AGR BIOL ENG, V13, P29, DOI 10.25165/j.ijabe.20201303.5439.
   Zhang SC, 2019, INT J AGR BIOL ENG, V12, P82, DOI 10.25165/j.ijabe.20191204.4641.
   {[}周俊 Zhou Jun], 2021, {[}农业机械学报, Transactions of the Chinese Society for Agricultural Machinery], V52, P1.
   Zhou L, 2019, COMPR REV FOOD SCI F, V18, P1793, DOI 10.1111/1541-4337.12492.},
Number-of-Cited-References = {41},
Times-Cited = {4},
Usage-Count-Last-180-days = {9},
Usage-Count-Since-2013 = {20},
Journal-ISO = {Agriculture-Basel},
Doc-Delivery-Number = {YO0ZS},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000747677300001},
OA = {gold},
DA = {2023-08-12},
}

@article{ WOS:000667648700001,
Author = {Huang, Denghong and Zhou, Zhongfa and Zhang, Zhenzhen and Zhu, Meng and
   Yin, Linjiang and Peng, Ruiwen and Zhang, Yang and Zhang, Wenhui},
Title = {Recognition and counting of pitaya trees in karst mountain environment
   based on unmanned aerial vehicle RGB images},
Journal = {JOURNAL OF APPLIED REMOTE SENSING},
Year = {2021},
Volume = {15},
Number = {4},
Month = {JUN 10},
Abstract = {The counting of crop plants is an important basis for the estimation of
   pitaya yield. Traditional crop monitoring methods are time-consuming and
   laborious. The pitaya tree, one of the characteristic economic crops in
   the complex mountain environment, was selected as the research object.
   Considering the comprehensive factors such as different seasons, cloud
   shadow shading, crop interplanting, steep terrain, different breeds, and
   ages of pitaya trees, the quad-rotor unmanned aerial vehicles (UAVs)
   were used to collect the visible light images of the planting base of
   pitaya trees in the test area in karst plateau canyon region and the
   verification area in a complex environment. First, the characteristics
   of the RGB values of the eight main ground objects in the test areas are
   analyzed according to the color index, geometric size, and texture
   characteristics, which show that pitaya plants, weeds, and shrubs have
   certain interference with each other. Then the excess green index (ExG)
   of the images is calculated to enhance the vegetation characteristics
   and separate vegetation and non-vegetation. Gaussian high-pass filter
   (GHPF) is used to retain the high-frequency information of pitaya plants
   on the ExG images. After GHPF processing, the DN values of shrub and
   weeds are reduced, the edges of the area target are enhanced, and the
   influences of weeds and cloud shadows on plant identification are
   eliminated. Finally, through field measurement of pitaya plant data and
   OTSU, grayscale segmentation was performed on the images processed by
   GHPF and the pitaya plant information was extracted. Combined with the
   projection area of single pitaya tree, the number of pitaya trees was
   obtained by area screening method. The target detection percentage of
   test area A, test area B, and the verification area in complex
   environment is, respectively, 96.99\%, 94.66\%, and 94.30\%; the quality
   percentage of them is, respectively, 92.46\%, 90.41\% and 91.50\%; the
   branching factor of them is, respectively, 0.05, 0.05, and 0.03, proving
   that the RGB images collected by UAV can be used in the recognition and
   counting of pitaya trees in complex mountain environments. Our study can
   provide a reference for the application of low-cost, high-efficiency UAV
   visible light remote sensing to precision agriculture in complex
   mountain environment. (C) 2021 Society of Photo-Optical Instrumentation
   Engineers (SPIE)},
Publisher = {SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS},
Address = {1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA},
Type = {Article},
Language = {English},
Affiliation = {Zhou, ZF (Corresponding Author), Guizhou Normal Univ, Sch Karst Sci, Guiyang, Peoples R China.
   Zhou, ZF (Corresponding Author), Guizhou Normal Univ, Sch Geog \& Environm Sci, Guiyang, Peoples R China.
   Zhou, ZF (Corresponding Author), State Engn Technol Inst Karst Desertificat Contro, Guiyang, Peoples R China.
   Huang, Denghong; Zhou, Zhongfa; Zhang, Zhenzhen; Zhu, Meng; Yin, Linjiang; Peng, Ruiwen; Zhang, Yang; Zhang, Wenhui, Guizhou Normal Univ, Sch Karst Sci, Guiyang, Peoples R China.
   Huang, Denghong; Zhou, Zhongfa; Zhang, Zhenzhen; Zhu, Meng; Yin, Linjiang; Peng, Ruiwen; Zhang, Yang; Zhang, Wenhui, Guizhou Normal Univ, Sch Geog \& Environm Sci, Guiyang, Peoples R China.
   Huang, Denghong; Zhou, Zhongfa; Zhang, Zhenzhen; Zhu, Meng; Yin, Linjiang; Peng, Ruiwen; Zhang, Yang; Zhang, Wenhui, State Engn Technol Inst Karst Desertificat Contro, Guiyang, Peoples R China.},
DOI = {10.1117/1.JRS.15.042402},
Article-Number = {042402},
ISSN = {1931-3195},
Keywords = {unmanned aerial vehicles; visible light remote sensing; color index;
   Gaussian high-pass filter; pitaya tree},
Keywords-Plus = {HEIGHT; SYSTEM},
Research-Areas = {Environmental Sciences \& Ecology; Remote Sensing; Imaging Science \&
   Photographic Technology},
Web-of-Science-Categories  = {Environmental Sciences; Remote Sensing; Imaging Science \& Photographic
   Technology},
Author-Email = {fa6897@163.com},
Affiliations = {Guizhou Normal University; Guizhou Normal University},
ORCID-Numbers = {zhang, zhen zhen/0000-0001-5902-0397},
Funding-Acknowledgement = {Guizhou Provincial Science and Technology Foundation {[}194]; National
   Key Research and Development Program of China {[}2018YFB0505400];
   Agricultural Major Industrial Scientific Research Soft Science Project
   of Guizhou Provincial Department of Education {[}Qianjiaohe KY
   {[}2019]032]; National Natural Science Foundation of China {[}41661088];
   Guizhou Province High-level Innovative Talent Training Plan
   ``Hundred{''} Level Talents {[}Qiankehe Platform Talents {[}2016] 5674]},
Funding-Text = {This research was supported by Guizhou Provincial Science and Technology
   Foundation (Grant No. Qankehe Foundation-ZK{[}2021] general Project No.
   194); the National Key Research and Development Program of China (Grant
   No. 2018YFB0505400); Agricultural Major Industrial Scientific Research
   Soft Science Project of Guizhou Provincial Department of Education
   (Grant No. Qianjiaohe KY {[}2019]032); National Natural Science
   Foundation of China (Grant No. 41661088); Guizhou Province High-level
   Innovative Talent Training Plan ``Hundred{''} Level Talents (Grant No.
   Qiankehe Platform Talents {[}2016] 5674). We would like to thank the
   editors and the anonymous reviewers for their insightful comments and
   suggestions, which helped to clarify the text and improve the manuscript
   significantly. The authors declare no conflicts of interest.},
Cited-References = {Al-Rahbi S, 2019, J APPL REMOTE SENS, V13, DOI 10.1117/1.JRS.13.034514.
   Bazi Y, 2014, INT GEOSCI REMOTE SE, P537, DOI 10.1109/IGARSS.2014.6946478.
   Das J, 2015, IEEE INT CON AUTO SC, P462, DOI 10.1109/CoASE.2015.7294123.
   Dorj UO, 2013, INT J SECUR APPL, V7, P405.
   Du MM, 2017, INT J AGR BIOL ENG, V10, P1, DOI 10.25165/j.ijabe.20171005.3180.
   Fryskowska A., 2015, ISPRS INT ARCH PHOTO, V40, P1, DOI DOI 10.5194/ISPRSARCHIVES-XL-1-W4-1-2015.
   Gitelson AA, 2002, REMOTE SENS ENVIRON, V80, P76, DOI 10.1016/S0034-4257(01)00289-9.
   Gonzalez R. C., 2010, DIGITAL IMAGE PROCES, V3rd, P479.
   Guo Q, 2017, INT J REMOTE SENS, V38, P2954, DOI 10.1080/01431161.2017.1285083.
   Holman FH, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8121031.
   Hunt E. Raymond Jr, 2005, Precision Agriculture, V6, P359, DOI 10.1007/s11119-005-2324-5.
   Jeong S, 2016, J APPL REMOTE SENS, V10, DOI 10.1117/1.JRS.10.026027.
   Karhan Z, 2015, SIG PROCESS COMMUN, P1541, DOI 10.1109/SIU.2015.7130140.
   Kestur R, 2018, J INDIAN SOC REMOTE, V46, P991, DOI 10.1007/s12524-018-0756-4.
   Kumar T., 2010, INT J COMPUT APPL, V7, P7, DOI {[}DOI 10.5120/1140-1493, 10.5120/1140-1493].
   Lamm RD, 2002, T ASAE, V45, P231.
   Lebourgeois V, 2012, PRECIS AGRIC, V13, P525, DOI 10.1007/s11119-012-9262-9.
   Lee EC, 2011, SENSORS-BASEL, V11, P2319, DOI 10.3390/s110302319.
   Araus JL, 2014, TRENDS PLANT SCI, V19, P52, DOI 10.1016/j.tplants.2013.09.008.
   MAO W., 2003, REAL TIME DETECTION.
   Migdall S, 2009, PRECIS AGRIC, V10, P508, DOI 10.1007/s11119-009-9104-6.
   Motohka T, 2010, REMOTE SENS-BASEL, V2, P2369, DOI 10.3390/rs2102369.
   Mulla DJ, 2013, BIOSYST ENG, V114, P358, DOI 10.1016/j.biosystemseng.2012.08.009.
   NasrAbadi SBF, 2018, J APPL REMOTE SENS, V12, DOI 10.1117/1.JRS.12.026007.
   OTSU T, 1982, MAKROMOL CHEM-RAPID, V3, P127.
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J.
   Payne AB, 2013, COMPUT ELECTRON AGR, V91, P57, DOI 10.1016/j.compag.2012.11.009.
   Potgieter AB, 2017, FRONT PLANT SCI, V8, DOI 10.3389/fpls.2017.01532.
   Qian JP, 2018, SCI AGR, V75, P273, DOI {[}10.1590/1678-992X-2016-0152, 10.1590/1678-992x-2016-0152].
   Rasmussen J, 2013, WEED RES, V53, P242, DOI 10.1111/wre.12026.
   Scott JB, 2015, HORTTECHNOLOGY, V25, P617, DOI 10.21273/HORTTECH.25.5.617.
   Shufelt JA, 1999, IEEE T PATTERN ANAL, V21, P311, DOI 10.1109/34.761262.
   Sonka M., 1993, IMAGE PROCESSING ANA, pXIX.
   Sunoj S, 2017, T ASABE, V60, P1467, DOI 10.13031/trans.12105.
   Torres-Sanchez J, 2014, COMPUT ELECTRON AGR, V103, P104, DOI 10.1016/j.compag.2014.02.009.
   Varela S, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10020343.
   WOEBBECKE DM, 1993, P SOC PHOTO-OPT INS, V1836, P208, DOI 10.1117/12.144030.
   Xu ZQ, 2019, J APPL REMOTE SENS, V14, DOI 10.1117/I.JRS.14.022204.
   Yang GJ, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9070642.
   Yin DM, 2019, REMOTE SENS ENVIRON, V223, P34, DOI 10.1016/j.rse.2018.12.034.
   Yue JB, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9070708.
   Yun Hee-Sup, 2016, Journal of Biosystems Engineering, V41, P126.},
Number-of-Cited-References = {42},
Times-Cited = {2},
Usage-Count-Last-180-days = {13},
Usage-Count-Since-2013 = {33},
Journal-ISO = {J. Appl. Remote Sens.},
Doc-Delivery-Number = {TB0QV},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000667648700001},
DA = {2023-08-12},
}
